<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Daniela’s Notes for Nicemboim, Schad, &amp; Vasishth (2024) - 3&nbsp; Ch. 3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../book_notes/ch8.html" rel="next">
<link href="../book_notes/ch2.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Keine Treffer",
    "search-matching-documents-text": "Treffer",
    "search-copy-link-title": "Link in die Suche kopieren",
    "search-hide-matches-text": "Zusätzliche Treffer verbergen",
    "search-more-match-text": "weitere Treffer in diesem Dokument",
    "search-more-matches-text": "weitere Treffer in diesem Dokument",
    "search-clear-button-title": "Zurücksetzen",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Abbrechen",
    "search-submit-button-title": "Abschicken",
    "search-label": "Suchen"
  }
}</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: {autoNumber: "AMS"} },
  tex2jax: {inlineMath: [ ['$','$'], ["\\(","\\)"] ]}
});
</script>

<!-- This is what works with Quarto -->
<script>
  MathJax = {
    tex: {
      tags: 'ams'  // should be 'ams', 'none', or 'all'
    }
  };
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="cutsom.css">
<meta name="twitter:title" content="Daniela’s Notes for Nicemboim, Schad, &amp; Vasishth (2024) - 3&nbsp; Ch. 3">
<meta name="twitter:description" content="">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Daniela’s Notes for Nicemboim, Schad, &amp; Vasishth (2024)</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Suchen"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Navigation umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://daniela-palleschi.github.io/"> <i class="bi bi-home" role="img">
</i> 
<span class="menu-text">D. Palleschi</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Dunkelmodus umschalten"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../book_notes/ch1.html">Book notes</a></li><li class="breadcrumb-item"><a href="../book_notes/ch3.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Ch. 3</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Overview</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Purpose</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../setup/project_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project set-up</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Book notes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book_notes/ch1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Chapter notes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book_notes/ch2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Ch. 2</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book_notes/ch3.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Ch. 3</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book_notes/ch8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Contrast Coding</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Book exercises</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book_exercises/ch1_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Ch. 1 Exercises</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book_exercises/ch5_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Ch. Exercises</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book_exercises/ch8_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Ch. 8 Exercises</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Literaturverzeichnis</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Chatper contents</h2>
   
  <ul>
  <li><a href="#set-up" id="toc-set-up" class="nav-link active" data-scroll-target="#set-up">Set up</a></li>
  <li><a href="#ch.-3---computational-bayesian-data-analysis" id="toc-ch.-3---computational-bayesian-data-analysis" class="nav-link" data-scroll-target="#ch.-3---computational-bayesian-data-analysis"><span class="header-section-number">4</span> Ch. 3 - Computational Bayesian data analysis</a>
  <ul>
  <li><a href="#deriving-the-posterior-through-sampling" id="toc-deriving-the-posterior-through-sampling" class="nav-link" data-scroll-target="#deriving-the-posterior-through-sampling"><span class="header-section-number">4.1</span> Deriving the posterior through sampling</a></li>
  <li><a href="#bayesian-regression-models-using-stan-brms" id="toc-bayesian-regression-models-using-stan-brms" class="nav-link" data-scroll-target="#bayesian-regression-models-using-stan-brms"><span class="header-section-number">4.2</span> Bayesian regression models using Stan: brms</a>
  <ul class="collapse">
  <li><a href="#a-simple-linear-model-a-single-subject-pressing-a-button-repeatedly" id="toc-a-simple-linear-model-a-single-subject-pressing-a-button-repeatedly" class="nav-link" data-scroll-target="#a-simple-linear-model-a-single-subject-pressing-a-button-repeatedly"><span class="header-section-number">4.2.1</span> A simple linear model: A single subject pressing a button repeatedly</a>
  <ul class="collapse">
  <li><a href="#specifying-the-model-in-brms" id="toc-specifying-the-model-in-brms" class="nav-link" data-scroll-target="#specifying-the-model-in-brms"><span class="header-section-number">4.2.1.1</span> Specifying the model in <code>brms</code></a></li>
  <li><a href="#sampling-and-convergence-in-a-nutshell" id="toc-sampling-and-convergence-in-a-nutshell" class="nav-link" data-scroll-target="#sampling-and-convergence-in-a-nutshell"><span class="header-section-number">4.2.1.2</span> Sampling and convergence in a nutshell</a></li>
  <li><a href="#output-of-brms" id="toc-output-of-brms" class="nav-link" data-scroll-target="#output-of-brms"><span class="header-section-number">4.2.1.3</span> Output of <code>brms</code></a></li>
  </ul></li>
  </ul></li>
  <li><a href="#prior-predictive-distribution" id="toc-prior-predictive-distribution" class="nav-link" data-scroll-target="#prior-predictive-distribution"><span class="header-section-number">4.3</span> Prior predictive distribution</a></li>
  <li><a href="#the-influence-of-priors-sensitivity-analysis" id="toc-the-influence-of-priors-sensitivity-analysis" class="nav-link" data-scroll-target="#the-influence-of-priors-sensitivity-analysis"><span class="header-section-number">4.4</span> The influence of priors: sensitivity analysis</a>
  <ul class="collapse">
  <li><a href="#flat-uninformative-priors" id="toc-flat-uninformative-priors" class="nav-link" data-scroll-target="#flat-uninformative-priors"><span class="header-section-number">4.4.1</span> Flat, uninformative priors</a></li>
  <li><a href="#regularising-priors" id="toc-regularising-priors" class="nav-link" data-scroll-target="#regularising-priors"><span class="header-section-number">4.4.2</span> Regularising priors</a></li>
  <li><a href="#principled-priors" id="toc-principled-priors" class="nav-link" data-scroll-target="#principled-priors"><span class="header-section-number">4.4.3</span> Principled priors</a></li>
  <li><a href="#informative-priors" id="toc-informative-priors" class="nav-link" data-scroll-target="#informative-priors"><span class="header-section-number">4.4.4</span> Informative priors</a></li>
  </ul></li>
  <li><a href="#re-visiting-the-button-press-example-with-different-priors" id="toc-re-visiting-the-button-press-example-with-different-priors" class="nav-link" data-scroll-target="#re-visiting-the-button-press-example-with-different-priors"><span class="header-section-number">4.5</span> Re-visiting the button-press example with different priors</a></li>
  <li><a href="#posterior-predictive-distribution" id="toc-posterior-predictive-distribution" class="nav-link" data-scroll-target="#posterior-predictive-distribution"><span class="header-section-number">4.6</span> Posterior predictive distribution</a>
  <ul class="collapse">
  <li><a href="#comparing-different-likelihoods" id="toc-comparing-different-likelihoods" class="nav-link" data-scroll-target="#comparing-different-likelihoods"><span class="header-section-number">4.6.1</span> Comparing different likelihoods</a></li>
  <li><a href="#the-log-normal-likelihood" id="toc-the-log-normal-likelihood" class="nav-link" data-scroll-target="#the-log-normal-likelihood"><span class="header-section-number">4.6.2</span> The log-normal likelihood</a></li>
  <li><a href="#re-fitting-a-single-subject-pressing-a-button-repeatedly-with-a-log-normal-likelihood" id="toc-re-fitting-a-single-subject-pressing-a-button-repeatedly-with-a-log-normal-likelihood" class="nav-link" data-scroll-target="#re-fitting-a-single-subject-pressing-a-button-repeatedly-with-a-log-normal-likelihood"><span class="header-section-number">4.6.3</span> Re-fitting a single subject pressing a button repeatedly with a log-normal likelihood</a></li>
  </ul></li>
  <li><a href="#list-of-most-important-commands" id="toc-list-of-most-important-commands" class="nav-link" data-scroll-target="#list-of-most-important-commands"><span class="header-section-number">4.7</span> List of most important commands</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">4.8</span> Summary</a></li>
  </ul></li>
  <li><a href="#session-info" id="toc-session-info" class="nav-link" data-scroll-target="#session-info"><span class="header-section-number">5</span> Session Info</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../book_notes/ch1.html">Book notes</a></li><li class="breadcrumb-item"><a href="../book_notes/ch3.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Ch. 3</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Ch. 3</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<section id="set-up" class="level1 unnumbered">
<h1 class="unnumbered">Set up</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set global knit options</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">echo =</span> T, <span class="co"># print chunks?</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">eval =</span> T, <span class="co"># run chunks?</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">error =</span> F, <span class="co"># print errors?</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">warning =</span> F, <span class="co"># print warnings?</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">message =</span> F, <span class="co"># print messages?</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>                      <span class="at">cache =</span> F <span class="co"># cache?; be careful with this!</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>                      )</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># suppress scientific notation</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">scipen=</span><span class="dv">999</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># play a sound if error encountered</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">error =</span> <span class="cf">function</span>() {beepr<span class="sc">::</span><span class="fu">beep</span>(<span class="dv">9</span>)})</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="do">## create list of package names</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>packages <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="co">#"SIN", # this package was removed from the CRAN repository</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>               <span class="st">"MASS"</span>, <span class="st">"dplyr"</span>, <span class="st">"tidyr"</span>, <span class="st">"purrr"</span>, <span class="st">"extraDistr"</span>, <span class="st">"ggplot2"</span>, <span class="st">"loo"</span>, <span class="st">"bridgesampling"</span>, <span class="st">"brms"</span>, <span class="st">"bayesplot"</span>, <span class="st">"tictoc"</span>, <span class="st">"hypr"</span>, <span class="st">"bcogsci"</span>, <span class="st">"papaja"</span>, <span class="st">"grid"</span>, <span class="st">"kableExtra"</span>, <span class="st">"gridExtra"</span>, <span class="st">"lme4"</span>, <span class="st">"cowplot"</span>, <span class="st">"pdftools"</span>, <span class="st">"cmdstanr"</span>, <span class="st">"rootSolve"</span>, <span class="st">"rstan"</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># NB: if you haven't already installed bcogsci through devtools, it won't be loaded</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="do">## Now load or install &amp; load all</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>package.check <span class="ot">&lt;-</span> <span class="fu">lapply</span>(</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  packages,</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">FUN =</span> <span class="cf">function</span>(x) {</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="sc">!</span><span class="fu">require</span>(x, <span class="at">character.only =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>      <span class="fu">install.packages</span>(x, <span class="at">dependencies =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>      <span class="fu">library</span>(x, <span class="at">character.only =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co"># this is also required, taken from the textbook</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="do">## Save compiled models:</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="fu">rstan_options</span>(<span class="at">auto_write =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="do">## Parallelize the chains using all the cores:</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">mc.cores =</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>())</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co"># To solve some conflicts between packages</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>select <span class="ot">&lt;-</span> dplyr<span class="sc">::</span>select</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>extract <span class="ot">&lt;-</span> rstan<span class="sc">::</span>extract</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="ch.-3---computational-bayesian-data-analysis" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Ch. 3 - Computational Bayesian data analysis</h1>
<ul>
<li>for real datasets, it was too cumbersome to do all the math to dertermine posterior distributions
<ul>
<li>thanks to probabilistic programming languages, we can define our models without have to do all the math</li>
</ul></li>
</ul>
<section id="deriving-the-posterior-through-sampling" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="deriving-the-posterior-through-sampling"><span class="header-section-number">4.1</span> Deriving the posterior through sampling</h2>
<ul>
<li>recall the example cloze task for <em>It’s raining, I’m going to take the…</em>, with the ‘correct’ answer <em>bus</em> (‘umbrella’ in the book but to me ‘bus’ is the most natural completion)
<ul>
<li>imagine 80 ‘successes’ and 20 ‘failures’</li>
<li>assuming a binomial distribution as the likelihood function, and <span class="math inline">\(Beta(a = 4, b = 4)\)</span> as a prior distribution for the cloze probability</li>
<li>if we can obtain samples from the posterior distribution or <span class="math inline">\(\theta\)</span>, instead of an analystically derived posterior distribution, given enough samples we will have a good <em>approximation</em> of the posterior distribution</li>
<li>‘<em>obtain samples</em>’ here means a situation similar to when we use <code>rbinom</code> or <code>rnorm</code> to obtain samples from a particular distribution</li>
<li>assume we used some probabilistic prgramming langauge to obtain 20,000 samples from the posterior distribution of the cloze probability <span class="math inline">\(\theta\)</span></li>
</ul></li>
</ul>
</section>
<section id="bayesian-regression-models-using-stan-brms" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="bayesian-regression-models-using-stan-brms"><span class="header-section-number">4.2</span> Bayesian regression models using Stan: brms</h2>
<ul>
<li>because of increased computing power and probabilistic programming languages (e.g., WinBUGS, JAGS, R-INLA, pymc3, Turing, Stan), Bayesian statistics is now more popular
<ul>
<li>these languages allow th euser to define models without the complexities of the sampling process</li>
<li>however, they require learning a new language as te statistical model must be specified using a specific syntax</li>
<li>additionally, some knowledge of the <em>sampling process</em> is needed to correctly parametrize the models and avoid convergence issues</li>
</ul></li>
<li>Bayesian inference in <code>R</code> is possible without having the fully specify the model thanks to <code>stanarm</code> and <code>brms</code> packages
<ul>
<li>both packages provide Bayesian equivalents of R model-fitting functions like <code>(g)lmer</code></li>
<li>both use Stan as the back-end for estimation and sampling</li>
</ul></li>
<li>for this part of the book we will focus on <code>brms</code>
<ul>
<li>it can be useful for a smooth transition from frequentist models to their Bayesian equivalents</li>
<li>it has the added benefit that the Stan code can be inspected via <code>brms::make_stancode()</code> and <code>brms::make_standata()</code></li>
<li>users can then customatize their models or learn from the code produced internally by <code>brms</code></li>
</ul></li>
</ul>
<section id="a-simple-linear-model-a-single-subject-pressing-a-button-repeatedly" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="a-simple-linear-model-a-single-subject-pressing-a-button-repeatedly"><span class="header-section-number">4.2.1</span> A simple linear model: A single subject pressing a button repeatedly</h3>
<ul>
<li>imagine having data from a single participant repeatedly pressing the spacebar as fast as possible
<ul>
<li>the data are response times in imilliseconds in each trial; we want to know how long it takes to press a key for this subject</li>
</ul></li>
<li>let’s model the data with thef ollowing assumptions:
<ol type="1">
<li>Tehre is a true (unknown) underlying time, <span class="math inline">\(\mu\)</span> ms, that the subject needs to press the psace bar</li>
<li>There is some noise in this process</li>
<li>The noise is normally distributed (this assumption is questionable given that response times are generally skewed, we will fix this assumption later)</li>
</ol></li>
</ul>
<p>This means that the likelihood for each observation <span class="math inline">\(n\)</span> will be:</p>
<p><span class="math display">\[
rt_{n} \sim Normal(\mu, \sigma)
\tag{3.2}
\]</span></p>
<ul>
<li>where <span class="math inline">\(n\)</span> = 1, …, <span class="math inline">\(N\)</span>, and <span class="math inline">\(rt\)</span> is the dependent variable (RTs in ms)
<ul>
<li>the variable <span class="math inline">\(N\)</span> indexes the total number of data points</li>
<li><span class="math inline">\(\mu\)</span> indicates the <em>location</em> of the normal distirbution function; the lcoation parameter shifts the distribution left or right on the horizontal axis</li>
<li>in the <em>normal distribution</em>, the location is also the mean of the distribution</li>
<li><span class="math inline">\(\sigma\)</span> indicates the <em>scale</em> of the distribution; as the scale decreases, the distribution gets narrower</li>
<li>for the normal distribution, the scale is also the standard deviation</li>
</ul></li>
<li>this same equation can be expressed as:</li>
</ul>
<p><span class="math display">\[
rt_n = \mu + \varepsilon \hbox{, where } \varepsilon_n \stackrel{iid}{\sim} \mathit{Normal}(0,\sigma) \tag{3.3}
\]</span></p>
<ul>
<li>this version of the model should be understood to mean that each data point <span class="math inline">\(rt_n\)</span> has some variability around a mean value <span class="math inline">\(\mu\)</span>, and that variability has standard deviation <span class="math inline">\(\sigma\)</span>
<ul>
<li>the term <span class="math inline">\(iid\)</span> (‘independent and identically distributed’) implies that each data point <span class="math inline">\(rt_n\)</span> is independently generated (i.e., not correlated with any of the other data points), and is coming from the same distribution (<span class="math inline">\(Normal(\mu,\sigma)\)</span>)</li>
</ul></li>
<li><strong>Frequentist model</strong>: that will give us the <em>maximu likelihood estimate</em> (the sample mean) of the time it takes to press the space bar
<ul>
<li>this owuld be enough ifnmroamtion to write the formular in <code>R</code>, <code>lm(rt ~ 1)</code></li>
</ul></li>
<li><strong>Bayesian linear model</strong>: we will also need to define <em>priors</em> for the two parameters of our model
<ul>
<li>let’s say we know for sure that the time it takes to press a key will be positive and lower than a minute (0-60,000ms), but we don’t want to make a commitment regarding which values are more likely</li>
<li>we encode what we know about the noise in the task in <span class="math inline">\(\sigma\)</span>: this parameter must be positive and we’ll assume any value below 2000ms is equally likely; such <em>flat</em> or <em>uniformative</em> priors are generaly strongly discouraged: it will almost never be the best approximation of what we know</li>
<li>let’s start with such priors, regardless:</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mu &amp;\sim \mathit{Uniform}(0, 60000) \\
\sigma &amp;\sim \mathit{Uniform}(0, 2000)
\end{aligned}
\tag{3.4}
\]</span></p>
<ul>
<li>load the data from the <code>bcogsci</code> package</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"df_spacebar"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df_spacebar <span class="ot">&lt;-</span> df_spacebar <span class="sc">%&gt;%</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">rt =</span> t)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_spacebar)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 2
     rt trial
  &lt;int&gt; &lt;int&gt;
1   141     1
2   138     2
3   128     3
4   132     4
5   126     5
6   134     6</code></pre>
</div>
</div>
<ul>
<li>plot the data before you do anything else; as we suspected, the data lock a bit (positively) skewed, but let’s ignore that for now</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df_spacebar <span class="sc">%&gt;%</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(rt)) <span class="sc">+</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Button-press data"</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"response times"</span>) <span class="sc">+</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>() <span class="sc">+</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<section id="specifying-the-model-in-brms" class="level4" data-number="4.2.1.1">
<h4 data-number="4.2.1.1" class="anchored" data-anchor-id="specifying-the-model-in-brms"><span class="header-section-number">4.2.1.1</span> Specifying the model in <code>brms</code></h4>
<ul>
<li>fit the model defined by equations <span class="math inline">\(\ref{3.2}\)</span> and <span class="math inline">\(\ref{3.4}\)</span></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>fit_press <span class="ot">&lt;-</span> <span class="fu">brm</span>(</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">60000</span>),</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">class =</span> Intercept, <span class="co"># mean</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">lb =</span> <span class="dv">0</span>,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">ub =</span> <span class="dv">60000</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">2000</span>),</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">class =</span> sigma, <span class="co"># sd</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">lb =</span> <span class="dv">0</span>,</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">ub =</span> <span class="dv">2000</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">4</span>,</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">2000</span>,</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">warmup =</span> <span class="dv">1000</span>,</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press_1"</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>some differences between this syntax and <code>lm()</code>:
<ol type="1">
<li><code>family = gaussian()</code> makes it explicity that the underlying likelihood function is a normal distribution</li>
</ol>
<ul>
<li>this is implicit in <code>lm()</code></li>
<li>the default for <code>brms</code> is <code>gaussian()</code></li>
<li>other linking function are possible, just like in the <code>glm()</code> function</li>
</ul>
<ol start="2" type="1">
<li><code>prior</code> takes as argument a vector of priors</li>
</ol>
<ul>
<li>this is optional, but we should <strong><em>always</em></strong> explicitly specify each prior; otherwise <code>brms</code> will define priors but they may or may not be appropriate</li>
<li>this is why we need <code>lb</code> (lower bound) and <code>upper bound</code> to specify the plausible range of values to sample from in cases where the distribution is restricted (e.g., reaction times cannot be negative, so <code>lb</code> must be at least 0)</li>
</ul>
<ol start="3" type="1">
<li><code>chains</code> refers to the number of independent runs for sampling</li>
</ol>
<ul>
<li>default = 4</li>
</ul>
<ol start="4" type="1">
<li><code>iter</code> refers to the number of iteratiosn that a sampler makes to sample from the posterior distribution of each paramter</li>
</ol>
<ul>
<li>default = 2000</li>
</ul>
<ol start="5" type="1">
<li><code>warmup</code> refers to the number of iterations from the start of sampling that are eventually discarded</li>
</ol>
<ul>
<li>default = <span class="math inline">\(\frac{`iter`}{2}\)</span></li>
</ul></li>
<li>the last 3 options determine the behaviour of the sampling algorithm</li>
</ul>
</section>
<section id="sampling-and-convergence-in-a-nutshell" class="level4" data-number="4.2.1.2">
<h4 data-number="4.2.1.2" class="anchored" data-anchor-id="sampling-and-convergence-in-a-nutshell"><span class="header-section-number">4.2.1.2</span> Sampling and convergence in a nutshell</h4>
<ul>
<li>our 4 chains start independently from each other
<ul>
<li>each chain “searches” for samples of the posterior distribution in a multidimensional space, where each parameter corresponds to a dimension</li>
<li>the shape of this space is determined by the priors and likelihood</li>
<li>chains start at a random location and each iteraton takes one sample each</li>
<li>when sampling begins, the samples may or may not belong to the posterior distributions of the parameters; eventually the chains end up in the vicinity of the posterior and from then on the samples will belong to the posterior</li>
</ul></li>
<li>therefore, when sampling starts the samples from the different chains can be far from each other; at some point they will <strong>converge</strong> and start delivering samples from the posterior distributions
<ul>
<li>typically the default values of <code>brms</code> will be sufficient to achieve convergence</li>
<li>if not, <code>brms</code> (but really <code>Stan</code>) will print out warnings with suggestions for fixin the convergence problems</li>
<li>this is why we remove the <code>warmup</code> samples, because the chains can start far apart and not in the posterior distribution</li>
<li>so, if we run 4 chains with 2000 iterations, we will obtain a total of 4000 iterations (<span class="math inline">\(\frac{4 chains * 2000 iterations}{2} = \frac{8000}{2}\)</span>)</li>
</ul></li>
</ul>
</section>
<section id="output-of-brms" class="level4" data-number="4.2.1.3">
<h4 data-number="4.2.1.3" class="anchored" data-anchor-id="output-of-brms"><span class="header-section-number">4.2.1.3</span> Output of <code>brms</code></h4>
<ul>
<li>once the model has ben fit (and assuming we didn’t get any warning messages about convergence), we can print out the samples of the posterior distributions using <code>as_draws_df()</code></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press) <span class="sc">%&gt;%</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">3</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A draws_df: 3 iterations, 1 chains, and 5 variables
  b_Intercept sigma Intercept lprior  lp__
1         166    25       166    -19 -1685
2         167    25       167    -19 -1684
3         166    26       166    -19 -1685
# ... hidden reserved variables {'.chain', '.iteration', '.draw'}</code></pre>
</div>
</div>
<ul>
<li><code>b_Intercept</code> corresponds to our <span class="math inline">\(\mu\)</span>; we can ignore the last 2 columns</li>
<li>plot the density and trace plot of each paramter after warmup:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_press)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>and print the object with the brms fit</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>fit_press</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   168.68      1.33   166.04   171.27 1.00     2773     2839

Further Distributional Parameters:
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    24.98      0.92    23.29    26.89 1.00     3201     2719

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<ul>
<li>or with <code>posterior_summary()</code></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">posterior_summary</span>(fit_press)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               Estimate Est.Error        Q2.5       Q97.5
b_Intercept   168.67592 1.3341598   166.03664   171.27276
sigma          24.98047 0.9160944    23.28801    26.89033
Intercept     168.67592 1.3341598   166.03664   171.27276
lprior        -18.60300 0.0000000   -18.60300   -18.60300
lp__        -1683.74586 0.9681534 -1686.26917 -1682.77752</code></pre>
</div>
</div>
<ul>
<li><code>Estimate</code> is just the <em>mean</em> of the posterior samples</li>
<li><code>Est.Error</code> is the <em>standard deviation</em> of the posterior</li>
<li><code>CI</code>s mark the upper and lower bounds of the 95% <em>credible intervals</em></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept <span class="sc">%&gt;%</span> </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 168.6759</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept <span class="sc">%&gt;%</span> </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sd</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.33416</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept <span class="sc">%&gt;%</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">quantile</span>(<span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    2.5%    97.5% 
166.0366 171.2728 </code></pre>
</div>
</div>
<ul>
<li>summary also provides:
<ul>
<li><code>Rhat</code>: compares between- and within-chain estimate of each parameter
<ul>
<li>is &gt;1 when chains have not mixed well; we can only rely on the model if the R-hats for <em>all</em> parameters are &lt;1.05 (warnings will appear otherwise)</li>
</ul></li>
<li><code>Bulk_ESS</code>: ‘bulk effective sample size’ is a measure of sampling efficienty in the bulk of the posterior distribution
<ul>
<li>i.e., the effectice sample size for the mean and median estimates</li>
</ul></li>
<li><code>Tail_ESS</code>: ‘tail effective sample size’: the sampling efficiency at the tails of the distribution
<ul>
<li>i.e., the minimum of effective sample sizes for 5% and 95% quantiles</li>
</ul></li>
<li>the number of post-warmup samples is generally lower than the effective sample size, because the samples from the chains are not independent (they are correlated to some extent) , and carry less information about the posterior distribution in comparison to <em>independent</em> samples</li>
</ul></li>
<li>very low sample size indicates sampling problems (and will produce warnings) and in general appear when chains are not properly mixed
<ul>
<li>as a rule of thumb, a minimum of 400 effective sample size is required for statistical summaries</li>
</ul></li>
<li>we wee our model fits without problems, and we get some posterior distribution for our parameters, but we should ask the following questions:</li>
</ul>
<ol type="1">
<li>What informationa re the priors encoding? Do the priors make sense?</li>
<li>Does the likelihood assumed int he model make sense for the data?</li>
</ol>
<ul>
<li>to answer these questions we can look at the <em>prior</em> and <em>posterior distributions</em> and we can do sensitivity analyses</li>
</ul>
</section>
</section>
</section>
<section id="prior-predictive-distribution" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="prior-predictive-distribution"><span class="header-section-number">4.3</span> Prior predictive distribution</h2>
<ul>
<li>we had the following priors in our linear model:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mu &amp;\sim \mathit{Uniform}(0, 60000) \\
\sigma &amp;\sim \mathit{Uniform}(0, 2000)
\end{aligned}
\tag{3.5}
\]</span></p>
<ul>
<li>these priors encode assumptions about our data</li>
<li>to understand these assumptions, we are going to generate data from the model
<ul>
<li>such data, which is generated entirely by the <em>prior distributions</em>, is called the <strong>prior predictive distribution</strong></li>
<li>generating prior predictive distributions repeatedly helps us to check whether the priors make sense; we want to know whether the priors generate realistic-looking data</li>
</ul></li>
<li>to do this, repeat the following many times:
<ol type="1">
<li>Tae one sample from each of the priors</li>
<li>Plug those samples into the porbability density/mass function used as the likelihood int he model to generate a dataset <span class="math inline">\(y_{pred_1}, ..., y_{pred_n}\)</span></li>
</ol>
<ul>
<li>each sample is an imaginary or potential data set</li>
</ul></li>
<li>create a function that does this:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>normal_predictive_distribution <span class="ot">&lt;-</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(mu_samples, sigma_samples, N_obs) {</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># empty data frame with headers:</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    df_pred <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">trialn =</span> <span class="fu">numeric</span>(<span class="dv">0</span>),</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">rt_pred =</span> <span class="fu">numeric</span>(<span class="dv">0</span>),</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">iter =</span> <span class="fu">numeric</span>(<span class="dv">0</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># i iterates from 1 to the length of mu_samples,</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># which we assume is identical to</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the length of the sigma_samples:</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_along</span>(mu_samples)) {</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>      mu <span class="ot">&lt;-</span> mu_samples[i]</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>      sigma <span class="ot">&lt;-</span> sigma_samples[i]</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>      df_pred <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>        df_pred,</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>        <span class="fu">tibble</span>(</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>          <span class="at">trialn =</span> <span class="fu">seq_len</span>(N_obs), <span class="co"># 1, 2,... N_obs</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>          <span class="at">rt_pred =</span> <span class="fu">rnorm</span>(N_obs, mu, sigma),</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>          <span class="at">iter =</span> i</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    df_pred</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>  }</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>the code below produces 1000 samples of the prior predictive distribution of the model we defined for <code>fit_press</code> from the <code>df_spacebar</code> data, that had 361 trials
<ul>
<li>this code will produce 361,000 predicted values (361 observations x 1000 simulations)</li>
<li>we could also use the option <code>sample_prior = "only"</code> in our <code>brms</code> model, but it still depends on Stam’s sampler which uses Hamiltonian Monte Carlo, and can fail to converge especially with uninformative priors</li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>N_samples <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df_spacebar)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>mu_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">60000</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>sigma_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">2000</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>prior_pred <span class="ot">&lt;-</span> <span class="fu">normal_predictive_distribution</span>(</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_samples =</span> mu_samples,</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_samples =</span> sigma_samples,</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">N_obs =</span> N_obs</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="fu">toc</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2.118 sec elapsed</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>prior_pred</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 361,000 × 3
   trialn rt_pred  iter
    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
 1      1  26813.     1
 2      2  27298.     1
 3      3  28224.     1
 4      4  28051.     1
 5      5  28176.     1
 6      6  27918.     1
 7      7  28332.     1
 8      8  28241.     1
 9      9  27841.     1
10     10  27232.     1
# ℹ 360,990 more rows</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Box 3.1: A more efficint prior predictive distribution function
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>alternatively, we could use the <code>purr::map2_dfr()</code> functions as below, which would run a bit faster:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(purrr)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the function:</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>normal_predictive_distribution <span class="ot">&lt;-</span> <span class="cf">function</span>(mu_samples,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>                                           sigma_samples,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>                                           N_obs) {</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map2_dfr</span>(mu_samples, sigma_samples, <span class="cf">function</span>(mu, sigma) {</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tibble</span>(</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">trialn =</span> <span class="fu">seq_len</span>(N_obs),</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">rt_pred =</span> <span class="fu">rnorm</span>(N_obs, mu, sigma)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>  }, <span class="at">.id =</span> <span class="st">"iter"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># .id is always a string and</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># needs to be converted to a number</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">iter =</span> <span class="fu">as.numeric</span>(iter))</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the timing:</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>prior_pred <span class="ot">&lt;-</span> <span class="fu">normal_predictive_distribution</span>(</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_samples =</span> mu_samples,</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_samples =</span> sigma_samples,</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">N_obs =</span> N_obs</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a><span class="fu">toc</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<ul>
<li>let’s look at the first 18 samples of the <em>prior predictive distribution</em></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>prior_pred <span class="sc">%&gt;%</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(iter <span class="sc">&lt;=</span> <span class="dv">18</span>) <span class="sc">%&gt;%</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(rt_pred)) <span class="sc">+</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"18 samples"</span>,</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">x=</span><span class="st">"predicted rt (ms)"</span>) <span class="sc">+</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..)) <span class="sc">+</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.x =</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>      <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">40</span>, <span class="at">vjust =</span> <span class="dv">1</span>, <span class="at">hjust =</span> <span class="dv">1</span>, <span class="at">size =</span> <span class="dv">14</span>)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.0005</span>),</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.00025</span>, <span class="fl">0.0005</span>), <span class="at">name =</span> <span class="st">"density"</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>iter, <span class="at">ncol =</span> <span class="dv">3</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-samples18" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-samples18-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="ch3_files/figure-html/fig-samples18-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-samples18-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;4.1: 18 samples
</figcaption>
</figure>
</div>
</div>
</div>
<ul>
<li>Figure @fig-samples18 shows prior data sets that are not realistic: the data shows RT distributions are symmetrical (and we know they are generally right-skewed)
<ul>
<li>worse, a few have <em>negative</em> RT values</li>
</ul></li>
<li>so, our priors led to unrealistic values in our prior predictive distribution
<ul>
<li>so our priors weren’t very useful</li>
</ul></li>
<li>so, what priors should we have used?</li>
</ul>
</section>
<section id="the-influence-of-priors-sensitivity-analysis" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="the-influence-of-priors-sensitivity-analysis"><span class="header-section-number">4.4</span> The influence of priors: sensitivity analysis</h2>
<ul>
<li>there are 4 main classes of priors in this book
<ul>
<li>but there is no fixed nomenclature for these kind of priors, there’s no current naming convention in the field</li>
</ul></li>
</ul>
<section id="flat-uninformative-priors" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="flat-uninformative-priors"><span class="header-section-number">4.4.1</span> Flat, uninformative priors</h3>
<ul>
<li>the idea behind uninformative priors is to let the data ‘speak fo ritself’ and to not bias the statistical inference iwth ’subjective priors</li>
<li>issues with this approach:
<ul>
<li>the prior is as subjective as the likelihood, and different choices of likelihood might have a stronger mpace on the posterior than choice of priors</li>
<li>uninformative priors are in general unrealistic and give equal weight to all values within the support of the prior distribution</li>
<li>unifnromative priors m ake the sampling slower and might lead to convergence problems</li>
<li>it is not always clear which parametrization of a given distribution the flat priors should be assigned to</li>
</ul></li>
<li>in our space bar button press example, and uniformative prior would be:</li>
</ul>
<p><span class="math display">\[
\mu \sim Uniform(-10^{20}, 10^{20})
\]</span> - this is a strange prior because it’s on them millisecond scale, and allows for impossibly large positive values, as well as negative values which are not possible at all</p>
</section>
<section id="regularising-priors" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="regularising-priors"><span class="header-section-number">4.4.2</span> Regularising priors</h3>
<ul>
<li><p>used when we don’t have <em>much</em> prior information or knowledge</p>
<ul>
<li>sometimes called <em>weakly informative</em> or <em>mildly informative</em></li>
</ul></li>
<li><p>these are priors that down-weight extreme values (they provide <em>regularization</em>)</p>
<ul>
<li>usually not very informative, and mostly let the likelihood dominate in determining the posteriors</li>
</ul></li>
<li><p>these are <strong>theory-neutral</strong> priors; they do not bias the parameters to values spported by any prior belief or theory</p></li>
<li><p>these priors help stabilize computation</p></li>
<li><p>in our button press example, a regularizing prior owuld be</p></li>
</ul>
<p><span class="math display">\[
\mu \sim Normal_+(0,1000)
\]</span> - where <span class="math inline">\(Normal_+\)</span> indicates that the normal distribution is truncated at 0ms (i.e., is cut off at 0, so no negative values are possible) - this is regularizing because it rules out negative button-pressing times and down-weights extreme values over 2000ms</p>
</section>
<section id="principled-priors" class="level3" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="principled-priors"><span class="header-section-number">4.4.3</span> Principled priors</h3>
<ul>
<li>these priors encode all (or most of) the theory-neutral information
<ul>
<li>one generally knows what one’s data do and do not look like, it is possible to build priors that truly reflect the properties of potential data sets</li>
</ul></li>
<li>in our button press example, a principled prior could be</li>
</ul>
<p><span class="math display">\[
\mu \sim Normal_+(250,100)
\]</span> - it is not overly restrictive, but represents a guess about plausible button-pressing tiems - <em>prior predictive checks</em> using principled priors should produce realisitic distributions of the dependent variable</p>
</section>
<section id="informative-priors" class="level3" data-number="4.4.4">
<h3 data-number="4.4.4" class="anchored" data-anchor-id="informative-priors"><span class="header-section-number">4.4.4</span> Informative priors</h3>
<ul>
<li>for cases wehre a lot of prior knowledge exists, and not much data</li>
<li>unless there is a <em>very</em> good reason to use informative priors, it is not a good idea to let the priors have too much influence on the posterior
<ul>
<li>e.g., investigating a language-imparied population from which we can’t get many subjects, but a lot of previous published work exists on the topic</li>
</ul></li>
<li>in our button press data, an informative prior could be based on the meta-analysis of previously published or existing data, or the result of prior elicitation from an expert on the topic under investigation
<ul>
<li>e.g., the following prior:</li>
</ul></li>
</ul>
<p><span class="math display">\[
\mu \sim Normal_+(200,20)
\]</span></p>
<ul>
<li>this will have some influence ont he posterior for <span class="math inline">\(\mu\)</span>, especially when one has relatively sparse data</li>
</ul>
</section>
</section>
<section id="re-visiting-the-button-press-example-with-different-priors" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="re-visiting-the-button-press-example-with-different-priors"><span class="header-section-number">4.5</span> Re-visiting the button-press example with different priors</h2>
<ul>
<li>what would happen if even wider priors were used for the model we defined earlier?
<ul>
<li>suppose every mean between -10^6 and 10^6 is assumed to be equally likely</li>
<li>this is clearly unrealistic and nonsensical; we don’t expect negative values</li>
<li>for the sd, we could assume any value between 0 and 10^6 is equally likely; the likelihood remains unchanged</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mu &amp;\sim \mathit{Uniform}(-10^{6}, 10^{6}) \\
\sigma &amp;\sim \mathit{Uniform}(0,  10^{6})
\end{aligned}
\tag{3.6}
\]</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The default settings are used when they are not set explicitly:</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 4 chains, with half of the iterations (set as 3000) as warmup.</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>fit_press_unif <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="sc">-</span><span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>, <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>),</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">class =</span> Intercept,</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>          <span class="at">lb =</span> <span class="sc">-</span><span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>,</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>          <span class="at">ub =</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>),</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>),</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>          <span class="at">class =</span> sigma,</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>          <span class="at">lb =</span> <span class="dv">0</span>,</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>          <span class="at">ub =</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">3000</span>,</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># the following needed to be changed to achieve convergence</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">list</span>(<span class="at">adapt_delta =</span> .<span class="dv">99</span>,</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>                 <span class="at">max_treedepth =</span> <span class="dv">15</span>),</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press_unif"</span>)</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>even with these priors, the output of the model is virtually dientical to the previous one</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>fit_press_unif</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 3000; warmup = 1500; thin = 1;
         total post-warmup draws = 6000

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   168.62      1.33   166.02   171.27 1.00     4176     2981

Further Distributional Parameters:
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    25.00      0.90    23.37    26.91 1.00      600      710

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>fit_press</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   168.68      1.33   166.04   171.27 1.00     2773     2839

Further Distributional Parameters:
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    24.98      0.92    23.29    26.89 1.00     3201     2719

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<ul>
<li>what about very informative priors?
<ul>
<li>assume the mean values very close to 400ms are the most likely, and that the sd of RTs is very close to 100ms</li>
<li>this is not very sensical, 200ms seems like a more realistic mean for button-press</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mu &amp;\sim \mathit{Normal}(400, 10) \\
\sigma &amp;\sim \mathit{Normal}_+(100, 10) \end{aligned}
\tag{3.7}
\]</span> - if we refit our model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>fit_press_inf <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">400</span>, <span class="dv">10</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># brms knows that SDs need to be bounded</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to exclude values below zero:</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">100</span>, <span class="dv">10</span>), <span class="at">class =</span> sigma)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press_inf"</span>)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>we see that the likelihood mostly dominates again, and the new posterior means and CrIs are only shifted by a few milliseconds when these unrealistic but informative priors are used:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>fit_press_inf</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   172.90      1.38   170.20   175.63 1.00     2994     2659

Further Distributional Parameters:
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    26.09      1.07    24.12    28.28 1.00     2507     2165

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<ul>
<li>as a final example of sensitivity analysis, let’s choose some <em>principled</em> priors</li>
<li>assuming we have some prior experience, let’s suppose the mean RT is expected to be arround 200ms, with a 95% probability of the mean ranging from 0 to 400ms
<ul>
<li>this uncertainty is perhaps unreasonably large, but one might want to allow a bit more uncertainty than one really thinks is reasonable (sometimes called <em>Cromwell’s rules</em>)</li>
<li>let’s then decide on the prior <span class="math inline">\(Normal(200,100)\)</span></li>
<li>with just a single participnt and a simple task, the residual standard deviation <span class="math inline">\(\sigma\)</span> shouldn’t be very large: let’s settle on a location of 50ms for a trucnated normal distribution, but still allow for relatively large uncertainty:</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mu &amp;\sim \mathit{Normal}(200, 100) \\
\sigma &amp;\sim \mathit{Normal}_+(50, 50)
\end{aligned}
\]</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>fit_press_prin <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">200</span>, <span class="dv">100</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">50</span>, <span class="dv">50</span>), <span class="at">class =</span> sigma)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press_prin"</span>)</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>again, the estimates are virtually the same as before:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>fit_press_prin</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept   168.69      1.30   166.15   171.18 1.00     4101     2734

Further Distributional Parameters:
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma    25.00      0.96    23.16    26.95 1.00     4219     2608

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<ul>
<li><p>these examples do not mean priors <em>never</em> matter</p></li>
<li><p>when there is enough data, the likelihood will dominate in determing the posterior distributions</p>
<ul>
<li>what constitutes ‘enough’ data is also a function of the complexity of the model; more complex models require more data, as a rule</li>
</ul></li>
<li><p>regularized, principled priors (i.e., those that are more consistent with our a priori beliefs about the data) in general speed-up model convergence</p></li>
<li><p>to see how influenced by the priors the posterior is, it’s wise to carry out a <strong>sensitivity analysis</strong>: try different priors and either verify that the posterior doesn’t chagne drastically, or report how the posterior is affected by some specific priors</p></li>
</ul>
</section>
<section id="posterior-predictive-distribution" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="posterior-predictive-distribution"><span class="header-section-number">4.6</span> Posterior predictive distribution</h2>
<ul>
<li>the <strong>posterior predictive distribution</strong> is a <em>collection of data sets generated from the model</em> (the likelihood and the priors)</li>
<li>having obtained the posterior distributions of the parameters after taking into account the data, the posterior distributions can be used to generate future data from the model
<ul>
<li><p>i.e., given the <em>posterior distribution</em> of the parameters of the model, the <em>posterior</em> <strong><em>predictive</em></strong> <em>distribution</em> gives us some indication of what future data might look like</p></li>
<li><p>once the posterior distributions <span class="math inline">\(p(\theta|y)\)</span> are available, the predictions based on these distributions, by integrating out the parameters</p></li>
</ul></li>
</ul>
<p><span class="math display">\[
p(\boldsymbol{y_{pred}}\mid \boldsymbol{y} ) = \int_{\boldsymbol{\Theta}} p(\boldsymbol{y_{pred}}, \boldsymbol{\Theta}\mid \boldsymbol{y})\, d\boldsymbol{\Theta}= \int_{\boldsymbol{\Theta}}
p(\boldsymbol{y_{pred}}\mid \boldsymbol{\Theta},\boldsymbol{y})p(\boldsymbol{\Theta}\mid \boldsymbol{y})\, d\boldsymbol{\Theta}
\]</span> - assuming the past and future observations are conditionally independent given <span class="math inline">\(\theta\)</span>, the above equation can be written as:</p>
<p><span class="math display">\[
p(\boldsymbol{y_{pred}}\mid \boldsymbol{y} )=\int_{\boldsymbol{\Theta}} p(\boldsymbol{y_{pred}}\mid \boldsymbol{\Theta}) p(\boldsymbol{\Theta}\mid \boldsymbol{y})\, d\boldsymbol{\Theta}
\tag{3.8}
\]</span></p>
<ul>
<li>this <strong>posterior predictive distribution</strong> has important differences from predictions obtained with the <em>frequentist</em> approach
<ul>
<li><strong>frequentist</strong>: gives a point estimate of each predicted observation given the maximum likelihood estimate of <span class="math inline">\(\theta\)</span> (a point value)</li>
<li><strong>Bayesian</strong>: gives a <em>distribution</em> of values for each predicated observation</li>
</ul></li>
<li>as with the <em>prior</em> predictive distribution, the integration can be carried out computationally by generating samples from the posterior predictive distribution
<ul>
<li>we can use the same function <code>normal_predictive_distribution()</code> as created above; the only difference is that the samples come from the <strong>posterior</strong>, not from <code>mu</code> and <code>sigma</code></li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df_spacebar)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>mu_samples <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>sigma_samples <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>sigma</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="fu">normal_predictive_distribution</span>(</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_samples =</span> mu_samples,</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_samples =</span> sigma_samples,</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">N_obs =</span> N_obs</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1,444,000 × 3
   trialn rt_pred  iter
    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
 1      1    170.     1
 2      2    171.     1
 3      3    165.     1
 4      4    165.     1
 5      5    214.     1
 6      6    206.     1
 7      7    165.     1
 8      8    149.     1
 9      9    122.     1
10     10    177.     1
# ℹ 1,443,990 more rows</code></pre>
</div>
</div>
<ul>
<li>the function <code>brms::posterior_predict()</code> is convenient, as it delivers samples from the posterior predictive distribution
<ul>
<li>in a matrix, with the samples as rows and observations (data-points) as columns; so for <code>fit_press</code> there’d be 361 columns</li>
<li>N.B., if the model is fit with <code>sample_prior = "only"</code>, the dependent variable is ignored and <code>posterior_predict</code> will give samples from the <em>prior</em> predictive distribution</li>
</ul></li>
<li>the <strong>posterior predictive distirubtion</strong> can be used to examine the ‘descriptive adequacy’ of the model under consideration
<ul>
<li>this is called <strong><em>posterior predictive checks</em></strong></li>
<li>the goal is to establish that the posterior predictive data look more or less similar to the observed data</li>
<li>achieveing ‘descriptive adequacy’ means the current data <em>could</em> have been generated by the model</li>
</ul></li>
<li>pass a test of descriptive adequacy is not strong evidence in favour of a model, but a major failure in descriptive adequacy can be interpreted as strong evidence against a model (i.e., passing the test is <strong><em>necessary but not sufficient</em></strong> evidence in favour of the model)</li>
<li>in addition, one should check that the <em>range</em> of predictions that the model makes is reasonably constrained
<ul>
<li>if a model can capture any possible outcome, then the model fit to a particular data set is not so informative</li>
<li>thus, posterior predictive checking is important but only a sanity check to assess whether the model behaviour is reasonable</li>
</ul></li>
<li>we can usually just use the plot functions from <code>brms</code>
<ul>
<li>e.g., <code>ppcheck()</code> takes as arguments the model, number of predicted data sets, and the type of visualisation
<ul>
<li>in these plots, the <strong>observed data</strong> are plotted as <span class="math inline">\(y\)</span>, and <strong>predicted data</strong> as <span class="math inline">\(y_{rep}\)</span></li>
</ul></li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># histograms</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="co"># model</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ndraws =</span> <span class="dv">11</span>, <span class="co"># n of predicted data sets</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">type =</span> <span class="st">"hist"</span> <span class="co"># plot type</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>         )</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># layered density plots</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="co"># model</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="co"># n of predicted data sets</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">type =</span> <span class="st">"dens_overlay"</span> <span class="co"># plot type</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>         )</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>we see the data (<span class="math inline">\(y\)</span>) is slightly skewed and has no values smaller than 100ms, but the predictive distributions are centered and symmetrical
<ul>
<li>so the posterior predictive check shows a slight mismatch between the observed and predicted data</li>
</ul></li>
<li>Can we build a better model? Let’s see…</li>
</ul>
<section id="comparing-different-likelihoods" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="comparing-different-likelihoods"><span class="header-section-number">4.6.1</span> Comparing different likelihoods</h3>
<ul>
<li>response times are not usually normally distributed
<ul>
<li><em>log-normal</em> distribution would be more realistic</li>
</ul></li>
</ul>
</section>
<section id="the-log-normal-likelihood" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="the-log-normal-likelihood"><span class="header-section-number">4.6.2</span> The log-normal likelihood</h3>
<ul>
<li>if <span class="math inline">\(y\)</span> is log-normally distributed, that means that <span class="math inline">\(log(y)\)</span> is normally distributed
<ul>
<li>the log-normal distribution is also defined using the parameters location (<span class="math inline">\(\mu\)</span>) and scale (<span class="math inline">\(\sigma\)</span>), but these are on the log ms scale and correspond to the mean and standard deviation of the logarithm of the data <span class="math inline">\(y\)</span>, <span class="math inline">\(log(y)\)</span>, which will be normally distributed</li>
<li>therefore, when we model some data <span class="math inline">\(y\)</span> using the log-normal likelihood, the parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are on a different scale than the data <span class="math inline">\(y\)</span>, which is represented here:</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\log(\boldsymbol{y}) &amp;\sim \mathit{Normal}( \mu, \sigma)\\
\boldsymbol{y} &amp;\sim \mathit{LogNormal}( \mu, \sigma)
\end{aligned}
\tag{3.9}
\]</span></p>
<ul>
<li>we can obtain samples from the log-normal distribution, using the normal distribution by first setting an auxiliary variable, <span class="math inline">\(z\)</span>, so that <span class="math inline">\(z = log(y)\)</span>
<ul>
<li>so, <span class="math inline">\(z \sim Normal(\mu, \sigma)\)</span></li>
<li>then we can use <span class="math inline">\(exp(z)\)</span> as samples from the <span class="math inline">\(LogNormal(\mu,\sigma)\)</span></li>
<li>since exp(<span class="math inline">\(z\)</span>) = exp(log(<span class="math inline">\(y\)</span>)) = <span class="math inline">\(y\)</span></li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">6</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">500000</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate N random samples from a log-normal distribution</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>sl <span class="ot">&lt;-</span> <span class="fu">rlnorm</span>(N, mu, sigma)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(<span class="at">samples =</span> sl), <span class="fu">aes</span>(samples)) <span class="sc">+</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">binwidth =</span> <span class="dv">50</span>) <span class="sc">+</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Log-normal distribution</span><span class="sc">\n</span><span class="st">"</span>) <span class="sc">+</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2000</span>))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-27-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate N random samples from a normal distribution,</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and then exponentiate them</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>sn <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">rnorm</span>(N, mu, sigma))</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(<span class="at">samples =</span> sn), <span class="fu">aes</span>(samples)) <span class="sc">+</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">binwidth =</span> <span class="dv">50</span>) <span class="sc">+</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Exponentiated samples from</span><span class="sc">\n</span><span class="st">a normal distribution"</span>) <span class="sc">+</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2000</span>))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-27-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="re-fitting-a-single-subject-pressing-a-button-repeatedly-with-a-log-normal-likelihood" class="level3" data-number="4.6.3">
<h3 data-number="4.6.3" class="anchored" data-anchor-id="re-fitting-a-single-subject-pressing-a-button-repeatedly-with-a-log-normal-likelihood"><span class="header-section-number">4.6.3</span> Re-fitting a single subject pressing a button repeatedly with a log-normal likelihood</h3>
<ul>
<li>if we assume that response times are log-normally distributed, we’ll need to change our likelihood function as follows:</li>
</ul>
<p><span class="math display">\[
rt_n \sim LogNormal(\mu, \sigma)
\]</span></p>
<ul>
<li>but now <strong><em>the scale of our priors needs to change</em></strong>!
<ul>
<li>starting with uniform priors for ease of exposition, although these are really not appropriate:</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{align}
\mu &amp;\sim Uniform(0,11)\\
\sigma &amp;\sim Uniform(0,1)
\end{align}
\]</span></p>
<ul>
<li>because the parameters are on a different scale than the dependent variable, their interpretation chagnes and it is more complex than dealing with a linear model that assumes a normal likelihood (<strong>location and scale do not coincide with the mean and standard deviation of the log-normal</strong>)
<ul>
<li><strong><em>the location, <span class="math inline">\(\mu\)</span></em></strong>: in our previous linear model, <span class="math inline">\(\mu\)</span> represented the mean
<ul>
<li>now the mean needs to be calculated in the following way: exp(<span class="math inline">\(\frac{\mu + \sigma^2}{2}\)</span>)</li>
<li>i.e., in the log-normal, the mean is dependent on both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span></li>
<li>the median is just exp(<span class="math inline">\(\mu\)</span>)</li>
<li>N.B., the prior of <span class="math inline">\(\mu\)</span> is not on the milliseconds scale, but the log milliseconds scale</li>
</ul></li>
<li><strong><em>the scale, <span class="math inline">\(\sigma\)</span></em></strong>: the standard deviation of the normal distribution of log(<span class="math inline">\(y\)</span>)
<ul>
<li>the standard deviation of a log-normal distribution with <em>location</em> <span class="math inline">\(\mu\)</span> and <em>scale</em> <span class="math inline">\(\sigma\)</span> will be exp(<span class="math inline">\(\frac{\mu + \sigma^2}{2} \times \sqrt{exp(\sigma^2) - 1}\)</span>)</li>
<li>unlike the normal distribution, the spread of the log-normal distribution depends on both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span></li>
</ul></li>
</ul></li>
<li>to understand the meaning of our priors on the millisecond scale, we need to take into account both the priors and the likelihood; this can be done by generating a <strong>prior predictive distribution</strong>
<ul>
<li>we can just exponentiate the samples produced by <code>normal_predictive_distribution()</code></li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>N_samples <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df_spacebar)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>mu_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">11</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>sigma_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>prior_pred_ln <span class="ot">&lt;-</span> <span class="fu">normal_predictive_distribution</span>(</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_samples =</span> mu_samples,</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_samples =</span> sigma_samples,</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">N_obs =</span> N_obs</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rt_pred =</span> <span class="fu">exp</span>(rt_pred))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>we can’t generate negative values anymore (exp(any finite number) &gt; 0)
<ul>
<li>these priors might work in the sense that the model might converge, but it would be better to have <strong>regularizing priors</strong> for the model, such as:</li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{align}
\mu &amp;\sim Normal(6,1.5)\\
\sigma &amp;\sim Normal_+(0,1)
\end{align}
\]</span></p>
<ul>
<li>the prior for <span class="math inline">\(\sigma\)</span> is a truncated distribution
<ul>
<li>although its location is 0, this is not the mean</li>
<li>we can calculate its approximate mean from a large number of random samples of the prior distribution using the function <code>extraDistr::rtnorm()</code>, where the parameter <code>a = 0</code> expresses the fact that the normal distribution is truncated from the left at 0</li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">rtnorm</span>(<span class="dv">100000</span>, <span class="co"># generate n = 100,000</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>            <span class="dv">0</span>, <span class="dv">1</span>,</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">a =</span> <span class="dv">0</span> <span class="co"># truncate at 0</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7983271</code></pre>
</div>
</div>
<ul>
<li>and even before generating the prior predictive distribution, we can calculate the values within which we are 95% sure the expected median of the observations will lie
<ul>
<li>we can do this by looking at what happens at 2 standard deviations away from the mean of the prior, <span class="math inline">\(\mu\)</span>, that is <span class="math inline">\(6 - 2 \times 1.5\)</span> and <span class="math inline">\(6 + 2 \times 1.5\)</span>, and exponentiating these values</li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">c</span>(<span class="at">lower =</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fl">1.5</span>),</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">higher =</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fl">1.5</span>)),</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> lower higher 
  20.1 8103.1 </code></pre>
</div>
</div>
<ul>
<li>so our prior for <span class="math inline">\(\mu\)</span> is still not too informative (these are medians, the actual values generated by the log-normal distribution can be much more spread out)
<ul>
<li>we can now plot the distribution of some representative statistics of the prior preditive distributions using <code>brms</code> to sample from the priors ignoring the <code>rt</code> data, by setting <code>sample_prior = "only"</code></li>
<li>if we want to use <code>brms</code> to generate prior predictive data <em>before</em> collecting the data, we do need to have some non-<code>NA</code> vlaues as the dependent variable, <code>rt</code></li>
<li>setting <code>sample_prior = "only"</code> will ignore the data, but we still need to add it: in this case, we add a vector of 1 as “data”</li>
<li>we need to specify that the familiy is <code>lognormal()</code></li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create place-holder data (for cases where we don't yet have any data but want to check out the prior predictive distribution)</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>df_spacebar_ref <span class="ot">&lt;-</span> df_spacebar <span class="sc">%&gt;%</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rt =</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">n</span>()))</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="co"># now run a model that runs only prior samples</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>fit_prior_press_ln <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar_ref,</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">lognormal</span>(),</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">6</span>, <span class="fl">1.5</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> sigma)</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_prior =</span> <span class="st">"only"</span>, <span class="co"># this is how we tell the model to only produce priors!</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">list</span>(<span class="at">adapt_delta =</span> .<span class="dv">9</span>),</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_prior_press_ln"</span>)</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><p>to avoid the warnings, we need to increase the <code>adapt_delta</code> parameter’s default value from 0.8 to 0.95 to simulate the data</p></li>
<li><p>plot the prior predictive distribution of means with the following code</p>
<ul>
<li>to get a prior predictive distribution, we want to ignore the data, so set <code>prefix = "ppd"</code></li>
<li>IMPORTANTLY, this should be run on a model that had <code>sample_prior = "only"</code>, and therefore ignored the data; otherwise we’d just be plotting the posterior</li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"100"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of means"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-32-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>to plot the distribution of mimimum and maximum values, replace <code>mean</code> with <code>min</code> and <code>max</code></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"100"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of means"</span>)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"min"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"100"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of minimum values"</span>)</span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"10"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb50-30"><a href="#cb50-30" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb50-31"><a href="#cb50-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb50-32"><a href="#cb50-32" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb50-33"><a href="#cb50-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of maximum values"</span>)</span>
<span id="cb50-34"><a href="#cb50-34" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_grid</span>(p1, p2, p3, <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span><span class="dv">1</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-33-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>these plots show that the priors that we are using are still quite uninformative
<ul>
<li>the tails of the prior predictive distributions that correspond to our normal priors (shown above) are even further to the right, reaching more extreme values than for the prior predictive distributions generated by uniform priors</li>
<li>our new priors are still far from representing our prior knowledge</li>
<li>we can use summary statistics to test whether the priors are in a plausible range by defining the extreme data that would be very implausible to ever observe</li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>fit_press_ln <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">lognormal</span>(),</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">6</span>, <span class="fl">1.5</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> sigma)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press_ln"</span>)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>when we look at the summary of the posterior, the parameters are on the log-scale</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>fit_press_ln</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Family: lognormal 
  Links: mu = identity; sigma = identity 
Formula: rt ~ 1 
   Data: df_spacebar (Number of observations: 361) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept     5.12      0.01     5.10     5.13 1.00     3528     2782

Further Distributional Parameters:
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma     0.13      0.01     0.13     0.15 1.00     2971     2621

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<ul>
<li>if we want to know how long it takes to press the space bar in milliseconds, we need to transform the <span class="math inline">\(\mu\)</span> (or <code>Intercept</code> in the model) to milliseconds; we know that the median of the log-normal distribution is exp(<span class="math inline">\(\mu\)</span>), so we do the following to calculate an estimate in milliseconds:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>estimate_ms <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">as_draws_df</span>(fit_press_ln)<span class="sc">$</span>b_Intercept)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>if we want to know the mean and 95% CrI of these samples:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">mean =</span> <span class="fu">mean</span>(estimate_ms), <span class="fu">quantile</span>(estimate_ms, <span class="at">probs =</span> <span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>)))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    mean     2.5%    97.5% 
167.0491 164.6491 169.4007 </code></pre>
</div>
</div>
<ul>
<li>we can now check whether our <em>predicted data sets</em> look similar to the observed data</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press_ln, <span class="at">ndraws =</span> <span class="dv">100</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-38-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>here it seems the posterior predicted data are more similar to the observed data, compared to when we had the normal likelihood
<ul>
<li>but it’s not easy to tell</li>
</ul></li>
<li>another way to examine the extent to which the prediced data looks similar to the observed data: look at the distribution of some summary statistics
<ul>
<li>just like with the prior predictive distributions, examine the distribution of representative summary statistics for the data sets generated by different models</li>
<li>however, unlike with <em>prior</em> predictive distributions, we now have a clear reference: our observed data (which we ignore/don’t have yet for prior predictive distributions)</li>
</ul></li>
<li>we suspect that the normal distribution would generate response times that are too fast (since it’s symmetrical) and that the log-normal distribution may capture the long tail better than the normal model
<ul>
<li>based on this, we compute the distribution of minimum and maximum values for the posterior predictive distributions, adn compare them with the minimum and maximum values respectively in the data</li>
<li>we cn use <code>pp_check()</code> to do this, by using as stat <code>min</code> or <code>max</code> for our models <code>fit_press</code> (normal distribution) and <code>fit_press_ln</code> (log-normal distribution)</li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>ggpubr<span class="sc">::</span><span class="fu">ggarrange</span>(</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># normal min</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pp_check</span>(fit_press, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"min"</span>) <span class="sc">+</span> </span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Normal model (min)"</span>) <span class="sc">+</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># normal max</span></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pp_check</span>(fit_press, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>) <span class="sc">+</span> </span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Normal model (max)"</span>) <span class="sc">+</span></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># log-normal min</span></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pp_check</span>(fit_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"min"</span>) <span class="sc">+</span> </span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Log-normal model (min)"</span>) <span class="sc">+</span></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># log-normal max</span></span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pp_check</span>(fit_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>) <span class="sc">+</span> </span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Log-normal model (max)"</span>) <span class="sc">+</span></span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>  cowplot<span class="sc">::</span><span class="fu">get_legend</span>(<span class="fu">pp_check</span>(fit_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)),</span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span> <span class="dv">2</span>, </span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">heights =</span> <span class="fu">c</span>(.<span class="dv">45</span>,.<span class="dv">45</span>,.<span class="dv">1</span>),</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"A"</span>,<span class="st">"B"</span>,<span class="st">"C"</span>,<span class="st">"D"</span>)</span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-39-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>here we see the log-normal does a slightly better job since the minimum value is contained in the bulk of the log-normal distribution and in the tai of the normal one</li>
</ul>
</section>
</section>
<section id="list-of-most-important-commands" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="list-of-most-important-commands"><span class="header-section-number">4.7</span> List of most important commands</h2>
<ul>
<li>core <code>brms</code> function for fitting models, for generating prior predictive and posterior predictive data</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>fit_press <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">60000</span>), <span class="at">class =</span> Intercept, <span class="at">lb =</span> <span class="dv">0</span>, <span class="at">ub =</span> <span class="dv">60000</span>),</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">2000</span>), <span class="at">class =</span> sigma, <span class="at">lb =</span> <span class="dv">0</span>, <span class="at">ub =</span> <span class="dv">2000</span>)</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">4</span>,</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">2000</span>,</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">warmup =</span> <span class="dv">1000</span>,</span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press"</span>)</span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>  <span class="do">## uncomment for prior predictive:</span></span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a>  <span class="do">## sample_prior = "only",</span></span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a>  <span class="do">## uncomment when dealing with divergent transitions</span></span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a>  <span class="do">## control = list(adapt_delta = .9)</span></span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>extract samples from fitted model:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A draws_df: 1000 iterations, 4 chains, and 5 variables
   b_Intercept sigma Intercept lprior  lp__
1          167    25       167    -19 -1683
2          171    26       171    -19 -1684
3          167    26       167    -19 -1684
4          168    26       168    -19 -1684
5          170    25       170    -19 -1684
6          169    25       169    -19 -1683
7          169    25       169    -19 -1683
8          168    25       168    -19 -1683
9          171    25       171    -19 -1684
10         167    24       167    -19 -1685
# ... with 3990 more draws
# ... hidden reserved variables {'.chain', '.iteration', '.draw'}</code></pre>
</div>
</div>
<ul>
<li>basic plot of posteriors</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_press)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-42-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>plot prior predictive/posterior predictive data</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Posterior predictive check:</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="at">type =</span> <span class="st">"dens_overlay"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-43-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot posterior predictive distribution of statistical summaries:</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>) <span class="sc">+</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Posterior predictive distribution"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-43-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot prior predictive distribution of statistical summaries:</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>,</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Prior predictive distribution"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch3_files/figure-html/unnamed-chunk-43-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="summary" class="level2" data-number="4.8">
<h2 data-number="4.8" class="anchored" data-anchor-id="summary"><span class="header-section-number">4.8</span> Summary</h2>
<ul>
<li>in this chapter we:
<ul>
<li>learned how to fit and interpret a Bayesian model with a normal likelihood</li>
<li>looked at the effect of priors by means of prior predictive distributions and sensitivity analysis</li>
<li>looked at the fit of the posterior by inspecting the posterior predictive distribution (which givees us some idea about the descriptive adequacy of the model)</li>
<li>learned how to fit a Bayesian model with a log-normal likelihood, and how to compare the predictive accuracy of different models</li>
</ul></li>
</ul>
</section>
</section>
<section id="session-info" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Session Info</h1>
<p>Compiled with R version 4.4.0 (2024-04-24) (Puppy Cup) in RStudio version 2023.12.1.402 (Ocean Storm).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>R version 4.4.0 (2024-04-24)
Platform: aarch64-apple-darwin20
Running under: macOS Ventura 13.2.1

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: Europe/Berlin
tzcode source: internal

attached base packages:
[1] grid      stats     graphics  grDevices datasets  utils     methods  
[8] base     

other attached packages:
 [1] rstan_2.32.6         StanHeaders_2.32.7   rootSolve_1.8.2.4   
 [4] cmdstanr_0.7.1       pdftools_3.4.0       cowplot_1.1.3       
 [7] lme4_1.1-35.3        Matrix_1.7-0         gridExtra_2.3       
[10] kableExtra_1.4.0     papaja_0.1.2         tinylabels_0.2.4    
[13] bcogsci_0.0.0.9000   hypr_0.2.8           tictoc_1.2.1        
[16] bayesplot_1.11.1     brms_2.21.0          Rcpp_1.0.12         
[19] bridgesampling_1.1-2 loo_2.7.0            ggplot2_3.5.1       
[22] extraDistr_1.10.0    purrr_1.0.2          tidyr_1.3.1         
[25] dplyr_1.1.4          MASS_7.3-60.2       

loaded via a namespace (and not attached):
 [1] Rdpack_2.6           inline_0.3.19        sandwich_3.1-0      
 [4] rlang_1.1.3          magrittr_2.0.3       multcomp_1.4-25     
 [7] matrixStats_1.3.0    compiler_4.4.0       reshape2_1.4.4      
[10] systemfonts_1.0.6    vctrs_0.6.5          stringr_1.5.1       
[13] pkgconfig_2.0.3      fastmap_1.1.1        backports_1.4.1     
[16] labeling_0.4.3       effectsize_0.8.7     utf8_1.2.4          
[19] rmarkdown_2.26       pracma_2.4.4         ps_1.7.6            
[22] nloptr_2.0.3         xfun_0.43            jsonlite_1.8.8      
[25] broom_1.0.5          parallel_4.4.0       R6_2.5.1            
[28] stringi_1.8.4        car_3.1-2            boot_1.3-30         
[31] estimability_1.5     knitr_1.46           zoo_1.8-12          
[34] parameters_0.21.6    splines_4.4.0        tidyselect_1.2.1    
[37] rstudioapi_0.16.0    abind_1.4-5          yaml_2.3.8          
[40] codetools_0.2-20     processx_3.8.4       pkgbuild_1.4.4      
[43] qpdf_1.3.3           plyr_1.8.9           lattice_0.22-6      
[46] tibble_3.2.1         withr_3.0.0          bayestestR_0.13.2   
[49] askpass_1.2.0        posterior_1.5.0      coda_0.19-4.1       
[52] evaluate_0.23        survival_3.5-8       RcppParallel_5.1.7  
[55] xml2_1.3.6           ggpubr_0.6.0         pillar_1.9.0        
[58] carData_3.0-5        tensorA_0.36.2.1     checkmate_2.3.1     
[61] renv_1.0.7           stats4_4.4.0         insight_0.19.10     
[64] distributional_0.4.0 generics_0.1.3       rprojroot_2.0.4     
[67] rstantools_2.4.0     munsell_0.5.1        scales_1.3.0        
[70] minqa_1.2.6          xtable_1.8-4         glue_1.7.0          
[73] emmeans_1.10.1       tools_4.4.0          ggsignif_0.6.4      
[76] mvtnorm_1.2-4        rbibutils_2.2.16     QuickJSR_1.1.3      
[79] datawizard_0.10.0    colorspace_2.1-0     nlme_3.1-164        
[82] cli_3.6.2            fansi_1.0.6          viridisLite_0.4.2   
[85] svglite_2.1.3        Brobdingnag_1.2-9    gtable_0.3.5        
[88] rstatix_0.7.2        digest_0.6.35        TH.data_1.1-2       
[91] htmlwidgets_1.6.4    farver_2.1.1         htmltools_0.5.8.1   
[94] lifecycle_1.0.4      here_1.0.1          </code></pre>
</div>
</div>
</section>
<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" data-custom-style="Bibliography" role="list" style="display: none">

</div>


<!-- -->

</section>

</main> <!-- /main -->
<script>
var custom_title = document.querySelectorAll('.custom .theorem-title');

for (let i = 0; i < custom_title.length; i++ ) {
   var mod_name = custom_title[i].innerHTML;
   custom_title[i].innerHTML = mod_name.replace("Beispiel", "Aufgabe");
};
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Kopiert");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Kopiert");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../book_notes/ch2.html" class="pagination-link" aria-label="Ch. 2">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Ch. 2</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../book_notes/ch8.html" class="pagination-link" aria-label="Contrast Coding">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Contrast Coding</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Quellcode</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb68" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Ch. 3"</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="fu"># Set up {-}</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, results = "hide", warning=F,message=F,error=F}</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a><span class="in"># set global knit options</span></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::opts_chunk$set(echo = T, # print chunks?</span></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a><span class="in">                      eval = T, # run chunks?</span></span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a><span class="in">                      error = F, # print errors?</span></span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a><span class="in">                      warning = F, # print warnings?</span></span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a><span class="in">                      message = F, # print messages?</span></span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a><span class="in">                      cache = F # cache?; be careful with this!</span></span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a><span class="in">                      )</span></span>
<span id="cb68-16"><a href="#cb68-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-17"><a href="#cb68-17" aria-hidden="true" tabindex="-1"></a><span class="in"># suppress scientific notation</span></span>
<span id="cb68-18"><a href="#cb68-18" aria-hidden="true" tabindex="-1"></a><span class="in">options(scipen=999)</span></span>
<span id="cb68-19"><a href="#cb68-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-20"><a href="#cb68-20" aria-hidden="true" tabindex="-1"></a><span class="in"># play a sound if error encountered</span></span>
<span id="cb68-21"><a href="#cb68-21" aria-hidden="true" tabindex="-1"></a><span class="in">options(error = function() {beepr::beep(9)})</span></span>
<span id="cb68-22"><a href="#cb68-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-23"><a href="#cb68-23" aria-hidden="true" tabindex="-1"></a><span class="in"># load packages</span></span>
<span id="cb68-24"><a href="#cb68-24" aria-hidden="true" tabindex="-1"></a><span class="in">## create list of package names</span></span>
<span id="cb68-25"><a href="#cb68-25" aria-hidden="true" tabindex="-1"></a><span class="in">packages &lt;- c( #"SIN", # this package was removed from the CRAN repository</span></span>
<span id="cb68-26"><a href="#cb68-26" aria-hidden="true" tabindex="-1"></a><span class="in">               "MASS", "dplyr", "tidyr", "purrr", "extraDistr", "ggplot2", "loo", "bridgesampling", "brms", "bayesplot", "tictoc", "hypr", "bcogsci", "papaja", "grid", "kableExtra", "gridExtra", "lme4", "cowplot", "pdftools", "cmdstanr", "rootSolve", "rstan"</span></span>
<span id="cb68-27"><a href="#cb68-27" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb68-28"><a href="#cb68-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-29"><a href="#cb68-29" aria-hidden="true" tabindex="-1"></a><span class="in"># NB: if you haven't already installed bcogsci through devtools, it won't be loaded</span></span>
<span id="cb68-30"><a href="#cb68-30" aria-hidden="true" tabindex="-1"></a><span class="in">## Now load or install &amp; load all</span></span>
<span id="cb68-31"><a href="#cb68-31" aria-hidden="true" tabindex="-1"></a><span class="in">package.check &lt;- lapply(</span></span>
<span id="cb68-32"><a href="#cb68-32" aria-hidden="true" tabindex="-1"></a><span class="in">  packages,</span></span>
<span id="cb68-33"><a href="#cb68-33" aria-hidden="true" tabindex="-1"></a><span class="in">  FUN = function(x) {</span></span>
<span id="cb68-34"><a href="#cb68-34" aria-hidden="true" tabindex="-1"></a><span class="in">    if (!require(x, character.only = TRUE)) {</span></span>
<span id="cb68-35"><a href="#cb68-35" aria-hidden="true" tabindex="-1"></a><span class="in">      install.packages(x, dependencies = TRUE)</span></span>
<span id="cb68-36"><a href="#cb68-36" aria-hidden="true" tabindex="-1"></a><span class="in">      library(x, character.only = TRUE)</span></span>
<span id="cb68-37"><a href="#cb68-37" aria-hidden="true" tabindex="-1"></a><span class="in">    }</span></span>
<span id="cb68-38"><a href="#cb68-38" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb68-39"><a href="#cb68-39" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb68-40"><a href="#cb68-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-41"><a href="#cb68-41" aria-hidden="true" tabindex="-1"></a><span class="in"># this is also required, taken from the textbook</span></span>
<span id="cb68-42"><a href="#cb68-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-43"><a href="#cb68-43" aria-hidden="true" tabindex="-1"></a><span class="in">## Save compiled models:</span></span>
<span id="cb68-44"><a href="#cb68-44" aria-hidden="true" tabindex="-1"></a><span class="in">rstan_options(auto_write = FALSE)</span></span>
<span id="cb68-45"><a href="#cb68-45" aria-hidden="true" tabindex="-1"></a><span class="in">## Parallelize the chains using all the cores:</span></span>
<span id="cb68-46"><a href="#cb68-46" aria-hidden="true" tabindex="-1"></a><span class="in">options(mc.cores = parallel::detectCores())</span></span>
<span id="cb68-47"><a href="#cb68-47" aria-hidden="true" tabindex="-1"></a><span class="in"># To solve some conflicts between packages</span></span>
<span id="cb68-48"><a href="#cb68-48" aria-hidden="true" tabindex="-1"></a><span class="in">select &lt;- dplyr::select</span></span>
<span id="cb68-49"><a href="#cb68-49" aria-hidden="true" tabindex="-1"></a><span class="in">extract &lt;- rstan::extract</span></span>
<span id="cb68-50"><a href="#cb68-50" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-51"><a href="#cb68-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-52"><a href="#cb68-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-53"><a href="#cb68-53" aria-hidden="true" tabindex="-1"></a><span class="fu"># Ch. 3 - Computational Bayesian data analysis</span></span>
<span id="cb68-54"><a href="#cb68-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-55"><a href="#cb68-55" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>for real datasets, it was too cumbersome to do all the math to dertermine posterior distributions</span>
<span id="cb68-56"><a href="#cb68-56" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>thanks to probabilistic programming languages, we can define our models without have to do all the math</span>
<span id="cb68-57"><a href="#cb68-57" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-58"><a href="#cb68-58" aria-hidden="true" tabindex="-1"></a><span class="fu">## Deriving the posterior through sampling</span></span>
<span id="cb68-59"><a href="#cb68-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-60"><a href="#cb68-60" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>recall the example cloze task for *It's raining, I'm going to take the...*, with the 'correct' answer *bus* ('umbrella' in the book but to me 'bus' is the most natural completion)</span>
<span id="cb68-61"><a href="#cb68-61" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>imagine 80 'successes' and 20 'failures'</span>
<span id="cb68-62"><a href="#cb68-62" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>assuming a binomial distribution as the likelihood function, and $Beta(a = 4, b = 4)$ as a prior distribution for the cloze probability</span>
<span id="cb68-63"><a href="#cb68-63" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>if we can obtain samples from the posterior distribution or $\theta$, instead of an analystically derived posterior distribution, given enough samples we will have a good *approximation* of the posterior distribution</span>
<span id="cb68-64"><a href="#cb68-64" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>'*obtain samples*' here means a situation similar to when we use <span class="in">`rbinom`</span> or <span class="in">`rnorm`</span> to obtain samples from a particular distribution</span>
<span id="cb68-65"><a href="#cb68-65" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>assume we used some probabilistic prgramming langauge to obtain 20,000 samples from the posterior distribution of the cloze probability $\theta$</span>
<span id="cb68-66"><a href="#cb68-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-67"><a href="#cb68-67" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bayesian regression models using Stan: brms</span></span>
<span id="cb68-68"><a href="#cb68-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-69"><a href="#cb68-69" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>because of increased computing power and probabilistic programming languages (e.g., WinBUGS, JAGS, R-INLA, pymc3, Turing, Stan), Bayesian statistics is now more popular</span>
<span id="cb68-70"><a href="#cb68-70" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>these languages allow th euser to define models without the complexities of the sampling process</span>
<span id="cb68-71"><a href="#cb68-71" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>however, they require learning a new language as te statistical model must be specified using a specific syntax</span>
<span id="cb68-72"><a href="#cb68-72" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>additionally, some knowledge of the *sampling process* is needed to correctly parametrize the models and avoid convergence issues</span>
<span id="cb68-73"><a href="#cb68-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-74"><a href="#cb68-74" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Bayesian inference in <span class="in">`R`</span> is possible without having the fully specify the model thanks to <span class="in">`stanarm`</span> and <span class="in">`brms`</span> packages</span>
<span id="cb68-75"><a href="#cb68-75" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>both packages provide Bayesian equivalents of R model-fitting functions like <span class="in">`(g)lmer`</span></span>
<span id="cb68-76"><a href="#cb68-76" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>both use Stan as the back-end for estimation and sampling</span>
<span id="cb68-77"><a href="#cb68-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-78"><a href="#cb68-78" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>for this part of the book we will focus on <span class="in">`brms`</span></span>
<span id="cb68-79"><a href="#cb68-79" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>it can be useful for a smooth transition from frequentist models to their Bayesian equivalents</span>
<span id="cb68-80"><a href="#cb68-80" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>it has the added benefit that the Stan code can be inspected via <span class="in">`brms::make_stancode()`</span> and <span class="in">`brms::make_standata()`</span></span>
<span id="cb68-81"><a href="#cb68-81" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>users can then customatize their models or learn from the code produced internally by <span class="in">`brms`</span></span>
<span id="cb68-82"><a href="#cb68-82" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-83"><a href="#cb68-83" aria-hidden="true" tabindex="-1"></a><span class="fu">### A simple linear model: A single subject pressing a button repeatedly</span></span>
<span id="cb68-84"><a href="#cb68-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-85"><a href="#cb68-85" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>imagine having data from a single participant repeatedly pressing the spacebar as fast as possible</span>
<span id="cb68-86"><a href="#cb68-86" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>the data are response times in imilliseconds in each trial; we want to know how long it takes to press a key for this subject</span>
<span id="cb68-87"><a href="#cb68-87" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-88"><a href="#cb68-88" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>let's model the data with thef ollowing assumptions:</span>
<span id="cb68-89"><a href="#cb68-89" aria-hidden="true" tabindex="-1"></a><span class="ss">  1. </span>Tehre is a true (unknown) underlying time, $\mu$ ms, that the subject needs to press the psace bar</span>
<span id="cb68-90"><a href="#cb68-90" aria-hidden="true" tabindex="-1"></a><span class="ss">  2. </span>There is some noise in this process</span>
<span id="cb68-91"><a href="#cb68-91" aria-hidden="true" tabindex="-1"></a><span class="ss">  3. </span>The noise is normally distributed (this assumption is questionable given that response times are generally skewed, we will fix this assumption later)</span>
<span id="cb68-92"><a href="#cb68-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-93"><a href="#cb68-93" aria-hidden="true" tabindex="-1"></a>This means that the likelihood for each observation $n$ will be:</span>
<span id="cb68-94"><a href="#cb68-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-95"><a href="#cb68-95" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-96"><a href="#cb68-96" aria-hidden="true" tabindex="-1"></a>rt_{n} \sim Normal(\mu, \sigma)</span>
<span id="cb68-97"><a href="#cb68-97" aria-hidden="true" tabindex="-1"></a>\tag{3.2}</span>
<span id="cb68-98"><a href="#cb68-98" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-99"><a href="#cb68-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-100"><a href="#cb68-100" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>where $n$ = 1, ..., $N$, and $rt$ is the dependent variable (RTs in ms)</span>
<span id="cb68-101"><a href="#cb68-101" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>the variable $N$ indexes the total number of data points</span>
<span id="cb68-102"><a href="#cb68-102" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>$\mu$ indicates the *location* of the normal distirbution function; the lcoation parameter shifts the distribution left or right on the horizontal axis</span>
<span id="cb68-103"><a href="#cb68-103" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>in the *normal distribution*, the location is also the mean of the distribution</span>
<span id="cb68-104"><a href="#cb68-104" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>$\sigma$ indicates the *scale* of the distribution; as the scale decreases, the distribution gets narrower</span>
<span id="cb68-105"><a href="#cb68-105" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>for the normal distribution, the scale is also the standard deviation</span>
<span id="cb68-106"><a href="#cb68-106" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-107"><a href="#cb68-107" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>this same equation can be expressed as:</span>
<span id="cb68-108"><a href="#cb68-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-109"><a href="#cb68-109" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-110"><a href="#cb68-110" aria-hidden="true" tabindex="-1"></a>rt_n = \mu + \varepsilon \hbox{, where } \varepsilon_n \stackrel{iid}{\sim} \mathit{Normal}(0,\sigma) \tag{3.3} </span>
<span id="cb68-111"><a href="#cb68-111" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-112"><a href="#cb68-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-113"><a href="#cb68-113" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>this version of the model should be understood to mean that each data point $rt_n$ has some variability around a mean value $\mu$, and that variability has standard deviation $\sigma$</span>
<span id="cb68-114"><a href="#cb68-114" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>the term $iid$ ('independent and identically distributed') implies that each data point $rt_n$ is independently generated (i.e., not correlated with any of the other data points), and is coming from the same distribution ($Normal(\mu,\sigma)$)</span>
<span id="cb68-115"><a href="#cb68-115" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-116"><a href="#cb68-116" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Frequentist model**: that will give us the *maximu likelihood estimate* (the sample mean) of the time it takes to press the space bar</span>
<span id="cb68-117"><a href="#cb68-117" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>this owuld be enough ifnmroamtion to write the formular in <span class="in">`R`</span>, <span class="in">`lm(rt ~ 1)`</span></span>
<span id="cb68-118"><a href="#cb68-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-119"><a href="#cb68-119" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Bayesian linear model**: we will also need to define *priors* for the two parameters of our model</span>
<span id="cb68-120"><a href="#cb68-120" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>let's say we know for sure that the time it takes to press a key will be positive and lower than a minute (0-60,000ms), but we don't want to make a commitment regarding which values are more likely</span>
<span id="cb68-121"><a href="#cb68-121" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>we encode what we know about the noise in the task in $\sigma$: this parameter must be positive and we'll assume any value below 2000ms is equally likely; such *flat* or *uniformative* priors are generaly strongly discouraged: it will almost never be the best approximation of what we know</span>
<span id="cb68-122"><a href="#cb68-122" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>let's start with such priors, regardless:</span>
<span id="cb68-123"><a href="#cb68-123" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-124"><a href="#cb68-124" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-125"><a href="#cb68-125" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb68-126"><a href="#cb68-126" aria-hidden="true" tabindex="-1"></a>\mu &amp;\sim \mathit{Uniform}(0, 60000) <span class="sc">\\</span></span>
<span id="cb68-127"><a href="#cb68-127" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \mathit{Uniform}(0, 2000) </span>
<span id="cb68-128"><a href="#cb68-128" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb68-129"><a href="#cb68-129" aria-hidden="true" tabindex="-1"></a>\tag{3.4}</span>
<span id="cb68-130"><a href="#cb68-130" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-131"><a href="#cb68-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-132"><a href="#cb68-132" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>load the data from the <span class="in">`bcogsci`</span> package</span>
<span id="cb68-133"><a href="#cb68-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-136"><a href="#cb68-136" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-137"><a href="#cb68-137" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"df_spacebar"</span>)</span>
<span id="cb68-138"><a href="#cb68-138" aria-hidden="true" tabindex="-1"></a>df_spacebar <span class="ot">&lt;-</span> df_spacebar <span class="sc">%&gt;%</span></span>
<span id="cb68-139"><a href="#cb68-139" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">rt =</span> t)</span>
<span id="cb68-140"><a href="#cb68-140" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_spacebar)</span>
<span id="cb68-141"><a href="#cb68-141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-142"><a href="#cb68-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-143"><a href="#cb68-143" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>plot the data before you do anything else; as we suspected, the data lock a bit (positively) skewed, but let's ignore that for now</span>
<span id="cb68-144"><a href="#cb68-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-147"><a href="#cb68-147" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-148"><a href="#cb68-148" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 6</span></span>
<span id="cb68-149"><a href="#cb68-149" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb68-150"><a href="#cb68-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-151"><a href="#cb68-151" aria-hidden="true" tabindex="-1"></a>df_spacebar <span class="sc">%&gt;%</span></span>
<span id="cb68-152"><a href="#cb68-152" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(rt)) <span class="sc">+</span></span>
<span id="cb68-153"><a href="#cb68-153" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Button-press data"</span>,</span>
<span id="cb68-154"><a href="#cb68-154" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"response times"</span>) <span class="sc">+</span></span>
<span id="cb68-155"><a href="#cb68-155" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>() <span class="sc">+</span></span>
<span id="cb68-156"><a href="#cb68-156" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb68-157"><a href="#cb68-157" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-158"><a href="#cb68-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-159"><a href="#cb68-159" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Specifying the model in `brms`</span></span>
<span id="cb68-160"><a href="#cb68-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-161"><a href="#cb68-161" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>fit the model defined by equations \ref{3.2} and \ref{3.4}</span>
<span id="cb68-162"><a href="#cb68-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-165"><a href="#cb68-165" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-166"><a href="#cb68-166" aria-hidden="true" tabindex="-1"></a>fit_press <span class="ot">&lt;-</span> <span class="fu">brm</span>(</span>
<span id="cb68-167"><a href="#cb68-167" aria-hidden="true" tabindex="-1"></a>  rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb68-168"><a href="#cb68-168" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb68-169"><a href="#cb68-169" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb68-170"><a href="#cb68-170" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb68-171"><a href="#cb68-171" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(</span>
<span id="cb68-172"><a href="#cb68-172" aria-hidden="true" tabindex="-1"></a>      <span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">60000</span>),</span>
<span id="cb68-173"><a href="#cb68-173" aria-hidden="true" tabindex="-1"></a>      <span class="at">class =</span> Intercept, <span class="co"># mean</span></span>
<span id="cb68-174"><a href="#cb68-174" aria-hidden="true" tabindex="-1"></a>      <span class="at">lb =</span> <span class="dv">0</span>,</span>
<span id="cb68-175"><a href="#cb68-175" aria-hidden="true" tabindex="-1"></a>      <span class="at">ub =</span> <span class="dv">60000</span></span>
<span id="cb68-176"><a href="#cb68-176" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb68-177"><a href="#cb68-177" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(</span>
<span id="cb68-178"><a href="#cb68-178" aria-hidden="true" tabindex="-1"></a>      <span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">2000</span>),</span>
<span id="cb68-179"><a href="#cb68-179" aria-hidden="true" tabindex="-1"></a>      <span class="at">class =</span> sigma, <span class="co"># sd</span></span>
<span id="cb68-180"><a href="#cb68-180" aria-hidden="true" tabindex="-1"></a>      <span class="at">lb =</span> <span class="dv">0</span>,</span>
<span id="cb68-181"><a href="#cb68-181" aria-hidden="true" tabindex="-1"></a>      <span class="at">ub =</span> <span class="dv">2000</span></span>
<span id="cb68-182"><a href="#cb68-182" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb68-183"><a href="#cb68-183" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb68-184"><a href="#cb68-184" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">4</span>,</span>
<span id="cb68-185"><a href="#cb68-185" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">2000</span>,</span>
<span id="cb68-186"><a href="#cb68-186" aria-hidden="true" tabindex="-1"></a>  <span class="at">warmup =</span> <span class="dv">1000</span>,</span>
<span id="cb68-187"><a href="#cb68-187" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press_1"</span>)</span>
<span id="cb68-188"><a href="#cb68-188" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-189"><a href="#cb68-189" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-190"><a href="#cb68-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-191"><a href="#cb68-191" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>some differences between this syntax and <span class="in">`lm()`</span>:</span>
<span id="cb68-192"><a href="#cb68-192" aria-hidden="true" tabindex="-1"></a><span class="ss">  1. </span><span class="in">`family = gaussian()`</span> makes it explicity that the underlying likelihood function is a normal distribution</span>
<span id="cb68-193"><a href="#cb68-193" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>this is implicit in <span class="in">`lm()`</span></span>
<span id="cb68-194"><a href="#cb68-194" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>the default for <span class="in">`brms`</span> is <span class="in">`gaussian()`</span></span>
<span id="cb68-195"><a href="#cb68-195" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>other linking function are possible, just like in the <span class="in">`glm()`</span> function</span>
<span id="cb68-196"><a href="#cb68-196" aria-hidden="true" tabindex="-1"></a><span class="ss">  2. </span><span class="in">`prior`</span> takes as argument a vector of priors</span>
<span id="cb68-197"><a href="#cb68-197" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>this is optional, but we should ***always*** explicitly specify each prior; otherwise <span class="in">`brms`</span> will define priors but they may or may not be appropriate</span>
<span id="cb68-198"><a href="#cb68-198" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>this is why we need <span class="in">`lb`</span> (lower bound) and <span class="in">`upper bound`</span> to specify the plausible range of values to sample from in cases where the distribution is restricted (e.g., reaction times cannot be negative, so <span class="in">`lb`</span> must be at least 0)</span>
<span id="cb68-199"><a href="#cb68-199" aria-hidden="true" tabindex="-1"></a><span class="ss">  3. </span><span class="in">`chains`</span> refers to the number of independent runs for sampling</span>
<span id="cb68-200"><a href="#cb68-200" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>default = 4</span>
<span id="cb68-201"><a href="#cb68-201" aria-hidden="true" tabindex="-1"></a><span class="ss">  4. </span><span class="in">`iter`</span> refers to the number of iteratiosn that a sampler makes to sample from the posterior distribution of each paramter</span>
<span id="cb68-202"><a href="#cb68-202" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>default = 2000</span>
<span id="cb68-203"><a href="#cb68-203" aria-hidden="true" tabindex="-1"></a><span class="ss">  5. </span><span class="in">`warmup`</span> refers to the number of iterations from the start of sampling that are eventually discarded</span>
<span id="cb68-204"><a href="#cb68-204" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>default = $\frac{<span class="in">`iter`</span>}{2}$</span>
<span id="cb68-205"><a href="#cb68-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-206"><a href="#cb68-206" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the last 3 options determine the behaviour of the sampling algorithm</span>
<span id="cb68-207"><a href="#cb68-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-208"><a href="#cb68-208" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Sampling and convergence in a nutshell</span></span>
<span id="cb68-209"><a href="#cb68-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-210"><a href="#cb68-210" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>our 4 chains start independently from each other</span>
<span id="cb68-211"><a href="#cb68-211" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>each chain "searches" for samples of the posterior distribution in a multidimensional space, where each parameter corresponds to a dimension</span>
<span id="cb68-212"><a href="#cb68-212" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>the shape of this space is determined by the priors and likelihood</span>
<span id="cb68-213"><a href="#cb68-213" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>chains start at a random location and each iteraton takes one sample each</span>
<span id="cb68-214"><a href="#cb68-214" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>when sampling begins, the samples may or may not belong to the posterior distributions of the parameters; eventually the chains end up in the vicinity of the posterior and from then on the samples will belong to the posterior</span>
<span id="cb68-215"><a href="#cb68-215" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-216"><a href="#cb68-216" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>therefore, when sampling starts the samples from the different chains can be far from each other; at some point they will **converge** and start delivering samples from the posterior distributions</span>
<span id="cb68-217"><a href="#cb68-217" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>typically the default values of <span class="in">`brms`</span> will be sufficient to achieve convergence</span>
<span id="cb68-218"><a href="#cb68-218" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>if not, <span class="in">`brms`</span> (but really <span class="in">`Stan`</span>) will print out warnings with suggestions for fixin the convergence problems</span>
<span id="cb68-219"><a href="#cb68-219" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>this is why we remove the <span class="in">`warmup`</span> samples, because the chains can start far apart and not in the posterior distribution</span>
<span id="cb68-220"><a href="#cb68-220" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>so, if we run 4 chains with 2000 iterations, we will obtain a total of 4000 iterations ($\frac{4 chains * 2000 iterations}{2} = \frac{8000}{2}$)</span>
<span id="cb68-221"><a href="#cb68-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-222"><a href="#cb68-222" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Output of `brms`</span></span>
<span id="cb68-223"><a href="#cb68-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-224"><a href="#cb68-224" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>once the model has ben fit (and assuming we didn't get any warning messages about convergence), we can print out the samples of the posterior distributions using <span class="in">`as_draws_df()`</span></span>
<span id="cb68-225"><a href="#cb68-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-228"><a href="#cb68-228" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-229"><a href="#cb68-229" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press) <span class="sc">%&gt;%</span></span>
<span id="cb68-230"><a href="#cb68-230" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">3</span>)</span>
<span id="cb68-231"><a href="#cb68-231" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-232"><a href="#cb68-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-233"><a href="#cb68-233" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`b_Intercept`</span> corresponds to our $\mu$; we can ignore the last 2 columns</span>
<span id="cb68-234"><a href="#cb68-234" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>plot the density and trace plot of each paramter after warmup:</span>
<span id="cb68-235"><a href="#cb68-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-238"><a href="#cb68-238" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-239"><a href="#cb68-239" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_press)</span>
<span id="cb68-240"><a href="#cb68-240" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-241"><a href="#cb68-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-242"><a href="#cb68-242" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>and print the object with the brms fit</span>
<span id="cb68-243"><a href="#cb68-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-246"><a href="#cb68-246" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-247"><a href="#cb68-247" aria-hidden="true" tabindex="-1"></a>fit_press</span>
<span id="cb68-248"><a href="#cb68-248" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-249"><a href="#cb68-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-250"><a href="#cb68-250" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>or with <span class="in">`posterior_summary()`</span></span>
<span id="cb68-251"><a href="#cb68-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-254"><a href="#cb68-254" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-255"><a href="#cb68-255" aria-hidden="true" tabindex="-1"></a><span class="fu">posterior_summary</span>(fit_press)</span>
<span id="cb68-256"><a href="#cb68-256" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-257"><a href="#cb68-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-258"><a href="#cb68-258" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`Estimate`</span> is just the *mean* of the posterior samples</span>
<span id="cb68-259"><a href="#cb68-259" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`Est.Error`</span> is the *standard deviation* of the posterior</span>
<span id="cb68-260"><a href="#cb68-260" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`CI`</span>s mark the upper and lower bounds of the 95\% *credible intervals*</span>
<span id="cb68-261"><a href="#cb68-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-264"><a href="#cb68-264" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-265"><a href="#cb68-265" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept <span class="sc">%&gt;%</span> </span>
<span id="cb68-266"><a href="#cb68-266" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>()</span>
<span id="cb68-267"><a href="#cb68-267" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-268"><a href="#cb68-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-271"><a href="#cb68-271" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-272"><a href="#cb68-272" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept <span class="sc">%&gt;%</span> </span>
<span id="cb68-273"><a href="#cb68-273" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sd</span>()</span>
<span id="cb68-274"><a href="#cb68-274" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-275"><a href="#cb68-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-278"><a href="#cb68-278" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-279"><a href="#cb68-279" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept <span class="sc">%&gt;%</span></span>
<span id="cb68-280"><a href="#cb68-280" aria-hidden="true" tabindex="-1"></a>  <span class="fu">quantile</span>(<span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">975</span>))</span>
<span id="cb68-281"><a href="#cb68-281" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-282"><a href="#cb68-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-283"><a href="#cb68-283" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>summary also provides:</span>
<span id="cb68-284"><a href="#cb68-284" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span><span class="in">`Rhat`</span>: compares between- and within-chain estimate of each parameter</span>
<span id="cb68-285"><a href="#cb68-285" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>is &gt;1 when chains have not mixed well; we can only rely on the model if the R-hats for *all* parameters are &lt;1.05 (warnings will appear otherwise)</span>
<span id="cb68-286"><a href="#cb68-286" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span><span class="in">`Bulk_ESS`</span>: 'bulk effective sample size' is a measure of sampling efficienty in the bulk of the posterior distribution</span>
<span id="cb68-287"><a href="#cb68-287" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>i.e., the effectice sample size for the mean and median estimates</span>
<span id="cb68-288"><a href="#cb68-288" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span><span class="in">`Tail_ESS`</span>: 'tail effective sample size': the sampling efficiency at the tails of the distribution</span>
<span id="cb68-289"><a href="#cb68-289" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>i.e., the minimum of effective sample sizes for 5\% and 95\% quantiles</span>
<span id="cb68-290"><a href="#cb68-290" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>the number of post-warmup samples is generally lower than the effective sample size, because the samples from the chains are not independent (they are correlated to some extent)</span>
<span id="cb68-291"><a href="#cb68-291" aria-hidden="true" tabindex="-1"></a>, and carry less information about the posterior distribution in comparison to *independent* samples</span>
<span id="cb68-292"><a href="#cb68-292" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>very low sample size indicates sampling problems (and will produce warnings) and in general appear when chains are not properly mixed</span>
<span id="cb68-293"><a href="#cb68-293" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>as a rule of thumb, a minimum of 400 effective sample size is required for statistical summaries</span>
<span id="cb68-294"><a href="#cb68-294" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-295"><a href="#cb68-295" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we wee our model fits without problems, and we get some posterior distribution for our parameters, but we should ask the following questions:</span>
<span id="cb68-296"><a href="#cb68-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-297"><a href="#cb68-297" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>What informationa re the priors encoding? Do the priors make sense?</span>
<span id="cb68-298"><a href="#cb68-298" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Does the likelihood assumed int he model make sense for the data?</span>
<span id="cb68-299"><a href="#cb68-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-300"><a href="#cb68-300" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>to answer these questions we can look at the *prior* and *posterior distributions* and we can do sensitivity analyses</span>
<span id="cb68-301"><a href="#cb68-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-302"><a href="#cb68-302" aria-hidden="true" tabindex="-1"></a><span class="fu">## Prior predictive distribution</span></span>
<span id="cb68-303"><a href="#cb68-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-304"><a href="#cb68-304" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we had the following priors in our linear model:</span>
<span id="cb68-305"><a href="#cb68-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-306"><a href="#cb68-306" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-307"><a href="#cb68-307" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb68-308"><a href="#cb68-308" aria-hidden="true" tabindex="-1"></a>\mu &amp;\sim \mathit{Uniform}(0, 60000) <span class="sc">\\</span></span>
<span id="cb68-309"><a href="#cb68-309" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \mathit{Uniform}(0, 2000) </span>
<span id="cb68-310"><a href="#cb68-310" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb68-311"><a href="#cb68-311" aria-hidden="true" tabindex="-1"></a>\tag{3.5}</span>
<span id="cb68-312"><a href="#cb68-312" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-313"><a href="#cb68-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-314"><a href="#cb68-314" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>these priors encode assumptions about our data</span>
<span id="cb68-315"><a href="#cb68-315" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>to understand these assumptions, we are going to generate data from the model</span>
<span id="cb68-316"><a href="#cb68-316" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>such data, which is generated entirely by the *prior distributions*, is called the **prior predictive distribution**</span>
<span id="cb68-317"><a href="#cb68-317" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>generating prior predictive distributions repeatedly helps us to check whether the priors make sense; we want to know whether the priors generate realistic-looking data</span>
<span id="cb68-318"><a href="#cb68-318" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-319"><a href="#cb68-319" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>to do this, repeat the following many times:</span>
<span id="cb68-320"><a href="#cb68-320" aria-hidden="true" tabindex="-1"></a><span class="ss">  1. </span>Tae one sample from each of the priors</span>
<span id="cb68-321"><a href="#cb68-321" aria-hidden="true" tabindex="-1"></a><span class="ss">  2. </span>Plug those samples into the porbability density/mass function used as the likelihood int he model to generate a dataset $y_{pred_1}, ..., y_{pred_n}$</span>
<span id="cb68-322"><a href="#cb68-322" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>each sample is an imaginary or potential data set</span>
<span id="cb68-323"><a href="#cb68-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-324"><a href="#cb68-324" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>create a function that does this:</span>
<span id="cb68-325"><a href="#cb68-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-328"><a href="#cb68-328" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-329"><a href="#cb68-329" aria-hidden="true" tabindex="-1"></a>normal_predictive_distribution <span class="ot">&lt;-</span></span>
<span id="cb68-330"><a href="#cb68-330" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(mu_samples, sigma_samples, N_obs) {</span>
<span id="cb68-331"><a href="#cb68-331" aria-hidden="true" tabindex="-1"></a>    <span class="co"># empty data frame with headers:</span></span>
<span id="cb68-332"><a href="#cb68-332" aria-hidden="true" tabindex="-1"></a>    df_pred <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb68-333"><a href="#cb68-333" aria-hidden="true" tabindex="-1"></a>      <span class="at">trialn =</span> <span class="fu">numeric</span>(<span class="dv">0</span>),</span>
<span id="cb68-334"><a href="#cb68-334" aria-hidden="true" tabindex="-1"></a>      <span class="at">rt_pred =</span> <span class="fu">numeric</span>(<span class="dv">0</span>),</span>
<span id="cb68-335"><a href="#cb68-335" aria-hidden="true" tabindex="-1"></a>      <span class="at">iter =</span> <span class="fu">numeric</span>(<span class="dv">0</span>)</span>
<span id="cb68-336"><a href="#cb68-336" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb68-337"><a href="#cb68-337" aria-hidden="true" tabindex="-1"></a>    <span class="co"># i iterates from 1 to the length of mu_samples,</span></span>
<span id="cb68-338"><a href="#cb68-338" aria-hidden="true" tabindex="-1"></a>    <span class="co"># which we assume is identical to</span></span>
<span id="cb68-339"><a href="#cb68-339" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the length of the sigma_samples:</span></span>
<span id="cb68-340"><a href="#cb68-340" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_along</span>(mu_samples)) {</span>
<span id="cb68-341"><a href="#cb68-341" aria-hidden="true" tabindex="-1"></a>      mu <span class="ot">&lt;-</span> mu_samples[i]</span>
<span id="cb68-342"><a href="#cb68-342" aria-hidden="true" tabindex="-1"></a>      sigma <span class="ot">&lt;-</span> sigma_samples[i]</span>
<span id="cb68-343"><a href="#cb68-343" aria-hidden="true" tabindex="-1"></a>      df_pred <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb68-344"><a href="#cb68-344" aria-hidden="true" tabindex="-1"></a>        df_pred,</span>
<span id="cb68-345"><a href="#cb68-345" aria-hidden="true" tabindex="-1"></a>        <span class="fu">tibble</span>(</span>
<span id="cb68-346"><a href="#cb68-346" aria-hidden="true" tabindex="-1"></a>          <span class="at">trialn =</span> <span class="fu">seq_len</span>(N_obs), <span class="co"># 1, 2,... N_obs</span></span>
<span id="cb68-347"><a href="#cb68-347" aria-hidden="true" tabindex="-1"></a>          <span class="at">rt_pred =</span> <span class="fu">rnorm</span>(N_obs, mu, sigma),</span>
<span id="cb68-348"><a href="#cb68-348" aria-hidden="true" tabindex="-1"></a>          <span class="at">iter =</span> i</span>
<span id="cb68-349"><a href="#cb68-349" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb68-350"><a href="#cb68-350" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb68-351"><a href="#cb68-351" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb68-352"><a href="#cb68-352" aria-hidden="true" tabindex="-1"></a>    df_pred</span>
<span id="cb68-353"><a href="#cb68-353" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb68-354"><a href="#cb68-354" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-355"><a href="#cb68-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-356"><a href="#cb68-356" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the code below produces 1000 samples of the prior predictive distribution of the model we defined for <span class="in">`fit_press`</span> from the <span class="in">`df_spacebar`</span> data, that had 361 trials</span>
<span id="cb68-357"><a href="#cb68-357" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>this code will produce 361,000 predicted values (361 observations x 1000 simulations)</span>
<span id="cb68-358"><a href="#cb68-358" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>we could also use the option <span class="in">`sample_prior = "only"`</span> in our <span class="in">`brms`</span> model, but it still depends on Stam's sampler which uses Hamiltonian Monte Carlo, and can fail to converge especially with uninformative priors</span>
<span id="cb68-359"><a href="#cb68-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-362"><a href="#cb68-362" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-363"><a href="#cb68-363" aria-hidden="true" tabindex="-1"></a>N_samples <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb68-364"><a href="#cb68-364" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df_spacebar)</span>
<span id="cb68-365"><a href="#cb68-365" aria-hidden="true" tabindex="-1"></a>mu_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">60000</span>)</span>
<span id="cb68-366"><a href="#cb68-366" aria-hidden="true" tabindex="-1"></a>sigma_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">2000</span>)</span>
<span id="cb68-367"><a href="#cb68-367" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb68-368"><a href="#cb68-368" aria-hidden="true" tabindex="-1"></a>prior_pred <span class="ot">&lt;-</span> <span class="fu">normal_predictive_distribution</span>(</span>
<span id="cb68-369"><a href="#cb68-369" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_samples =</span> mu_samples,</span>
<span id="cb68-370"><a href="#cb68-370" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_samples =</span> sigma_samples,</span>
<span id="cb68-371"><a href="#cb68-371" aria-hidden="true" tabindex="-1"></a>  <span class="at">N_obs =</span> N_obs</span>
<span id="cb68-372"><a href="#cb68-372" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-373"><a href="#cb68-373" aria-hidden="true" tabindex="-1"></a><span class="fu">toc</span>()</span>
<span id="cb68-374"><a href="#cb68-374" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-375"><a href="#cb68-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-378"><a href="#cb68-378" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-379"><a href="#cb68-379" aria-hidden="true" tabindex="-1"></a>prior_pred</span>
<span id="cb68-380"><a href="#cb68-380" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-381"><a href="#cb68-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-382"><a href="#cb68-382" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb68-383"><a href="#cb68-383" aria-hidden="true" tabindex="-1"></a><span class="fu">## Box 3.1: A more efficint prior predictive distribution function</span></span>
<span id="cb68-384"><a href="#cb68-384" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>alternatively, we could use the <span class="in">`purr::map2_dfr()`</span> functions as below, which would run a bit faster:</span>
<span id="cb68-385"><a href="#cb68-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-386"><a href="#cb68-386" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, eval = F}</span></span>
<span id="cb68-387"><a href="#cb68-387" aria-hidden="true" tabindex="-1"></a><span class="in">library(purrr)</span></span>
<span id="cb68-388"><a href="#cb68-388" aria-hidden="true" tabindex="-1"></a><span class="in"># Define the function:</span></span>
<span id="cb68-389"><a href="#cb68-389" aria-hidden="true" tabindex="-1"></a><span class="in">normal_predictive_distribution &lt;- function(mu_samples,</span></span>
<span id="cb68-390"><a href="#cb68-390" aria-hidden="true" tabindex="-1"></a><span class="in">                                           sigma_samples,</span></span>
<span id="cb68-391"><a href="#cb68-391" aria-hidden="true" tabindex="-1"></a><span class="in">                                           N_obs) {</span></span>
<span id="cb68-392"><a href="#cb68-392" aria-hidden="true" tabindex="-1"></a><span class="in">  map2_dfr(mu_samples, sigma_samples, function(mu, sigma) {</span></span>
<span id="cb68-393"><a href="#cb68-393" aria-hidden="true" tabindex="-1"></a><span class="in">    tibble(</span></span>
<span id="cb68-394"><a href="#cb68-394" aria-hidden="true" tabindex="-1"></a><span class="in">      trialn = seq_len(N_obs),</span></span>
<span id="cb68-395"><a href="#cb68-395" aria-hidden="true" tabindex="-1"></a><span class="in">      rt_pred = rnorm(N_obs, mu, sigma)</span></span>
<span id="cb68-396"><a href="#cb68-396" aria-hidden="true" tabindex="-1"></a><span class="in">    )</span></span>
<span id="cb68-397"><a href="#cb68-397" aria-hidden="true" tabindex="-1"></a><span class="in">  }, .id = "iter") %&gt;%</span></span>
<span id="cb68-398"><a href="#cb68-398" aria-hidden="true" tabindex="-1"></a><span class="in">    # .id is always a string and</span></span>
<span id="cb68-399"><a href="#cb68-399" aria-hidden="true" tabindex="-1"></a><span class="in">    # needs to be converted to a number</span></span>
<span id="cb68-400"><a href="#cb68-400" aria-hidden="true" tabindex="-1"></a><span class="in">    mutate(iter = as.numeric(iter))</span></span>
<span id="cb68-401"><a href="#cb68-401" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb68-402"><a href="#cb68-402" aria-hidden="true" tabindex="-1"></a><span class="in"># Test the timing:</span></span>
<span id="cb68-403"><a href="#cb68-403" aria-hidden="true" tabindex="-1"></a><span class="in">tic()</span></span>
<span id="cb68-404"><a href="#cb68-404" aria-hidden="true" tabindex="-1"></a><span class="in">prior_pred &lt;- normal_predictive_distribution(</span></span>
<span id="cb68-405"><a href="#cb68-405" aria-hidden="true" tabindex="-1"></a><span class="in">  mu_samples = mu_samples,</span></span>
<span id="cb68-406"><a href="#cb68-406" aria-hidden="true" tabindex="-1"></a><span class="in">  sigma_samples = sigma_samples,</span></span>
<span id="cb68-407"><a href="#cb68-407" aria-hidden="true" tabindex="-1"></a><span class="in">  N_obs = N_obs</span></span>
<span id="cb68-408"><a href="#cb68-408" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb68-409"><a href="#cb68-409" aria-hidden="true" tabindex="-1"></a><span class="in">toc()</span></span>
<span id="cb68-410"><a href="#cb68-410" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-411"><a href="#cb68-411" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb68-412"><a href="#cb68-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-413"><a href="#cb68-413" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>let's look at the first 18 samples of the *prior predictive distribution*</span>
<span id="cb68-414"><a href="#cb68-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-417"><a href="#cb68-417" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-418"><a href="#cb68-418" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 6</span></span>
<span id="cb68-419"><a href="#cb68-419" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-samples18</span></span>
<span id="cb68-420"><a href="#cb68-420" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "18 samples"</span></span>
<span id="cb68-421"><a href="#cb68-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-422"><a href="#cb68-422" aria-hidden="true" tabindex="-1"></a>prior_pred <span class="sc">%&gt;%</span></span>
<span id="cb68-423"><a href="#cb68-423" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(iter <span class="sc">&lt;=</span> <span class="dv">18</span>) <span class="sc">%&gt;%</span></span>
<span id="cb68-424"><a href="#cb68-424" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(rt_pred)) <span class="sc">+</span></span>
<span id="cb68-425"><a href="#cb68-425" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"18 samples"</span>,</span>
<span id="cb68-426"><a href="#cb68-426" aria-hidden="true" tabindex="-1"></a>      <span class="at">x=</span><span class="st">"predicted rt (ms)"</span>) <span class="sc">+</span></span>
<span id="cb68-427"><a href="#cb68-427" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..)) <span class="sc">+</span></span>
<span id="cb68-428"><a href="#cb68-428" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-429"><a href="#cb68-429" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb68-430"><a href="#cb68-430" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.x =</span></span>
<span id="cb68-431"><a href="#cb68-431" aria-hidden="true" tabindex="-1"></a>      <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">40</span>, <span class="at">vjust =</span> <span class="dv">1</span>, <span class="at">hjust =</span> <span class="dv">1</span>, <span class="at">size =</span> <span class="dv">14</span>)</span>
<span id="cb68-432"><a href="#cb68-432" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb68-433"><a href="#cb68-433" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(</span>
<span id="cb68-434"><a href="#cb68-434" aria-hidden="true" tabindex="-1"></a>    <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.0005</span>),</span>
<span id="cb68-435"><a href="#cb68-435" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.00025</span>, <span class="fl">0.0005</span>), <span class="at">name =</span> <span class="st">"density"</span></span>
<span id="cb68-436"><a href="#cb68-436" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb68-437"><a href="#cb68-437" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>iter, <span class="at">ncol =</span> <span class="dv">3</span>)</span>
<span id="cb68-438"><a href="#cb68-438" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-439"><a href="#cb68-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-440"><a href="#cb68-440" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Figure \@fig-samples18 shows prior data sets that are not realistic: the data shows RT distributions are symmetrical (and we know they are generally right-skewed)</span>
<span id="cb68-441"><a href="#cb68-441" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>worse, a few have *negative* RT values</span>
<span id="cb68-442"><a href="#cb68-442" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so, our priors led to unrealistic values in our prior predictive distribution</span>
<span id="cb68-443"><a href="#cb68-443" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>so our priors weren't very useful</span>
<span id="cb68-444"><a href="#cb68-444" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so, what priors should we have used?</span>
<span id="cb68-445"><a href="#cb68-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-446"><a href="#cb68-446" aria-hidden="true" tabindex="-1"></a><span class="fu">## The influence of priors: sensitivity analysis</span></span>
<span id="cb68-447"><a href="#cb68-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-448"><a href="#cb68-448" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>there are 4 main classes of priors in this book</span>
<span id="cb68-449"><a href="#cb68-449" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>but there is no fixed nomenclature for these kind of priors, there's no current naming convention in the field</span>
<span id="cb68-450"><a href="#cb68-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-451"><a href="#cb68-451" aria-hidden="true" tabindex="-1"></a><span class="fu">### Flat, uninformative priors</span></span>
<span id="cb68-452"><a href="#cb68-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-453"><a href="#cb68-453" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the idea behind uninformative priors is to let the data 'speak fo ritself' and to not bias the statistical inference iwth 'subjective priors</span>
<span id="cb68-454"><a href="#cb68-454" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>issues with this approach:</span>
<span id="cb68-455"><a href="#cb68-455" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>the prior is as subjective as the likelihood, and different choices of likelihood might have a stronger mpace on the posterior than choice of priors</span>
<span id="cb68-456"><a href="#cb68-456" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>uninformative priors are in general unrealistic and give equal weight to all values within the support of the prior distribution</span>
<span id="cb68-457"><a href="#cb68-457" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>unifnromative priors m ake the sampling slower and might lead to convergence problems</span>
<span id="cb68-458"><a href="#cb68-458" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>it is not always clear which parametrization of a given distribution the flat priors should be assigned to</span>
<span id="cb68-459"><a href="#cb68-459" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-460"><a href="#cb68-460" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>in our space bar button press example, and uniformative prior would be:</span>
<span id="cb68-461"><a href="#cb68-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-462"><a href="#cb68-462" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-463"><a href="#cb68-463" aria-hidden="true" tabindex="-1"></a>\mu \sim Uniform(-10^{20}, 10^{20})</span>
<span id="cb68-464"><a href="#cb68-464" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-465"><a href="#cb68-465" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>this is a strange prior because it's on them millisecond scale, and allows for impossibly large positive values, as well as negative values which are not possible at all</span>
<span id="cb68-466"><a href="#cb68-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-467"><a href="#cb68-467" aria-hidden="true" tabindex="-1"></a><span class="fu">### Regularising priors</span></span>
<span id="cb68-468"><a href="#cb68-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-469"><a href="#cb68-469" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>used when we don't have *much* prior information or knowledge</span>
<span id="cb68-470"><a href="#cb68-470" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>sometimes called *weakly informative* or *mildly informative*</span>
<span id="cb68-471"><a href="#cb68-471" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>these are priors that down-weight extreme values (they provide *regularization*)</span>
<span id="cb68-472"><a href="#cb68-472" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>usually not very informative, and mostly let the likelihood dominate in determining the posteriors</span>
<span id="cb68-473"><a href="#cb68-473" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>these are **theory-neutral** priors; they do not bias the parameters to values spported by any prior belief or theory</span>
<span id="cb68-474"><a href="#cb68-474" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>these priors help stabilize computation</span>
<span id="cb68-475"><a href="#cb68-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-476"><a href="#cb68-476" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>in our button press example, a regularizing prior owuld be</span>
<span id="cb68-477"><a href="#cb68-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-478"><a href="#cb68-478" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-479"><a href="#cb68-479" aria-hidden="true" tabindex="-1"></a>\mu \sim Normal_+(0,1000)</span>
<span id="cb68-480"><a href="#cb68-480" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-481"><a href="#cb68-481" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>where $Normal_+$ indicates that the normal distribution is truncated at 0ms (i.e., is cut off at 0, so no negative values are possible)</span>
<span id="cb68-482"><a href="#cb68-482" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>this is regularizing because it rules out negative button-pressing times and down-weights extreme values over 2000ms</span>
<span id="cb68-483"><a href="#cb68-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-484"><a href="#cb68-484" aria-hidden="true" tabindex="-1"></a><span class="fu">### Principled priors</span></span>
<span id="cb68-485"><a href="#cb68-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-486"><a href="#cb68-486" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>these priors encode all (or most of) the theory-neutral information</span>
<span id="cb68-487"><a href="#cb68-487" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>one generally knows what one's data do and do not look like, it is possible to build priors that truly reflect the properties of potential data sets</span>
<span id="cb68-488"><a href="#cb68-488" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>in our button press example, a principled prior could be</span>
<span id="cb68-489"><a href="#cb68-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-490"><a href="#cb68-490" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-491"><a href="#cb68-491" aria-hidden="true" tabindex="-1"></a>\mu \sim Normal_+(250,100)</span>
<span id="cb68-492"><a href="#cb68-492" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-493"><a href="#cb68-493" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>it is not overly restrictive, but represents a guess about plausible button-pressing tiems</span>
<span id="cb68-494"><a href="#cb68-494" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>*prior predictive checks* using principled priors should produce realisitic distributions of the dependent variable</span>
<span id="cb68-495"><a href="#cb68-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-496"><a href="#cb68-496" aria-hidden="true" tabindex="-1"></a><span class="fu">### Informative priors</span></span>
<span id="cb68-497"><a href="#cb68-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-498"><a href="#cb68-498" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>for cases wehre a lot of prior knowledge exists, and not much data</span>
<span id="cb68-499"><a href="#cb68-499" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>unless there is a *very* good reason to use informative priors, it is not a good idea to let the priors have too much influence on the posterior</span>
<span id="cb68-500"><a href="#cb68-500" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>e.g., investigating a language-imparied population from which we can't get many subjects, but a lot of previous published work exists on the topic</span>
<span id="cb68-501"><a href="#cb68-501" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-502"><a href="#cb68-502" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>in our button press data, an informative prior could be based on the meta-analysis of previously published or existing data, or the result of prior elicitation from an expert on the topic under investigation</span>
<span id="cb68-503"><a href="#cb68-503" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>e.g., the following prior:</span>
<span id="cb68-504"><a href="#cb68-504" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-505"><a href="#cb68-505" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-506"><a href="#cb68-506" aria-hidden="true" tabindex="-1"></a>\mu \sim Normal_+(200,20)</span>
<span id="cb68-507"><a href="#cb68-507" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-508"><a href="#cb68-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-509"><a href="#cb68-509" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>this will have some influence ont he posterior for $\mu$, especially when one has relatively sparse data</span>
<span id="cb68-510"><a href="#cb68-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-511"><a href="#cb68-511" aria-hidden="true" tabindex="-1"></a><span class="fu">## Re-visiting the button-press example with different priors</span></span>
<span id="cb68-512"><a href="#cb68-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-513"><a href="#cb68-513" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>what would happen if even wider priors were used for the model we defined earlier?</span>
<span id="cb68-514"><a href="#cb68-514" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>suppose every mean between -10^6 and 10^6 is assumed to be equally likely</span>
<span id="cb68-515"><a href="#cb68-515" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>this is clearly unrealistic and nonsensical; we don't expect negative values</span>
<span id="cb68-516"><a href="#cb68-516" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>for the sd, we could assume any value between 0 and 10^6 is equally likely; the likelihood remains unchanged</span>
<span id="cb68-517"><a href="#cb68-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-518"><a href="#cb68-518" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-519"><a href="#cb68-519" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb68-520"><a href="#cb68-520" aria-hidden="true" tabindex="-1"></a>\mu &amp;\sim \mathit{Uniform}(-10^{6}, 10^{6}) <span class="sc">\\</span></span>
<span id="cb68-521"><a href="#cb68-521" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \mathit{Uniform}(0,  10^{6}) </span>
<span id="cb68-522"><a href="#cb68-522" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb68-523"><a href="#cb68-523" aria-hidden="true" tabindex="-1"></a>\tag{3.6}</span>
<span id="cb68-524"><a href="#cb68-524" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-525"><a href="#cb68-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-528"><a href="#cb68-528" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-529"><a href="#cb68-529" aria-hidden="true" tabindex="-1"></a><span class="co"># The default settings are used when they are not set explicitly:</span></span>
<span id="cb68-530"><a href="#cb68-530" aria-hidden="true" tabindex="-1"></a><span class="co"># 4 chains, with half of the iterations (set as 3000) as warmup.</span></span>
<span id="cb68-531"><a href="#cb68-531" aria-hidden="true" tabindex="-1"></a>fit_press_unif <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb68-532"><a href="#cb68-532" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb68-533"><a href="#cb68-533" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb68-534"><a href="#cb68-534" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb68-535"><a href="#cb68-535" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="sc">-</span><span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>, <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>),</span>
<span id="cb68-536"><a href="#cb68-536" aria-hidden="true" tabindex="-1"></a>          <span class="at">class =</span> Intercept,</span>
<span id="cb68-537"><a href="#cb68-537" aria-hidden="true" tabindex="-1"></a>          <span class="at">lb =</span> <span class="sc">-</span><span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>,</span>
<span id="cb68-538"><a href="#cb68-538" aria-hidden="true" tabindex="-1"></a>          <span class="at">ub =</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>),</span>
<span id="cb68-539"><a href="#cb68-539" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>),</span>
<span id="cb68-540"><a href="#cb68-540" aria-hidden="true" tabindex="-1"></a>          <span class="at">class =</span> sigma,</span>
<span id="cb68-541"><a href="#cb68-541" aria-hidden="true" tabindex="-1"></a>          <span class="at">lb =</span> <span class="dv">0</span>,</span>
<span id="cb68-542"><a href="#cb68-542" aria-hidden="true" tabindex="-1"></a>          <span class="at">ub =</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>)</span>
<span id="cb68-543"><a href="#cb68-543" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb68-544"><a href="#cb68-544" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">3000</span>,</span>
<span id="cb68-545"><a href="#cb68-545" aria-hidden="true" tabindex="-1"></a>  <span class="co"># the following needed to be changed to achieve convergence</span></span>
<span id="cb68-546"><a href="#cb68-546" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">list</span>(<span class="at">adapt_delta =</span> .<span class="dv">99</span>,</span>
<span id="cb68-547"><a href="#cb68-547" aria-hidden="true" tabindex="-1"></a>                 <span class="at">max_treedepth =</span> <span class="dv">15</span>),</span>
<span id="cb68-548"><a href="#cb68-548" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press_unif"</span>)</span>
<span id="cb68-549"><a href="#cb68-549" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-550"><a href="#cb68-550" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-551"><a href="#cb68-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-552"><a href="#cb68-552" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>even with these priors, the output of the model is virtually dientical to the previous one</span>
<span id="cb68-553"><a href="#cb68-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-556"><a href="#cb68-556" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-557"><a href="#cb68-557" aria-hidden="true" tabindex="-1"></a>fit_press_unif</span>
<span id="cb68-558"><a href="#cb68-558" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-559"><a href="#cb68-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-562"><a href="#cb68-562" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-563"><a href="#cb68-563" aria-hidden="true" tabindex="-1"></a>fit_press</span>
<span id="cb68-564"><a href="#cb68-564" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-565"><a href="#cb68-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-566"><a href="#cb68-566" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>what about very informative priors?</span>
<span id="cb68-567"><a href="#cb68-567" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>assume the mean values very close to 400ms are the most likely, and that the sd of RTs is very close to 100ms</span>
<span id="cb68-568"><a href="#cb68-568" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>this is not very sensical, 200ms seems like a more realistic mean for button-press</span>
<span id="cb68-569"><a href="#cb68-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-570"><a href="#cb68-570" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-571"><a href="#cb68-571" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb68-572"><a href="#cb68-572" aria-hidden="true" tabindex="-1"></a>\mu &amp;\sim \mathit{Normal}(400, 10) <span class="sc">\\</span></span>
<span id="cb68-573"><a href="#cb68-573" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \mathit{Normal}_+(100, 10) \end{aligned}</span>
<span id="cb68-574"><a href="#cb68-574" aria-hidden="true" tabindex="-1"></a>\tag{3.7}</span>
<span id="cb68-575"><a href="#cb68-575" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-576"><a href="#cb68-576" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>if we refit our model:</span>
<span id="cb68-577"><a href="#cb68-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-580"><a href="#cb68-580" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-581"><a href="#cb68-581" aria-hidden="true" tabindex="-1"></a>fit_press_inf <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb68-582"><a href="#cb68-582" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb68-583"><a href="#cb68-583" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb68-584"><a href="#cb68-584" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb68-585"><a href="#cb68-585" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">400</span>, <span class="dv">10</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb68-586"><a href="#cb68-586" aria-hidden="true" tabindex="-1"></a>    <span class="co"># brms knows that SDs need to be bounded</span></span>
<span id="cb68-587"><a href="#cb68-587" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to exclude values below zero:</span></span>
<span id="cb68-588"><a href="#cb68-588" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">100</span>, <span class="dv">10</span>), <span class="at">class =</span> sigma)</span>
<span id="cb68-589"><a href="#cb68-589" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb68-590"><a href="#cb68-590" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press_inf"</span>)</span>
<span id="cb68-591"><a href="#cb68-591" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-592"><a href="#cb68-592" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-593"><a href="#cb68-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-594"><a href="#cb68-594" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we see that the likelihood mostly dominates again, and the new posterior means and CrIs are only shifted by a few milliseconds when these unrealistic but informative priors are used:</span>
<span id="cb68-595"><a href="#cb68-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-598"><a href="#cb68-598" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-599"><a href="#cb68-599" aria-hidden="true" tabindex="-1"></a>fit_press_inf</span>
<span id="cb68-600"><a href="#cb68-600" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-601"><a href="#cb68-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-602"><a href="#cb68-602" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>as a final example of sensitivity analysis, let's choose some *principled* priors</span>
<span id="cb68-603"><a href="#cb68-603" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>assuming we have some prior experience, let's suppose the mean RT is expected to be arround 200ms, with a 95\% probability of the mean ranging from 0 to 400ms</span>
<span id="cb68-604"><a href="#cb68-604" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>this uncertainty is perhaps unreasonably large, but one might want to allow a bit more uncertainty than one really thinks is reasonable (sometimes called *Cromwell's rules*)</span>
<span id="cb68-605"><a href="#cb68-605" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>let's then decide on the prior $Normal(200,100)$</span>
<span id="cb68-606"><a href="#cb68-606" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>with just a single participnt and a simple task, the residual standard deviation $\sigma$ shouldn't be very large: let's settle on a location of 50ms for a trucnated normal distribution, but still allow for relatively large uncertainty:</span>
<span id="cb68-607"><a href="#cb68-607" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-608"><a href="#cb68-608" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-609"><a href="#cb68-609" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb68-610"><a href="#cb68-610" aria-hidden="true" tabindex="-1"></a>\mu &amp;\sim \mathit{Normal}(200, 100) <span class="sc">\\</span></span>
<span id="cb68-611"><a href="#cb68-611" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \mathit{Normal}_+(50, 50) </span>
<span id="cb68-612"><a href="#cb68-612" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb68-613"><a href="#cb68-613" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-614"><a href="#cb68-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-617"><a href="#cb68-617" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-618"><a href="#cb68-618" aria-hidden="true" tabindex="-1"></a>fit_press_prin <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb68-619"><a href="#cb68-619" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb68-620"><a href="#cb68-620" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb68-621"><a href="#cb68-621" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb68-622"><a href="#cb68-622" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">200</span>, <span class="dv">100</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb68-623"><a href="#cb68-623" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">50</span>, <span class="dv">50</span>), <span class="at">class =</span> sigma)</span>
<span id="cb68-624"><a href="#cb68-624" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb68-625"><a href="#cb68-625" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press_prin"</span>)</span>
<span id="cb68-626"><a href="#cb68-626" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-627"><a href="#cb68-627" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-628"><a href="#cb68-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-629"><a href="#cb68-629" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>again, the estimates are virtually the same as before:</span>
<span id="cb68-630"><a href="#cb68-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-633"><a href="#cb68-633" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-634"><a href="#cb68-634" aria-hidden="true" tabindex="-1"></a>fit_press_prin</span>
<span id="cb68-635"><a href="#cb68-635" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-636"><a href="#cb68-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-637"><a href="#cb68-637" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>these examples do not mean priors *never* matter</span>
<span id="cb68-638"><a href="#cb68-638" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>when there is enough data, the likelihood will dominate in determing the posterior distributions</span>
<span id="cb68-639"><a href="#cb68-639" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>what constitutes 'enough' data is also a function of the complexity of the model; more complex models require more data, as a rule</span>
<span id="cb68-640"><a href="#cb68-640" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>regularized, principled priors (i.e., those that are more consistent with our a priori beliefs about the data) in general speed-up model convergence</span>
<span id="cb68-641"><a href="#cb68-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-642"><a href="#cb68-642" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>to see how influenced by the priors the posterior is, it's wise to carry out a **sensitivity analysis**: try different priors and either verify that the posterior doesn't chagne drastically, or report how the posterior is affected by some specific priors</span>
<span id="cb68-643"><a href="#cb68-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-644"><a href="#cb68-644" aria-hidden="true" tabindex="-1"></a><span class="fu">## Posterior predictive distribution</span></span>
<span id="cb68-645"><a href="#cb68-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-646"><a href="#cb68-646" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the **posterior predictive distribution** is a *collection of data sets generated from the model* (the likelihood and the priors)</span>
<span id="cb68-647"><a href="#cb68-647" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>having obtained the posterior distributions of the parameters after taking into account the data, the posterior distributions can be used to generate future data from the model</span>
<span id="cb68-648"><a href="#cb68-648" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>i.e., given the *posterior distribution* of the parameters of the model, the *posterior* ***predictive*** *distribution* gives us some indication of what future data might look like</span>
<span id="cb68-649"><a href="#cb68-649" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-650"><a href="#cb68-650" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>once the posterior distributions $p(\theta|y)$ are available, the predictions based on these distributions, by integrating out the parameters</span>
<span id="cb68-651"><a href="#cb68-651" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-652"><a href="#cb68-652" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-653"><a href="#cb68-653" aria-hidden="true" tabindex="-1"></a>p(\boldsymbol{y_{pred}}\mid \boldsymbol{y} ) = \int_{\boldsymbol{\Theta}} p(\boldsymbol{y_{pred}}, \boldsymbol{\Theta}\mid \boldsymbol{y})\, d\boldsymbol{\Theta}= \int_{\boldsymbol{\Theta}} </span>
<span id="cb68-654"><a href="#cb68-654" aria-hidden="true" tabindex="-1"></a>p(\boldsymbol{y_{pred}}\mid \boldsymbol{\Theta},\boldsymbol{y})p(\boldsymbol{\Theta}\mid \boldsymbol{y})\, d\boldsymbol{\Theta}</span>
<span id="cb68-655"><a href="#cb68-655" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-656"><a href="#cb68-656" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>assuming the past and future observations are conditionally independent given $\theta$, the above equation can be written as:</span>
<span id="cb68-657"><a href="#cb68-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-658"><a href="#cb68-658" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-659"><a href="#cb68-659" aria-hidden="true" tabindex="-1"></a>p(\boldsymbol{y_{pred}}\mid \boldsymbol{y} )=\int_{\boldsymbol{\Theta}} p(\boldsymbol{y_{pred}}\mid \boldsymbol{\Theta}) p(\boldsymbol{\Theta}\mid \boldsymbol{y})\, d\boldsymbol{\Theta}</span>
<span id="cb68-660"><a href="#cb68-660" aria-hidden="true" tabindex="-1"></a>\tag{3.8}</span>
<span id="cb68-661"><a href="#cb68-661" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-662"><a href="#cb68-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-663"><a href="#cb68-663" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>this **posterior predictive distribution** has important differences from predictions obtained with the *frequentist* approach</span>
<span id="cb68-664"><a href="#cb68-664" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>**frequentist**: gives a point estimate of each predicted observation given the maximum likelihood estimate of $\theta$ (a point value)</span>
<span id="cb68-665"><a href="#cb68-665" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>**Bayesian**: gives a *distribution* of values for each predicated observation</span>
<span id="cb68-666"><a href="#cb68-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-667"><a href="#cb68-667" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>as with the *prior* predictive distribution, the integration can be carried out computationally by generating samples from the posterior predictive distribution</span>
<span id="cb68-668"><a href="#cb68-668" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>we can use the same function <span class="in">`normal_predictive_distribution()`</span> as created above; the only difference is that the samples come from the **posterior**, not from <span class="in">`mu`</span> and <span class="in">`sigma`</span></span>
<span id="cb68-669"><a href="#cb68-669" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-672"><a href="#cb68-672" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-673"><a href="#cb68-673" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df_spacebar)</span>
<span id="cb68-674"><a href="#cb68-674" aria-hidden="true" tabindex="-1"></a>mu_samples <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>b_Intercept</span>
<span id="cb68-675"><a href="#cb68-675" aria-hidden="true" tabindex="-1"></a>sigma_samples <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(fit_press)<span class="sc">$</span>sigma</span>
<span id="cb68-676"><a href="#cb68-676" aria-hidden="true" tabindex="-1"></a><span class="fu">normal_predictive_distribution</span>(</span>
<span id="cb68-677"><a href="#cb68-677" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_samples =</span> mu_samples,</span>
<span id="cb68-678"><a href="#cb68-678" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_samples =</span> sigma_samples,</span>
<span id="cb68-679"><a href="#cb68-679" aria-hidden="true" tabindex="-1"></a>  <span class="at">N_obs =</span> N_obs</span>
<span id="cb68-680"><a href="#cb68-680" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-681"><a href="#cb68-681" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-682"><a href="#cb68-682" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-683"><a href="#cb68-683" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the function <span class="in">`brms::posterior_predict()`</span> is convenient, as it delivers samples from the posterior predictive distribution</span>
<span id="cb68-684"><a href="#cb68-684" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>in a matrix, with the samples as rows and observations (data-points) as columns; so for <span class="in">`fit_press`</span> there'd be 361 columns</span>
<span id="cb68-685"><a href="#cb68-685" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>N.B., if the model is fit with <span class="in">`sample_prior = "only"`</span>, the dependent variable is ignored and <span class="in">`posterior_predict`</span> will give samples from the *prior* predictive distribution</span>
<span id="cb68-686"><a href="#cb68-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-687"><a href="#cb68-687" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the **posterior predictive distirubtion** can be used to examine the 'descriptive adequacy' of the model under consideration</span>
<span id="cb68-688"><a href="#cb68-688" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>this is called ***posterior predictive checks***</span>
<span id="cb68-689"><a href="#cb68-689" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>the goal is to establish that the posterior predictive data look more or less similar to the observed data</span>
<span id="cb68-690"><a href="#cb68-690" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>achieveing 'descriptive adequacy' means the current data *could* have been generated by the model</span>
<span id="cb68-691"><a href="#cb68-691" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>pass a test of descriptive adequacy is not strong evidence in favour of a model, but a major failure in descriptive adequacy can be interpreted as strong evidence against a model (i.e., passing the test is ***necessary but not sufficient*** evidence in favour of the model)</span>
<span id="cb68-692"><a href="#cb68-692" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>in addition, one should check that the *range* of predictions that the model makes is reasonably constrained</span>
<span id="cb68-693"><a href="#cb68-693" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>if a model can capture any possible outcome, then the model fit to a particular data set is not so informative</span>
<span id="cb68-694"><a href="#cb68-694" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>thus, posterior predictive checking is important but only a sanity check to assess whether the model behaviour is reasonable</span>
<span id="cb68-695"><a href="#cb68-695" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-696"><a href="#cb68-696" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we can usually just use the plot functions from <span class="in">`brms`</span></span>
<span id="cb68-697"><a href="#cb68-697" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>e.g., <span class="in">`ppcheck()`</span> takes as arguments the model, number of predicted data sets, and the type of visualisation</span>
<span id="cb68-698"><a href="#cb68-698" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>in these plots, the **observed data** are plotted as $y$, and **predicted data** as $y_{rep}$</span>
<span id="cb68-699"><a href="#cb68-699" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb68-702"><a href="#cb68-702" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-703"><a href="#cb68-703" aria-hidden="true" tabindex="-1"></a><span class="co"># histograms</span></span>
<span id="cb68-704"><a href="#cb68-704" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="co"># model</span></span>
<span id="cb68-705"><a href="#cb68-705" aria-hidden="true" tabindex="-1"></a>         <span class="at">ndraws =</span> <span class="dv">11</span>, <span class="co"># n of predicted data sets</span></span>
<span id="cb68-706"><a href="#cb68-706" aria-hidden="true" tabindex="-1"></a>         <span class="at">type =</span> <span class="st">"hist"</span> <span class="co"># plot type</span></span>
<span id="cb68-707"><a href="#cb68-707" aria-hidden="true" tabindex="-1"></a>         )</span>
<span id="cb68-708"><a href="#cb68-708" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-709"><a href="#cb68-709" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb68-710"><a href="#cb68-710" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb68-713"><a href="#cb68-713" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-714"><a href="#cb68-714" aria-hidden="true" tabindex="-1"></a><span class="co"># layered density plots</span></span>
<span id="cb68-715"><a href="#cb68-715" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="co"># model</span></span>
<span id="cb68-716"><a href="#cb68-716" aria-hidden="true" tabindex="-1"></a>         <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="co"># n of predicted data sets</span></span>
<span id="cb68-717"><a href="#cb68-717" aria-hidden="true" tabindex="-1"></a>         <span class="at">type =</span> <span class="st">"dens_overlay"</span> <span class="co"># plot type</span></span>
<span id="cb68-718"><a href="#cb68-718" aria-hidden="true" tabindex="-1"></a>         )</span>
<span id="cb68-719"><a href="#cb68-719" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-720"><a href="#cb68-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-721"><a href="#cb68-721" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we see the data ($y$) is slightly skewed and has no values smaller than 100ms, but the predictive distributions are centered and symmetrical</span>
<span id="cb68-722"><a href="#cb68-722" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>so the posterior predictive check shows a slight mismatch between the observed and predicted data</span>
<span id="cb68-723"><a href="#cb68-723" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can we build a better model? Let's see...</span>
<span id="cb68-724"><a href="#cb68-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-725"><a href="#cb68-725" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comparing different likelihoods</span></span>
<span id="cb68-726"><a href="#cb68-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-727"><a href="#cb68-727" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>response times are not usually normally distributed</span>
<span id="cb68-728"><a href="#cb68-728" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>*log-normal* distribution would be more realistic</span>
<span id="cb68-729"><a href="#cb68-729" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-730"><a href="#cb68-730" aria-hidden="true" tabindex="-1"></a><span class="fu">### The log-normal likelihood</span></span>
<span id="cb68-731"><a href="#cb68-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-732"><a href="#cb68-732" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>if $y$ is log-normally distributed, that means that $log(y)$ is normally distributed</span>
<span id="cb68-733"><a href="#cb68-733" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>the log-normal distribution is also defined using the parameters location ($\mu$) and scale ($\sigma$), but these are on the log ms scale and correspond to the mean and standard deviation of the logarithm of the data $y$, $log(y)$, which will be normally distributed</span>
<span id="cb68-734"><a href="#cb68-734" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>therefore, when we model some data $y$ using the log-normal likelihood, the parameters $\mu$ and $\sigma$ are on a different scale than the data $y$, which is represented here:</span>
<span id="cb68-735"><a href="#cb68-735" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-736"><a href="#cb68-736" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-737"><a href="#cb68-737" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb68-738"><a href="#cb68-738" aria-hidden="true" tabindex="-1"></a>\log(\boldsymbol{y}) &amp;\sim \mathit{Normal}( \mu, \sigma)<span class="sc">\\</span></span>
<span id="cb68-739"><a href="#cb68-739" aria-hidden="true" tabindex="-1"></a>\boldsymbol{y} &amp;\sim \mathit{LogNormal}( \mu, \sigma) </span>
<span id="cb68-740"><a href="#cb68-740" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb68-741"><a href="#cb68-741" aria-hidden="true" tabindex="-1"></a>\tag{3.9}</span>
<span id="cb68-742"><a href="#cb68-742" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-743"><a href="#cb68-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-744"><a href="#cb68-744" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we can obtain samples from the log-normal distribution, using the normal distribution by first setting an auxiliary variable, $z$, so that $z = log(y)$</span>
<span id="cb68-745"><a href="#cb68-745" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>so, $z \sim Normal(\mu, \sigma)$</span>
<span id="cb68-746"><a href="#cb68-746" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>then we can use $exp(z)$ as samples from the $LogNormal(\mu,\sigma)$</span>
<span id="cb68-747"><a href="#cb68-747" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>since exp($z$) = exp(log($y$)) = $y$</span>
<span id="cb68-748"><a href="#cb68-748" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-751"><a href="#cb68-751" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-752"><a href="#cb68-752" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">6</span></span>
<span id="cb68-753"><a href="#cb68-753" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb68-754"><a href="#cb68-754" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">500000</span></span>
<span id="cb68-755"><a href="#cb68-755" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate N random samples from a log-normal distribution</span></span>
<span id="cb68-756"><a href="#cb68-756" aria-hidden="true" tabindex="-1"></a>sl <span class="ot">&lt;-</span> <span class="fu">rlnorm</span>(N, mu, sigma)</span>
<span id="cb68-757"><a href="#cb68-757" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(<span class="at">samples =</span> sl), <span class="fu">aes</span>(samples)) <span class="sc">+</span></span>
<span id="cb68-758"><a href="#cb68-758" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">binwidth =</span> <span class="dv">50</span>) <span class="sc">+</span></span>
<span id="cb68-759"><a href="#cb68-759" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Log-normal distribution</span><span class="sc">\n</span><span class="st">"</span>) <span class="sc">+</span></span>
<span id="cb68-760"><a href="#cb68-760" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2000</span>))</span>
<span id="cb68-761"><a href="#cb68-761" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate N random samples from a normal distribution,</span></span>
<span id="cb68-762"><a href="#cb68-762" aria-hidden="true" tabindex="-1"></a><span class="co"># and then exponentiate them</span></span>
<span id="cb68-763"><a href="#cb68-763" aria-hidden="true" tabindex="-1"></a>sn <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">rnorm</span>(N, mu, sigma))</span>
<span id="cb68-764"><a href="#cb68-764" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">tibble</span>(<span class="at">samples =</span> sn), <span class="fu">aes</span>(samples)) <span class="sc">+</span></span>
<span id="cb68-765"><a href="#cb68-765" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">binwidth =</span> <span class="dv">50</span>) <span class="sc">+</span></span>
<span id="cb68-766"><a href="#cb68-766" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Exponentiated samples from</span><span class="sc">\n</span><span class="st">a normal distribution"</span>) <span class="sc">+</span></span>
<span id="cb68-767"><a href="#cb68-767" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2000</span>))</span>
<span id="cb68-768"><a href="#cb68-768" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-769"><a href="#cb68-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-770"><a href="#cb68-770" aria-hidden="true" tabindex="-1"></a><span class="fu">### Re-fitting a single subject pressing a button repeatedly with a log-normal likelihood</span></span>
<span id="cb68-771"><a href="#cb68-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-772"><a href="#cb68-772" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>if we assume that response times are log-normally distributed, we'll need to change our likelihood function as follows:</span>
<span id="cb68-773"><a href="#cb68-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-774"><a href="#cb68-774" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-775"><a href="#cb68-775" aria-hidden="true" tabindex="-1"></a>rt_n \sim LogNormal(\mu, \sigma)</span>
<span id="cb68-776"><a href="#cb68-776" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-777"><a href="#cb68-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-778"><a href="#cb68-778" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>but now ***the scale of our priors needs to change***!</span>
<span id="cb68-779"><a href="#cb68-779" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>starting with uniform priors for ease of exposition, although these are really not appropriate:</span>
<span id="cb68-780"><a href="#cb68-780" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-781"><a href="#cb68-781" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-782"><a href="#cb68-782" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb68-783"><a href="#cb68-783" aria-hidden="true" tabindex="-1"></a>\mu &amp;\sim Uniform(0,11)<span class="sc">\\</span></span>
<span id="cb68-784"><a href="#cb68-784" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim Uniform(0,1)</span>
<span id="cb68-785"><a href="#cb68-785" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb68-786"><a href="#cb68-786" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-787"><a href="#cb68-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-788"><a href="#cb68-788" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>because the parameters are on a different scale than the dependent variable, their interpretation chagnes and it is more complex than dealing with a linear model that assumes a normal likelihood (**location and scale do not coincide with the mean and standard deviation of the log-normal**)</span>
<span id="cb68-789"><a href="#cb68-789" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>***the location, $\mu$***: in our previous linear model, $\mu$ represented the mean</span>
<span id="cb68-790"><a href="#cb68-790" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>now the mean needs to be calculated in the following way: exp($\frac{\mu + \sigma^2}{2}$)</span>
<span id="cb68-791"><a href="#cb68-791" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>i.e., in the log-normal, the mean is dependent on both $\mu$ and $\sigma$</span>
<span id="cb68-792"><a href="#cb68-792" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>the median is just exp($\mu$)</span>
<span id="cb68-793"><a href="#cb68-793" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>N.B., the prior of $\mu$ is not on the milliseconds scale, but the log milliseconds scale</span>
<span id="cb68-794"><a href="#cb68-794" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>***the scale, $\sigma$***: the standard deviation of the normal distribution of log($y$)</span>
<span id="cb68-795"><a href="#cb68-795" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>the standard deviation of a log-normal distribution with *location* $\mu$ and *scale* $\sigma$ will be exp($\frac{\mu + \sigma^2}{2} \times \sqrt{exp(\sigma^2) - 1}$)</span>
<span id="cb68-796"><a href="#cb68-796" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>unlike the normal distribution, the spread of the log-normal distribution depends on both $\mu$ and $\sigma$</span>
<span id="cb68-797"><a href="#cb68-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-798"><a href="#cb68-798" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>to understand the meaning of our priors on the millisecond scale, we need to take into account both the priors and the likelihood; this can be done by generating a **prior predictive distribution**</span>
<span id="cb68-799"><a href="#cb68-799" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>we can just exponentiate the samples produced by <span class="in">`normal_predictive_distribution()`</span></span>
<span id="cb68-800"><a href="#cb68-800" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-803"><a href="#cb68-803" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-804"><a href="#cb68-804" aria-hidden="true" tabindex="-1"></a>N_samples <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb68-805"><a href="#cb68-805" aria-hidden="true" tabindex="-1"></a>N_obs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df_spacebar)</span>
<span id="cb68-806"><a href="#cb68-806" aria-hidden="true" tabindex="-1"></a>mu_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">11</span>)</span>
<span id="cb68-807"><a href="#cb68-807" aria-hidden="true" tabindex="-1"></a>sigma_samples <span class="ot">&lt;-</span> <span class="fu">runif</span>(N_samples, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb68-808"><a href="#cb68-808" aria-hidden="true" tabindex="-1"></a>prior_pred_ln <span class="ot">&lt;-</span> <span class="fu">normal_predictive_distribution</span>(</span>
<span id="cb68-809"><a href="#cb68-809" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_samples =</span> mu_samples,</span>
<span id="cb68-810"><a href="#cb68-810" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma_samples =</span> sigma_samples,</span>
<span id="cb68-811"><a href="#cb68-811" aria-hidden="true" tabindex="-1"></a>  <span class="at">N_obs =</span> N_obs</span>
<span id="cb68-812"><a href="#cb68-812" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb68-813"><a href="#cb68-813" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rt_pred =</span> <span class="fu">exp</span>(rt_pred))</span>
<span id="cb68-814"><a href="#cb68-814" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-815"><a href="#cb68-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-816"><a href="#cb68-816" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we can't generate negative values anymore (exp(any finite number) &gt; 0)</span>
<span id="cb68-817"><a href="#cb68-817" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>these priors might work in the sense that the model might converge, but it would be better to have **regularizing priors** for the model, such as:</span>
<span id="cb68-818"><a href="#cb68-818" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-819"><a href="#cb68-819" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-820"><a href="#cb68-820" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb68-821"><a href="#cb68-821" aria-hidden="true" tabindex="-1"></a>\mu &amp;\sim Normal(6,1.5)<span class="sc">\\</span></span>
<span id="cb68-822"><a href="#cb68-822" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim Normal_+(0,1)</span>
<span id="cb68-823"><a href="#cb68-823" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb68-824"><a href="#cb68-824" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb68-825"><a href="#cb68-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-826"><a href="#cb68-826" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the prior for $\sigma$ is a truncated distribution</span>
<span id="cb68-827"><a href="#cb68-827" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>although its location is 0, this is not the mean</span>
<span id="cb68-828"><a href="#cb68-828" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>we can calculate its approximate mean from a large number of random samples of the prior distribution using the function <span class="in">`extraDistr::rtnorm()`</span>, where the parameter <span class="in">`a = 0`</span> expresses the fact that the normal distribution is truncated from the left at 0</span>
<span id="cb68-829"><a href="#cb68-829" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-832"><a href="#cb68-832" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-833"><a href="#cb68-833" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">rtnorm</span>(<span class="dv">100000</span>, <span class="co"># generate n = 100,000</span></span>
<span id="cb68-834"><a href="#cb68-834" aria-hidden="true" tabindex="-1"></a>            <span class="dv">0</span>, <span class="dv">1</span>,</span>
<span id="cb68-835"><a href="#cb68-835" aria-hidden="true" tabindex="-1"></a>            <span class="at">a =</span> <span class="dv">0</span> <span class="co"># truncate at 0</span></span>
<span id="cb68-836"><a href="#cb68-836" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-837"><a href="#cb68-837" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-838"><a href="#cb68-838" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-839"><a href="#cb68-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-840"><a href="#cb68-840" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>and even before generating the prior predictive distribution, we can calculate the values within which we are 95\% sure the expected median of the observations will lie</span>
<span id="cb68-841"><a href="#cb68-841" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>we can do this by looking at what happens at 2 standard deviations away from the mean of the prior, $\mu$, that is $6 - 2 \times 1.5$ and $6 + 2 \times 1.5$, and exponentiating these values</span>
<span id="cb68-842"><a href="#cb68-842" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-845"><a href="#cb68-845" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-846"><a href="#cb68-846" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">c</span>(<span class="at">lower =</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fl">1.5</span>),</span>
<span id="cb68-847"><a href="#cb68-847" aria-hidden="true" tabindex="-1"></a>        <span class="at">higher =</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fl">1.5</span>)),</span>
<span id="cb68-848"><a href="#cb68-848" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span>)</span>
<span id="cb68-849"><a href="#cb68-849" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-850"><a href="#cb68-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-851"><a href="#cb68-851" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so our prior for $\mu$ is still not too informative (these are medians, the actual values generated by the log-normal distribution can be much more spread out)</span>
<span id="cb68-852"><a href="#cb68-852" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>we can now plot the distribution of some representative statistics of the prior preditive distributions using <span class="in">`brms`</span> to sample from the priors ignoring the <span class="in">`rt`</span> data, by setting <span class="in">`sample_prior = "only"`</span></span>
<span id="cb68-853"><a href="#cb68-853" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>if we want to use <span class="in">`brms`</span> to generate prior predictive data *before* collecting the data, we do need to have some non-<span class="in">`NA`</span> vlaues as the dependent variable, <span class="in">`rt`</span></span>
<span id="cb68-854"><a href="#cb68-854" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>setting <span class="in">`sample_prior = "only"`</span> will ignore the data, but we still need to add it: in this case, we add a vector of 1 as "data"</span>
<span id="cb68-855"><a href="#cb68-855" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>we need to specify that the familiy is <span class="in">`lognormal()`</span></span>
<span id="cb68-856"><a href="#cb68-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-859"><a href="#cb68-859" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-860"><a href="#cb68-860" aria-hidden="true" tabindex="-1"></a><span class="co"># create place-holder data (for cases where we don't yet have any data but want to check out the prior predictive distribution)</span></span>
<span id="cb68-861"><a href="#cb68-861" aria-hidden="true" tabindex="-1"></a>df_spacebar_ref <span class="ot">&lt;-</span> df_spacebar <span class="sc">%&gt;%</span></span>
<span id="cb68-862"><a href="#cb68-862" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rt =</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">n</span>()))</span>
<span id="cb68-863"><a href="#cb68-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-864"><a href="#cb68-864" aria-hidden="true" tabindex="-1"></a><span class="co"># now run a model that runs only prior samples</span></span>
<span id="cb68-865"><a href="#cb68-865" aria-hidden="true" tabindex="-1"></a>fit_prior_press_ln <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb68-866"><a href="#cb68-866" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar_ref,</span>
<span id="cb68-867"><a href="#cb68-867" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">lognormal</span>(),</span>
<span id="cb68-868"><a href="#cb68-868" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb68-869"><a href="#cb68-869" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">6</span>, <span class="fl">1.5</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb68-870"><a href="#cb68-870" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> sigma)</span>
<span id="cb68-871"><a href="#cb68-871" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb68-872"><a href="#cb68-872" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_prior =</span> <span class="st">"only"</span>, <span class="co"># this is how we tell the model to only produce priors!</span></span>
<span id="cb68-873"><a href="#cb68-873" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">list</span>(<span class="at">adapt_delta =</span> .<span class="dv">9</span>),</span>
<span id="cb68-874"><a href="#cb68-874" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_prior_press_ln"</span>)</span>
<span id="cb68-875"><a href="#cb68-875" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-876"><a href="#cb68-876" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-877"><a href="#cb68-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-878"><a href="#cb68-878" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>to avoid the warnings, we need to increase the <span class="in">`adapt_delta`</span> parameter's default value from 0.8 to 0.95 to simulate the data</span>
<span id="cb68-879"><a href="#cb68-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-880"><a href="#cb68-880" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>plot the prior predictive distribution of means with the following code</span>
<span id="cb68-881"><a href="#cb68-881" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>to get a prior predictive distribution, we want to ignore the data, so set <span class="in">`prefix = "ppd"`</span></span>
<span id="cb68-882"><a href="#cb68-882" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>IMPORTANTLY, this should be run on a model that had <span class="in">`sample_prior = "only"`</span>, and therefore ignored the data; otherwise we'd just be plotting the posterior</span>
<span id="cb68-883"><a href="#cb68-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-886"><a href="#cb68-886" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-887"><a href="#cb68-887" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb68-888"><a href="#cb68-888" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb68-889"><a href="#cb68-889" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb68-890"><a href="#cb68-890" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb68-891"><a href="#cb68-891" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb68-892"><a href="#cb68-892" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb68-893"><a href="#cb68-893" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"100"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb68-894"><a href="#cb68-894" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb68-895"><a href="#cb68-895" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb68-896"><a href="#cb68-896" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb68-897"><a href="#cb68-897" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of means"</span>)</span>
<span id="cb68-898"><a href="#cb68-898" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-899"><a href="#cb68-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-900"><a href="#cb68-900" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>to plot the distribution of mimimum and maximum values, replace <span class="in">`mean`</span> with <span class="in">`min`</span> and <span class="in">`max`</span></span>
<span id="cb68-901"><a href="#cb68-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-904"><a href="#cb68-904" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-905"><a href="#cb68-905" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb68-906"><a href="#cb68-906" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb68-907"><a href="#cb68-907" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb68-908"><a href="#cb68-908" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb68-909"><a href="#cb68-909" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb68-910"><a href="#cb68-910" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb68-911"><a href="#cb68-911" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"100"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb68-912"><a href="#cb68-912" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb68-913"><a href="#cb68-913" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb68-914"><a href="#cb68-914" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb68-915"><a href="#cb68-915" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of means"</span>)</span>
<span id="cb68-916"><a href="#cb68-916" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"min"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb68-917"><a href="#cb68-917" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb68-918"><a href="#cb68-918" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb68-919"><a href="#cb68-919" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb68-920"><a href="#cb68-920" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb68-921"><a href="#cb68-921" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb68-922"><a href="#cb68-922" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"100"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb68-923"><a href="#cb68-923" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb68-924"><a href="#cb68-924" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb68-925"><a href="#cb68-925" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb68-926"><a href="#cb68-926" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of minimum values"</span>)</span>
<span id="cb68-927"><a href="#cb68-927" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(fit_prior_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>, <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb68-928"><a href="#cb68-928" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">300000</span>)) <span class="sc">+</span></span>
<span id="cb68-929"><a href="#cb68-929" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"Response times [ms]"</span>,</span>
<span id="cb68-930"><a href="#cb68-930" aria-hidden="true" tabindex="-1"></a>    <span class="at">trans =</span> <span class="st">"log"</span>,</span>
<span id="cb68-931"><a href="#cb68-931" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>),</span>
<span id="cb68-932"><a href="#cb68-932" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb68-933"><a href="#cb68-933" aria-hidden="true" tabindex="-1"></a>      <span class="st">"0.001"</span>, <span class="st">"1"</span>, <span class="st">"10"</span>, <span class="st">"1000"</span>, <span class="st">"10000"</span>,</span>
<span id="cb68-934"><a href="#cb68-934" aria-hidden="true" tabindex="-1"></a>      <span class="st">"100000"</span></span>
<span id="cb68-935"><a href="#cb68-935" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb68-936"><a href="#cb68-936" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb68-937"><a href="#cb68-937" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prior predictive distribution of maximum values"</span>)</span>
<span id="cb68-938"><a href="#cb68-938" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_grid</span>(p1, p2, p3, <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span><span class="dv">1</span>)</span>
<span id="cb68-939"><a href="#cb68-939" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-940"><a href="#cb68-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-941"><a href="#cb68-941" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>these plots show that the priors that we are using are still quite uninformative</span>
<span id="cb68-942"><a href="#cb68-942" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>the tails of the prior predictive distributions that correspond to our normal priors (shown above) are even further to the right, reaching more extreme values than for the prior predictive distributions generated by uniform priors</span>
<span id="cb68-943"><a href="#cb68-943" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>our new priors are still far from representing our prior knowledge</span>
<span id="cb68-944"><a href="#cb68-944" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>we can use summary statistics to test whether the priors are in a plausible range by defining the extreme data that would be very implausible to ever observe</span>
<span id="cb68-945"><a href="#cb68-945" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-948"><a href="#cb68-948" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-949"><a href="#cb68-949" aria-hidden="true" tabindex="-1"></a>fit_press_ln <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb68-950"><a href="#cb68-950" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb68-951"><a href="#cb68-951" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">lognormal</span>(),</span>
<span id="cb68-952"><a href="#cb68-952" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb68-953"><a href="#cb68-953" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">6</span>, <span class="fl">1.5</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb68-954"><a href="#cb68-954" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> sigma)</span>
<span id="cb68-955"><a href="#cb68-955" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb68-956"><a href="#cb68-956" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press_ln"</span>)</span>
<span id="cb68-957"><a href="#cb68-957" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-958"><a href="#cb68-958" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-959"><a href="#cb68-959" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-960"><a href="#cb68-960" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>when we look at the summary of the posterior, the parameters are on the log-scale</span>
<span id="cb68-961"><a href="#cb68-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-964"><a href="#cb68-964" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-965"><a href="#cb68-965" aria-hidden="true" tabindex="-1"></a>fit_press_ln</span>
<span id="cb68-966"><a href="#cb68-966" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-967"><a href="#cb68-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-968"><a href="#cb68-968" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>if we want to know how long it takes to press the space bar in milliseconds, we need to transform the $\mu$ (or <span class="in">`Intercept`</span> in the model) to milliseconds; we know that the median of the log-normal distribution is exp($\mu$), so we do the following to calculate an estimate in milliseconds:</span>
<span id="cb68-969"><a href="#cb68-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-972"><a href="#cb68-972" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-973"><a href="#cb68-973" aria-hidden="true" tabindex="-1"></a>estimate_ms <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">as_draws_df</span>(fit_press_ln)<span class="sc">$</span>b_Intercept)</span>
<span id="cb68-974"><a href="#cb68-974" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-975"><a href="#cb68-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-976"><a href="#cb68-976" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>if we want to know the mean and 95\% CrI of these samples:</span>
<span id="cb68-977"><a href="#cb68-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-980"><a href="#cb68-980" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-981"><a href="#cb68-981" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">mean =</span> <span class="fu">mean</span>(estimate_ms), <span class="fu">quantile</span>(estimate_ms, <span class="at">probs =</span> <span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>)))</span>
<span id="cb68-982"><a href="#cb68-982" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-983"><a href="#cb68-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-984"><a href="#cb68-984" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we can now check whether our *predicted data sets* look similar to the observed data</span>
<span id="cb68-985"><a href="#cb68-985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-988"><a href="#cb68-988" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-989"><a href="#cb68-989" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press_ln, <span class="at">ndraws =</span> <span class="dv">100</span>)</span>
<span id="cb68-990"><a href="#cb68-990" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-991"><a href="#cb68-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-992"><a href="#cb68-992" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>here it seems the posterior predicted data are more similar to the observed data, compared to when we had the normal likelihood</span>
<span id="cb68-993"><a href="#cb68-993" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>but it's not easy to tell</span>
<span id="cb68-994"><a href="#cb68-994" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>another way to examine the extent to which the prediced data looks similar to the observed data: look at the distribution of some summary statistics</span>
<span id="cb68-995"><a href="#cb68-995" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>just like with the prior predictive distributions, examine the distribution of representative summary statistics for the data sets generated by different models</span>
<span id="cb68-996"><a href="#cb68-996" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>however, unlike with *prior* predictive distributions, we now have a clear reference: our observed data (which we ignore/don't have yet for prior predictive distributions)</span>
<span id="cb68-997"><a href="#cb68-997" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we suspect that the normal distribution would generate response times that are too fast (since it's symmetrical) and that the log-normal distribution may capture the long tail better than the normal model</span>
<span id="cb68-998"><a href="#cb68-998" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>based on this, we compute the distribution of minimum and maximum values for the posterior predictive distributions, adn compare them with the minimum and maximum values respectively in the data</span>
<span id="cb68-999"><a href="#cb68-999" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>we cn use <span class="in">`pp_check()`</span> to do this, by using as stat <span class="in">`min`</span> or <span class="in">`max`</span> for our models <span class="in">`fit_press`</span> (normal distribution) and <span class="in">`fit_press_ln`</span> (log-normal distribution)</span>
<span id="cb68-1000"><a href="#cb68-1000" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-1003"><a href="#cb68-1003" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-1004"><a href="#cb68-1004" aria-hidden="true" tabindex="-1"></a>ggpubr<span class="sc">::</span><span class="fu">ggarrange</span>(</span>
<span id="cb68-1005"><a href="#cb68-1005" aria-hidden="true" tabindex="-1"></a>  <span class="co"># normal min</span></span>
<span id="cb68-1006"><a href="#cb68-1006" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pp_check</span>(fit_press, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"min"</span>) <span class="sc">+</span> </span>
<span id="cb68-1007"><a href="#cb68-1007" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Normal model (min)"</span>) <span class="sc">+</span></span>
<span id="cb68-1008"><a href="#cb68-1008" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb68-1009"><a href="#cb68-1009" aria-hidden="true" tabindex="-1"></a>  <span class="co"># normal max</span></span>
<span id="cb68-1010"><a href="#cb68-1010" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pp_check</span>(fit_press, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>) <span class="sc">+</span> </span>
<span id="cb68-1011"><a href="#cb68-1011" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Normal model (max)"</span>) <span class="sc">+</span></span>
<span id="cb68-1012"><a href="#cb68-1012" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb68-1013"><a href="#cb68-1013" aria-hidden="true" tabindex="-1"></a>  <span class="co"># log-normal min</span></span>
<span id="cb68-1014"><a href="#cb68-1014" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pp_check</span>(fit_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"min"</span>) <span class="sc">+</span> </span>
<span id="cb68-1015"><a href="#cb68-1015" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Log-normal model (min)"</span>) <span class="sc">+</span></span>
<span id="cb68-1016"><a href="#cb68-1016" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb68-1017"><a href="#cb68-1017" aria-hidden="true" tabindex="-1"></a>  <span class="co"># log-normal max</span></span>
<span id="cb68-1018"><a href="#cb68-1018" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pp_check</span>(fit_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>) <span class="sc">+</span> </span>
<span id="cb68-1019"><a href="#cb68-1019" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Log-normal model (max)"</span>) <span class="sc">+</span></span>
<span id="cb68-1020"><a href="#cb68-1020" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>),</span>
<span id="cb68-1021"><a href="#cb68-1021" aria-hidden="true" tabindex="-1"></a>  cowplot<span class="sc">::</span><span class="fu">get_legend</span>(<span class="fu">pp_check</span>(fit_press_ln, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"max"</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)),</span>
<span id="cb68-1022"><a href="#cb68-1022" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span> <span class="dv">2</span>, </span>
<span id="cb68-1023"><a href="#cb68-1023" aria-hidden="true" tabindex="-1"></a>  <span class="at">heights =</span> <span class="fu">c</span>(.<span class="dv">45</span>,.<span class="dv">45</span>,.<span class="dv">1</span>),</span>
<span id="cb68-1024"><a href="#cb68-1024" aria-hidden="true" tabindex="-1"></a>  <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"A"</span>,<span class="st">"B"</span>,<span class="st">"C"</span>,<span class="st">"D"</span>)</span>
<span id="cb68-1025"><a href="#cb68-1025" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-1026"><a href="#cb68-1026" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-1027"><a href="#cb68-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1028"><a href="#cb68-1028" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>here we see the log-normal does a slightly better job since the minimum value is contained in the bulk of the log-normal distribution and in the tai of the normal one</span>
<span id="cb68-1029"><a href="#cb68-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1030"><a href="#cb68-1030" aria-hidden="true" tabindex="-1"></a><span class="fu">## List of most important commands</span></span>
<span id="cb68-1031"><a href="#cb68-1031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1032"><a href="#cb68-1032" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>core <span class="in">`brms`</span> function for fitting models, for generating prior predictive and posterior predictive data</span>
<span id="cb68-1033"><a href="#cb68-1033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1036"><a href="#cb68-1036" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-1037"><a href="#cb68-1037" aria-hidden="true" tabindex="-1"></a>fit_press <span class="ot">&lt;-</span> <span class="fu">brm</span>(rt <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb68-1038"><a href="#cb68-1038" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_spacebar,</span>
<span id="cb68-1039"><a href="#cb68-1039" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb68-1040"><a href="#cb68-1040" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb68-1041"><a href="#cb68-1041" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">60000</span>), <span class="at">class =</span> Intercept, <span class="at">lb =</span> <span class="dv">0</span>, <span class="at">ub =</span> <span class="dv">60000</span>),</span>
<span id="cb68-1042"><a href="#cb68-1042" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">2000</span>), <span class="at">class =</span> sigma, <span class="at">lb =</span> <span class="dv">0</span>, <span class="at">ub =</span> <span class="dv">2000</span>)</span>
<span id="cb68-1043"><a href="#cb68-1043" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb68-1044"><a href="#cb68-1044" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">4</span>,</span>
<span id="cb68-1045"><a href="#cb68-1045" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">2000</span>,</span>
<span id="cb68-1046"><a href="#cb68-1046" aria-hidden="true" tabindex="-1"></a>  <span class="at">warmup =</span> <span class="dv">1000</span>,</span>
<span id="cb68-1047"><a href="#cb68-1047" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"models"</span>, <span class="st">"notes"</span>, <span class="st">"ch3"</span>, <span class="st">"fit_press"</span>)</span>
<span id="cb68-1048"><a href="#cb68-1048" aria-hidden="true" tabindex="-1"></a>  <span class="do">## uncomment for prior predictive:</span></span>
<span id="cb68-1049"><a href="#cb68-1049" aria-hidden="true" tabindex="-1"></a>  <span class="do">## sample_prior = "only",</span></span>
<span id="cb68-1050"><a href="#cb68-1050" aria-hidden="true" tabindex="-1"></a>  <span class="do">## uncomment when dealing with divergent transitions</span></span>
<span id="cb68-1051"><a href="#cb68-1051" aria-hidden="true" tabindex="-1"></a>  <span class="do">## control = list(adapt_delta = .9)</span></span>
<span id="cb68-1052"><a href="#cb68-1052" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-1053"><a href="#cb68-1053" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-1054"><a href="#cb68-1054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1055"><a href="#cb68-1055" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>extract samples from fitted model:</span>
<span id="cb68-1056"><a href="#cb68-1056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1059"><a href="#cb68-1059" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-1060"><a href="#cb68-1060" aria-hidden="true" tabindex="-1"></a><span class="fu">as_draws_df</span>(fit_press)</span>
<span id="cb68-1061"><a href="#cb68-1061" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-1062"><a href="#cb68-1062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1063"><a href="#cb68-1063" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>basic plot of posteriors</span>
<span id="cb68-1064"><a href="#cb68-1064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1067"><a href="#cb68-1067" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-1068"><a href="#cb68-1068" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_press)</span>
<span id="cb68-1069"><a href="#cb68-1069" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-1070"><a href="#cb68-1070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1071"><a href="#cb68-1071" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>plot prior predictive/posterior predictive data</span>
<span id="cb68-1072"><a href="#cb68-1072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1075"><a href="#cb68-1075" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-1076"><a href="#cb68-1076" aria-hidden="true" tabindex="-1"></a><span class="do">## Posterior predictive check:</span></span>
<span id="cb68-1077"><a href="#cb68-1077" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="at">type =</span> <span class="st">"dens_overlay"</span>)</span>
<span id="cb68-1078"><a href="#cb68-1078" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot posterior predictive distribution of statistical summaries:</span></span>
<span id="cb68-1079"><a href="#cb68-1079" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>) <span class="sc">+</span></span>
<span id="cb68-1080"><a href="#cb68-1080" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Posterior predictive distribution"</span>)</span>
<span id="cb68-1081"><a href="#cb68-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1082"><a href="#cb68-1082" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot prior predictive distribution of statistical summaries:</span></span>
<span id="cb68-1083"><a href="#cb68-1083" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(fit_press, <span class="at">ndraws =</span> <span class="dv">100</span>, <span class="at">type =</span> <span class="st">"stat"</span>, <span class="at">stat =</span> <span class="st">"mean"</span>,</span>
<span id="cb68-1084"><a href="#cb68-1084" aria-hidden="true" tabindex="-1"></a>         <span class="at">prefix =</span> <span class="st">"ppd"</span>) <span class="sc">+</span></span>
<span id="cb68-1085"><a href="#cb68-1085" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Prior predictive distribution"</span>)</span>
<span id="cb68-1086"><a href="#cb68-1086" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-1087"><a href="#cb68-1087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1088"><a href="#cb68-1088" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb68-1089"><a href="#cb68-1089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1090"><a href="#cb68-1090" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>in this chapter we:</span>
<span id="cb68-1091"><a href="#cb68-1091" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>learned how to fit and interpret a Bayesian model with a normal likelihood</span>
<span id="cb68-1092"><a href="#cb68-1092" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>looked at the effect of priors by means of prior predictive distributions and sensitivity analysis</span>
<span id="cb68-1093"><a href="#cb68-1093" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>looked at the fit of the posterior by inspecting the posterior predictive distribution (which givees us some idea about the descriptive adequacy of the model)</span>
<span id="cb68-1094"><a href="#cb68-1094" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>learned how to fit a Bayesian model with a log-normal likelihood, and how to compare the predictive accuracy of different models</span>
<span id="cb68-1095"><a href="#cb68-1095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1096"><a href="#cb68-1096" aria-hidden="true" tabindex="-1"></a><span class="fu"># Session Info</span></span>
<span id="cb68-1097"><a href="#cb68-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1098"><a href="#cb68-1098" aria-hidden="true" tabindex="-1"></a>Compiled with <span class="in">`r R.version$version`</span> (<span class="in">`r R.version$nickname`</span>) in RStudio version 2023.12.1.402 (Ocean Storm).</span>
<span id="cb68-1099"><a href="#cb68-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1102"><a href="#cb68-1102" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-1103"><a href="#cb68-1103" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb68-1104"><a href="#cb68-1104" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb68-1105"><a href="#cb68-1105" aria-hidden="true" tabindex="-1"></a><span class="fu">RStudio.Version</span>()<span class="sc">$</span>version; <span class="fu">RStudio.Version</span>()<span class="sc">$</span>release_name</span>
<span id="cb68-1106"><a href="#cb68-1106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-1107"><a href="#cb68-1107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1110"><a href="#cb68-1110" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb68-1111"><a href="#cb68-1111" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span>
<span id="cb68-1112"><a href="#cb68-1112" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb68-1113"><a href="#cb68-1113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1114"><a href="#cb68-1114" aria-hidden="true" tabindex="-1"></a><span class="fu"># References {.unnumbered}</span></span>
<span id="cb68-1115"><a href="#cb68-1115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-1116"><a href="#cb68-1116" aria-hidden="true" tabindex="-1"></a>::: {#refs custom-style="Bibliography"}</span>
<span id="cb68-1117"><a href="#cb68-1117" aria-hidden="true" tabindex="-1"></a>:::</span>
</code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>