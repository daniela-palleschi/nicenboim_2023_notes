[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Daniela’s Notes for Nicemboim, Schad, & Vasishth (2024)",
    "section": "",
    "text": "Purpose",
    "crumbs": [
      "Overview",
      "Purpose"
    ]
  },
  {
    "objectID": "setup/project_setup.html",
    "href": "setup/project_setup.html",
    "title": "Project set-up",
    "section": "",
    "text": "CRAN packages\nRequired packages hosted on CRAN are installed below.\n# install packages hosted on CRAN\ninstall.packages(c(#\"SIN\", # SIN package was removed from the CRAN repository\n  \"MASS\", \"dplyr\", \"tidyr\", \"purrr\", \"extraDistr\", \"ggplot2\", \"loo\", \"bridgesampling\", \"brms\", \"bayesplot\", \"tictoc\", \"hypr\",   \"papaja\", \"grid\", \"kableExtra\", \"gridExtra\", \"lme4\", \"cowplot\", \"pdftools\", \"cmdstanr\", \"rootSolve\"))\nSome required packages aren’t available on CRAN. They are installed below.",
    "crumbs": [
      "Overview",
      "Project set-up"
    ]
  },
  {
    "objectID": "setup/project_setup.html#developer-packages",
    "href": "setup/project_setup.html#developer-packages",
    "title": "Project set-up",
    "section": "Developer packages",
    "text": "Developer packages\nIf you don’t have the packages devtools and/or remotes already installed, run the next line(s). Otherwise, skip to the next chunk.\nFirst, check to see if you have the packages devtools, remotes, StanHeaders, and rstan installed. If the packages are installed, a file path will be printed (e.g., [1] \"/Library/Frameworks/R.framework/Versions/4.1/Resources/library/remotes\"). If not, you’ll get an error Error in find.package(\"x\") : there is no package called ‘x’.\n\nfind.package(\"devtools\")\n# run the next line if you don't have 'devtools' already installed\ninstall.packages(\"devtools\")\n\n\nfind.package(\"remotes\")\n# run the next line if you don't have 'remotes' already installed\ninstall.packages(\"devtools\")\n\n\nfind.package(\"StanHeaders\")\n# if 'Stanheaders' is installed, remove it to start fresh\nremove.packages(\"StanHeaders\")\n\n\nfind.package(\"rstan\")\n# if 'rstan' is installed, remove it to start fresh\nremove.packages(\"rstan\")\n\nNow we can install (or re-install) the relevant packages.\n\n# From https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started\n# run the next line if you already have rstan installed\n# remove.packages(c(\"StanHeaders\", \"rstan\"))\ninstall.packages(\"rstan\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\n\n# bcogsci packcage; contains data for the textbook exercises\ndevtools::install_github(\"bnicenboim/bcogsci\")\n\n# cmdstanr (https://mc-stan.org/cmdstanr/)\nremotes::install_github(\"stan-dev/cmdstanr\")\n\n# install SBC (optional)\ndevtools::install_github(\"hyunjimoon/SBC\")",
    "crumbs": [
      "Overview",
      "Project set-up"
    ]
  },
  {
    "objectID": "setup/project_setup.html#my-preferred-packages",
    "href": "setup/project_setup.html#my-preferred-packages",
    "title": "Project set-up",
    "section": "My preferred packages",
    "text": "My preferred packages\n\ninstall.packages(\"pacman\")\n\n\npacman::p_load(\n  renv,\n  here,\n  tidyverse,\n  Rmisc,\n  ggpubr,\n  cowplot,\n  brms,\n  beepr\n)\n\nTo link Zotero to the current Rproject.\n\nremotes::install_github(\"paleolimbot/rbbt\")",
    "crumbs": [
      "Overview",
      "Project set-up"
    ]
  },
  {
    "objectID": "setup/project_setup.html#update-renv.lock",
    "href": "setup/project_setup.html#update-renv.lock",
    "title": "Project set-up",
    "section": "Update renv.lock",
    "text": "Update renv.lock\nIf you want to update the renv.lock file:\n\nrenv::snapshot()",
    "crumbs": [
      "Overview",
      "Project set-up"
    ]
  },
  {
    "objectID": "book_notes/ch1.html",
    "href": "book_notes/ch1.html",
    "title": "1  Chapter notes",
    "section": "",
    "text": "Set up\n# set global knit options\nknitr::opts_chunk$set(echo = T, # print chunks?\n                      eval = T, # run chunks?\n                      error = F, # print errors?\n                      warning = F, # print warnings?\n                      message = F, # print messages?\n                      cache = T # cache?; be careful with this!\n                      )\n\n# suppress scientific notation\noptions(scipen=999)\n\n# load packages\n## create list of package names\npackages &lt;- c( #\"SIN\", # this package was removed from the CRAN repository\n               \"MASS\", \"dplyr\", \"tidyr\", \"purrr\", \"extraDistr\", \"ggplot2\", \"loo\", \"bridgesampling\", \"brms\", \"bayesplot\", \"tictoc\", \"hypr\", \"bcogsci\", \"papaja\", \"grid\", \"kableExtra\", \"gridExtra\", \"lme4\", \"cowplot\", \"pdftools\", \"cmdstanr\", \"rootSolve\", \"rstan\"\n  )\n\n# NB: if you haven't already installed bcogsci through devtools, it won't be loaded\n## Now load or install & load all\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n    }\n  }\n)\n\n# this is also required, taken from the textbook\n\n## Save compiled models:\nrstan_options(auto_write = FALSE)\n## Parallelize the chains using all the cores:\noptions(mc.cores = parallel::detectCores())\n# To solve some conflicts between packages\nselect &lt;- dplyr::select\nextract &lt;- rstan::extract",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Chapter notes</span>"
    ]
  },
  {
    "objectID": "book_notes/ch1.html#probability",
    "href": "book_notes/ch1.html#probability",
    "title": "1  Chapter notes",
    "section": "2.1 Probability",
    "text": "2.1 Probability\nFrequency-based versus uncertain-belief perspective of probability:\n\nrepeatable events, like rolling a die and getting a 6, are frequentist because probability is related to the frequency at which we’d observe an outcome given repeated observations\none-of-a-kind events, like earthquakes, don’t work with this idea of probability\n\n\nthe probability of an earthquake expresses our uncertainty about an event happening\nwe also be uncertain about how probable an event is: being 90% sure something is 50% likely to happen\nthis is what we’re interested in: how uncertain we are of an estimate\n\nIn Bayesian analysis, we want to express our uncertainty about the probability of observing an outcome (prior distribution).\n\n2.1.1 Conditional probability and Bayes’ rule\n\nA = “the streets are wet”\nB = “it was raining”\nP(A|B) = the probability of A given B\nP(A,B) = P(A|B)P(B) (the probability of A and B happening)\n\n\n\n2.1.2 Law of total probability\n\ndunno",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Chapter notes</span>"
    ]
  },
  {
    "objectID": "book_notes/ch1.html#discrete-random-variables",
    "href": "book_notes/ch1.html#discrete-random-variables",
    "title": "1  Chapter notes",
    "section": "2.2 Discrete random variables",
    "text": "2.2 Discrete random variables\nGenerating random sequences of simulated data with a binomial distribution. Imagine a cloze task, where we consider a particular word a success (1) and any other word a failure (0). If we run the experiment 20 times with a sample size of 10, the cloze probabilities for these 20 experiments would be:\nrbinom(10, n = 20, prob = .5)\n[1] 5 5 6 5 9 6 3 8 4 3 6 7 2 3 4 2 4 5 3 5\nFor discrete random variables such as the binomial, the probability distribution p(y|\\(\\theta\\)) is called a probability mass function (PMF) . The PMF defines the probability of each possible outcome. With n = 10 trials, there are 11 possible outcomes (0, 1, 2,…10 succeses). Which outcome is most probable depends on the parameter \\(\\theta\\) that represents the probability of success. Above, we set \\(\\theta\\) to 0.5.\n\n2.2.1 The mean and variance of the binomial distribution\nIn real exerimental situations we never know the true value of \\(\\theta\\) (probability of an outcome), but it can be derived from the data: \\(\\theta\\) hat = k/n, where k = number of observed successess, n = number of trials, and \\(\\theta\\) hat = observed proportion of successes. \\(\\theta\\) hat = maximum likelihood estimate of the true but unknown parameter \\(\\theta\\). Basically, the mean of the binomial distribution. The variance can also be estimated by computing (n(\\(\\theta\\)))(1 - \\(\\theta\\)). These estimates can be be used for statistical inference.\n\n\n2.2.2 Compute probability of a particular outcome (discrete): dibinom\ndbinom calculates probability of k successes out of n given a particular \\(\\theta\\).\n\ndbinom(5, size = 10, prob = .5)\n\n[1] 0.2460938\n\ndbinom(5, size = 10, prob = .1)\n\n[1] 0.001488035\n\ndbinom(5, size = 10, prob = .9)\n\n[1] 0.001488035\n\n\nWith continuous data, the probability of obtaining an exact value will always be zero. We’ll come ot this later.\n\n\n2.2.3 Compute cumulative probability: pbinom\nThe cumulative distribution function (CDF): essentially the sum of all probabilities of the values of k you are interested in. E.g., the probability of observing 2 successes or fewer (0, 1, or 2) is:\n\n# sum of probabilities for exact k's\ndbinom(0, size = 10, prob = .5) +\n  dbinom(1, size = 10, prob = .5) +\n  dbinom(2, size = 10, prob = .5)\n\n[1] 0.0546875\n\n# or\nsum(dbinom(0:2, size = 10, prob = .5))\n\n[1] 0.0546875\n\n# or use pbinom()\npbinom(2, size = 10, prob = 0.5, lower.tail = TRUE)\n\n[1] 0.0546875\n\n# conversely, what is the $\\theta$ of observing THREE successes or more?\npbinom(2, size = 10, prob = 0.5, lower.tail = F)\n\n[1] 0.9453125\n\n# or\nsum(dbinom(3:10, size = 10, prob = .5))\n\n[1] 0.9453125\n\n# the probability of observing 10 or fewer successes (out of 10 trials)\npbinom(10, size = 10, prob = 0.5, lower.tail = TRUE)\n\n[1] 1\n\n\n\n\n2.2.4 Compute the inverse of the CDF (quantile function): qbinom\nThe quantile function (the inverse CDF) obtains the value of k (the quantile) given the probability of obtaining k or less than k successes given some specific probability value p:\n\n# reverse of dbinom(2,10,.5) would be:\nqbinom(0.0546875, size=10, prob=.5)\n\n[1] 2\n\n\n\n2.2.4.1 Generage simulated data from binomial distribtion: rbinom\n\n# given 1 iteration of 10 trials where p = .5, produce a random value of k\nrbinom(1, 10, .5)\n\n[1] 5",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Chapter notes</span>"
    ]
  },
  {
    "objectID": "book_notes/ch1.html#continuous-random-variables",
    "href": "book_notes/ch1.html#continuous-random-variables",
    "title": "1  Chapter notes",
    "section": "2.3 Continuous random variables",
    "text": "2.3 Continuous random variables\nImagine vector of reading times data with a normal distribution, defined by its mean and its sd. The probability density function (PDF) for particular values of mean and sd (assuming a normal distribution) can be calculated using dnorm. The CDF can be found using pnorm, and the inverse CDF using qnorm. These are 3 different ways of looking at the infrmation.\n\n# p of observing a mean of 250ms when the true mean is 500 & sd = 100 (PDF)\ndnorm(400,mean = 500, sd = 100)\n\n[1] 0.002419707\n\n# p of observing 400ms *or lower* when the true mean is 500 & sd = 100 (CDF)\npnorm(400,mean = 500, sd = 100)\n\n[1] 0.1586553\n\n# k with a CDF of 0.1586553 when the true mean is 500 & sd = 100 (inverse CDF)\nqnorm(0.1586553, mean = 500, sd = 100)\n\n[1] 400\n\n\nQuestion: what is the probability of observing values between 200 and 700 from a normal distribution where mean = 500 and sd = 100?\n\npnorm(700,500,100) - pnorm(200,500,100)\n\n[1] 0.9759\n\n\nWith continuous data, it is only meaningful to ask about probabilities between two point values (e.g., probability that Y lies between a and b).\nWhat is the quantile q such that the probability of observing that value or something less (or more) than it is 0.975 (given the normal(500,100) distribution)?\n\nqnorm(0.975, m=500, sd=100)\n\n[1] 695.9964\n\n\nNext task: generate simulated data. generate 10 data points using the rnorm function and use this simulated data to compute the mean and stanrdard devaition.\n\nx &lt;- rnorm(10,500,100)\nmean(x)\n\n[1] 516.5017\n\nsd(x)\n\n[1] 113.2716\n\n# can also computer lower and upper bounds of 95% CIs\nquantile(x, probs = c(.025, .975))\n\n    2.5%    97.5% \n372.5688 677.9407 \n\n\n\n2.3.1 An important distinction: probability vs. densitiy in continuous random variables\nThe probability density function (PDF):\n\n# density with default m = 0 and sd = 1\ndnorm(1)\n\n[1] 0.2419707\n\n\nThis is not the probability of observing 1 in this distribution, as the probability of a single value in a continous distribtion will always be 0. This is becaue probability in a continuous distritubion is the area under the curve, and at a single point there is no area under the curve (i.e., p = 0). The pnorm function allows us to find the cumulative distribution function (CDF) for the normal distribution.\nFor example, the probability of obseving a value etween +/-2 in a normal distribution with mean 0 and sd 1:\n\npnorm(2, m = 0, sd = 1) - pnorm(-2, m = 0, sd = 1)\n\n[1] 0.9544997\n\n\nFor discrete random variables, the situation is different. These have a probability mass function (PMF), the binomial distribution that we saw before. Here, the PMF maps the possible y values to the probabilities of those exact values occurring.\n\ndbinom(2,size=10,prob=.5)\n\n[1] 0.04394531\n\n\n\n\n2.3.2 Truncating a normal distribution\nRefers to positive values only (truncating at 0).",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Chapter notes</span>"
    ]
  },
  {
    "objectID": "book_notes/ch1.html#bivariate-and-multivariate-distributions",
    "href": "book_notes/ch1.html#bivariate-and-multivariate-distributions",
    "title": "1  Chapter notes",
    "section": "2.4 Bivariate and multivariate distributions",
    "text": "2.4 Bivariate and multivariate distributions\nConsider a case where two discrete responses were recorded: a binary yes/no response, and a Likert acceptability rating (1-7).\nThe joint probability mass function is the joint PMF of two random variables.\nLet’s play around with some such data:\n\n# run if package is not loaded\n# library(bcogsci)\ndata(\"df_discreteagrmt\")\n\n\n2.4.0.1 Marginal distributions\nThe marginal distribution of each pair of values (let’s say x = the binary response, y = the Likert response) is computed by summing up\n\nrowSums(probs)\n\nobject probs is not defined in the book\n\n\n2.4.1 Generate simulated bivariate (multivariate) data\nSuppose we want to generate 100 pairs of correlated data, with correlation rho = 0.6. The two random variables have mean 0, and standard deviations 5 and 10 respectively.\n\n## define a variance-covariance matrix:\nSigma &lt;- matrix(c(5^2, 5 * 10 * .6, 5 * 10 * .6, 10^2),\n  byrow = FALSE, ncol = 2\n)\n## generate data:\nu &lt;- mvrnorm(\n  n = 100,\n  mu = c(0, 0),\n  Sigma = Sigma\n)\nhead(u, n = 3)\n\n          [,1]      [,2]\n[1,]  3.180268  9.383862\n[2,] 11.705874 22.998634\n[3,] -6.216305 -8.460007\n\n\n\n# plot the data\nggplot(tibble(u_1 = u[, 1], u_2 = u[, 2]), aes(u_1, u_2)) +\n  geom_point()",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Chapter notes</span>"
    ]
  },
  {
    "objectID": "book_notes/ch1.html#an-important-concept-the-marginal-likelihood-integrating-out-a-parameter",
    "href": "book_notes/ch1.html#an-important-concept-the-marginal-likelihood-integrating-out-a-parameter",
    "title": "1  Chapter notes",
    "section": "2.5 An important concept: the marginal likelihood (integrating out a parameter)",
    "text": "2.5 An important concept: the marginal likelihood (integrating out a parameter)",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Chapter notes</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html",
    "href": "book_notes/ch2.html",
    "title": "2  Ch. 2",
    "section": "",
    "text": "Set up\n# set global knit options\nknitr::opts_chunk$set(echo = T, # print chunks?\n                      eval = T, # run chunks?\n                      error = F, # print errors?\n                      warning = F, # print warnings?\n                      message = F, # print messages?\n                      cache = F # cache?; be careful with this!\n                      )\n\n# suppress scientific notation\noptions(scipen=999)\n\n# play a sound if error encountered\noptions(error = function() {beepr::beep(9)})\n\n# load packages\n## create list of package names\npackages &lt;- c( #\"SIN\", # this package was removed from the CRAN repository\n               \"MASS\", \"dplyr\", \"tidyr\", \"purrr\", \"extraDistr\", \"ggplot2\", \"loo\", \"bridgesampling\", \"brms\", \"bayesplot\", \"tictoc\", \"hypr\", \"bcogsci\", \"papaja\", \"grid\", \"kableExtra\", \"gridExtra\", \"lme4\", \"cowplot\", \"pdftools\", \"cmdstanr\", \"rootSolve\", \"rstan\"\n  )\n\n# NB: if you haven't already installed bcogsci through devtools, it won't be loaded\n## Now load or install & load all\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n    }\n  }\n)\n\n# this is also required, taken from the textbook\n\n## Save compiled models:\nrstan_options(auto_write = FALSE)\n## Parallelize the chains using all the cores:\noptions(mc.cores = parallel::detectCores())\n# To solve some conflicts between packages\nselect &lt;- dplyr::select\nextract &lt;- rstan::extract",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html#terms",
    "href": "book_notes/ch2.html#terms",
    "title": "2  Ch. 2",
    "section": "Terms",
    "text": "Terms\n\nposterior, p($theta$|y): probability distribution of the parameters conditional on the data\nlikelihood, p(y|$theta$): the PMF or PDF expressed as a function of \\(\\theta\\)\nprior, $theta$: the initial probability distribution of paramters before seeing the data\nmarginal likelihood, p(y): standardizes the posterior distribution to ensure the AUC sums to 1; it ensure the posterior is a valid probability distribution",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html#bayes-rule",
    "href": "book_notes/ch2.html#bayes-rule",
    "title": "2  Ch. 2",
    "section": "3.1 Bayes’ Rule",
    "text": "3.1 Bayes’ Rule\n\nBayes’ rule: when A and B are observable discrete events (like “it has been raining” or “the streets are wet”), we can state the rule as follows:\n\n\\[\nP(A\\mid B) = \\frac{P(B\\mid A) P(A)}{P(B)}\n\\tag{2.1}\n\\]\n\ngiven a vector of data y, we can work out the posterior distributions of parameters of interest which we represent as the vector of parameters \\(\\theta\\)\nto do this, we can re-write equation 2.1 as 2.2:\n\n\\[\np(\\boldsymbol{\\Theta}|\\boldsymbol{y}) = \\cfrac{ p(\\boldsymbol{y}|\\boldsymbol{\\Theta}) \\cdot p(\\boldsymbol{\\Theta}) }{p(\\boldsymbol{y})}\n\\tag{2.2}\n\\]\n\nnow, Bayes’ rule is writen in terms of probability distributions, where p() is the probability density function (continuous) or probability mass function (discrete)\nin words, this simply means:\n\n\\[\n\\hbox{Posterior} = \\frac{\\hbox{Likelihood} \\cdot \\hbox{Prior}}{\\hbox{Marginal Likelihood}}\n\\]",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html#deriving-the-posterior-using-bayes-rule-an-analystical-example",
    "href": "book_notes/ch2.html#deriving-the-posterior-using-bayes-rule-an-analystical-example",
    "title": "2  Ch. 2",
    "section": "3.2 Deriving the posterior using Bayes’ Rule: an analystical example",
    "text": "3.2 Deriving the posterior using Bayes’ Rule: an analystical example\n\nparticipants are shown sentences like It’s raining. I’m going to take the…\nif 100 participants complete the sentence, and 80 complete the sentence with bus, the estimated cloze probability would be \\(\\frac{80}{100}\\)=0.8\n\nthis is the maximum likelihood estimate of the probability of producing the word; as this is an estimate let’s add a hat: \\(\\hat \\theta\\)=0.8\n\nin the frequentist paradigm, \\(\\hat \\theta\\)=0.8 is an estimate of an unknown point value \\(\\theta\\) “out there in nature”\nN.B., the variability in the estimate will be influenced by the sample size\n\nif the true value of \\(\\theta\\) is really 0.80, we will still get some variability in the estimated proportion from a sample size of say 10 pariticpants\nlet’s carry out 100 simulated experiments and compute their variability:\n\n\n\nestimated_means &lt;- rbinom(n = 100, # generate 100 random binomial data sets\n                          size = 10, # of 10 obvs each\n                          prob = .8) / 10 # with prob 8, now divide these by 10 to get 100 means (k/n)\n\n# what is the sd of these 100 means?\nround(sd(estimated_means),3)\n\n[1] 0.125\n\n\n\ninstead, let’s imagine that \\(\\theta\\) is a random variable; i.e., it has a PDF associated with it\n\nthis PDDF would now represent our belief about possible values of \\(\\theta\\) before we have any data\ne.g., if we believe from the outset that all possible values between 0 and 1 are equally likely, we would have a uniform prior of \\(\\theta \\sim \\mathit{Uniform}\\)(0,1)\nlet’s re-run our simulated experiments, but with two sources of variability: the data and our uncertainty associated with \\(\\theta\\)\n\n\n\ntheta &lt;- runif(100, min = 0, max = 1) # simulate 100 numbers between 0:1\n\nestimated_means &lt;- rbinom( # generate random binomial data that has...\n  n = 100, # 100x\n  size = 10, # of 10 obvs\n  prob = theta # with prob = theta\n)/10 # divided by 10 to give us the mean for each\n\n# sd of the means from these 100 'experiments'\nround(sd(estimated_means),3)\n\n[1] 0.306\n\n\n\nthe higher standard deviation, representing variability int he estimate of the parameter, comes frm the added uncertainty from the \\(\\theta\\) parameter\n\nwhat would happen if we had tighter expectations, i.e., a very tight PDF for \\(\\theta\\), say (0.7,0.9)?\n\n\n\ntheta &lt;- runif(100, min = 0.7, max = 0.9) # simulate 100 numbers between 0:1\n\nestimated_means &lt;- rbinom( # generate random binomial data that has...\n  n = 100, # 100x\n  size = 10, # of 10 obvs\n  prob = theta # with prob = theta\n)/10 # divided by 10 to give us the mean for each\n\n# sd of the means from these 100 'experiments'\nround(sd(estimated_means),3)\n\n[1] 0.139\n\n\n\nthe variability is smaller; so the greater the uncertainty associated with the \\(\\theta\\) parameter, the greater the variability in the data\nthis is very different from the frequentist assumption that \\(\\theta\\) is a point value; in Bayesian \\(\\theta\\) is a random variable with a probability density/mass function associated with it\nthis PDF is called a prior distribution and represents our prior belief or knowledge about a possible value of this parameter\nonce we obtain data, these data serve to modify our prior belief about the distribution, called our posterior distribution",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html#choosing-a-likelihood",
    "href": "book_notes/ch2.html#choosing-a-likelihood",
    "title": "2  Ch. 2",
    "section": "3.3 Choosing a likelihood",
    "text": "3.3 Choosing a likelihood\n\nwith a binomial distribution like the cloze probability (chose ‘bus’ or not), the PMF can be written as:\n\n\\[\np(k|n,\\theta) = \\binom{n}\n{k} \\theta^k (1-\\theta)^{n-k}\n\\tag{2.3}\n\\]\n\nk = the number of times “bus” was given as an answer\nn = the total number of answers given\nif we collect 100 data points (n = 100), and find k = 80, we now have 2 fixed data points, n and k. The only variable is now \\(\\theta\\)\n\n\\[\np(k=80 | n= 100,  \\theta) = \\binom{n}{k} \\theta^{80} (1-\\theta)^{20}\n\\]\n\nthis is now a continuous function of the value of \\(\\theta\\), which can have a possible value between 0 and 1\nby contrast, the PMF of the binomial treats \\(\\theta\\) as a fixed value and defines a discrete distribution over the n+1 possible discrete values k that we can observe\nrecall: the PMF and the likelihood are the same function seen from different points of view: the only difference being what is considered fixed (PMF: \\(\\theta\\), likelihood: data) and what is varying (PMF: data, likelihood: \\(\\theta\\))\n\nPMF: \\(\\theta\\) is fixed, data varies\nlikelihood function: data is fixed, \\(\\theta\\) varies\n\n\nNow we go back to our main foal: using Bayes’ rule to find out the posterior distribution of \\(\\theta\\) given our data: p(\\(\\theta\\)*|n,k). We first need to define a prior distribution over the parameter \\(theta\\), thereby expressing our prior uncertainty about plausible values of \\(\\theta\\)",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html#choosinga-a-prior-for-theta",
    "href": "book_notes/ch2.html#choosinga-a-prior-for-theta",
    "title": "2  Ch. 2",
    "section": "3.4 Choosinga a prior for \\(\\theta\\)",
    "text": "3.4 Choosinga a prior for \\(\\theta\\)\n\npriors for a \\(\\theta\\) in a binominal distribution: the parameter \\(\\theta\\) is a random variable with a PDF whose range is [0,1]\nthe beta distribution, which is a PDF for a continuous random variable, is commonly used as a prior for parameters representing probabilities, and has the following PDF:\n\n\\[\np(\\theta|a,b)=  \\frac{1}{B(a,b)} \\theta^{a - 1} (1-\\theta)^{b-1}   \n\\tag{2.4}\n\\]\n\nB(a,b) is a normalising constant that ensures that the area under the curve sums to 1, so that p(\\(\\theta\\)|a,b) is a probability\nthe beta distribution’s paramters a and b express our prior beliefs about the probability of a success:\n\na = number of “successes” (answering “bus”)\nb = number of “failures” (not answering “bus”)\n\nthe different beta distributions shapes given different values of a and b are shown below (in r, a = shape1 and b = shape2)\n\n\nplot(function(x) \n  dbeta(x,shape1=1,shape2=1), 0,1,\n      main = \"Beta density\",\n  ylab=\"density\",xlab=\"theta\",ylim=c(0,3))\n\ntext(.5,1.1,\"a=1,b=1\")\n\nplot(function(x) \n  dbeta(x,shape1=3,shape2=3),0,1,add=TRUE)\ntext(.5,1.6,\"a=3,b=3\")\n\n\nplot(function(x) \n  dbeta(x,shape1=6,shape2=6),0,1,add=TRUE)\ntext(.5,2.8,\"a=6,b=6\")\n\nplot(function(x) \n  dbeta(x,shape1=2,shape2=6),0,1,add=TRUE)\ntext(.15,2.9,\"a=2,b=6\")\n\nplot(function(x) \n  dbeta(x,shape1=6,shape2=2),0,1,add=TRUE)\ntext(.85,2.9,\"a=6,b=2\")\n\n\n\n\n\n\n\n\n\nto express our uncertainty, we could compute 95% credible intervales, i.e., the region over which we are 95% certain the value of the parameter lies\n\n\n# compute 95% CrIs\nround(\n  qbeta(# at what quantiles (points on the x-axis)\n  c(.025,.975), # would the PDF cover 95% AUC\n  shape1 = 4, # where a = 4\n  shape2 = 4), # and b = 4\n  3) # rounded to 3 decimal points\n\n[1] 0.184 0.816\n\n\n\n\n\n\n\n\nSidebar\n\n\n\n\nin a unimodal distribution, one could use the narrowest interval that contains the mode (the highest posterior density interval (HDI))\nin skewed posterior distirbutions, the equal-tailed CrI and the HDI will not be identical, because the HDI will have unequal tail probabilities; this book uses the equal-tailed interval (like we computed above) because it’s the standard output in Stan and brms\n\n\n\n\nif we were to choose a = 10 and b = 10, we would still be assuming a prior that “bus” is just as likely as some other word, but now our prior uncertainty about this mean is lower, meaning we have a tighter prior:\n\n\n# compute 95% CrIs\nround(\n  qbeta(# at what quantiles (points on the x-axis)\n  c(.025,.975), # would the PDF cover 95% AUC\n  shape1 = 10, # where a = 4\n  shape2 = 10), # and b = 4\n  3) # rounded to 3 decimal points\n\n[1] 0.289 0.711\n\n\n\ncompare the AUC for the two beta distributions in Abbildung 3.1\n\n\nplot(function(x) \n  dbeta(x,shape1=4,shape2=4), 0,1,\n      main = \"Beta density\",\n  ylab=\"density\",xlab=\"theta\",ylim=c(0,4))\ntext(.5,2.35,\"a=4,b=4\")\n\nplot(function(x) \n  dbeta(x,shape1=10,shape2=10),0,1,add=TRUE,\n  ylab=\"density\",xlab=\"theta\",ylim=c(0,4))\ntext(.5,3.7,\"a=10,b=10\")\n\n\n\n\n\n\n\nAbbildung 3.1: Beta distributions with varying a and b values\n\n\n\n\n\n\nbut which prior should we choose? This depends on our prior knowledge\n\nif we don’t have much prior information, we could use a = b = 1; this is a uniform prior \\(\\mathit{Uniform}\\)(0,1), often clled a flat, non-informative, or uninformative prior\nif we have a lot of prior knowledge or a strong belief regarding the range of plausible values for \\(\\theta\\), we can use a different set of a and b values\nif we were to use a = 4 and b = 4, then our prior for \\(\\theta\\) would be:\n\n\n\\[\np(\\theta) = \\frac{1}{B(4,4)} \\theta^{3} (1-\\theta)^{3}\n\\]",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html#using-bayes-rule-to-computer-the-posterior-pthetank",
    "href": "book_notes/ch2.html#using-bayes-rule-to-computer-the-posterior-pthetank",
    "title": "2  Ch. 2",
    "section": "3.5 Using Baye’s rule to computer the posterior p(\\(\\theta\\)|n,k)",
    "text": "3.5 Using Baye’s rule to computer the posterior p(\\(\\theta\\)|n,k)\n\nrecall the equation from earlier:\n\n\\[\n\\hbox{Posterior} = \\frac{\\hbox{Likelihood} \\cdot \\hbox{Prior}}{\\hbox{Marginal Likelihood}}\n\\]\n\nnow that we’ve got the likelihood and the prior, we can use Bayes’ rule to calculate p(\\(\\theta\\)|n,k), as follows:\n\n\\[\np(\\theta|n=100,k=80) = \\frac{\\left[\\binom{100}{80} \\theta^{80} \\cdot (1-\\theta)^{20}\\right]  \\times \\left[\\frac{1}{B(4,4)} \\times \\theta^{3} (1-\\theta)^{3}\\right]}{p(k=80)}\n\\tag{2.6}\n\\]\n\nconstant values are those that do not depend on the unknown parameter of interest, \\(\\theta\\); so p(k = 80) will be a constant once we know the number of successes\n\nonce k is known, we already have several constant values\n\n\n\\[\np(\\theta|n=100,k=80) =   \\left[ \\frac{\\binom{100}{80}}{B(4,4)\\times p(k=80)} \\right]   [\\theta^{80} (1-\\theta)^{20} \\times  \\theta^{3} (1-\\theta)^{3}]\n\\tag{2.7}\n\\]\n\nwe can gather all the constants (in the square brackets below):\n\n\\[\np(\\theta|n=100,k=80) =   \\left[ \\frac{\\binom{100}{80}}{B(4,4)\\times p(k=80)} \\right]   [\\theta^{80} (1-\\theta)^{20} \\times  \\theta^{3} (1-\\theta)^{3}]\n\\tag{2.7}\n\\]\n\nand ignore the constants for now, which will later on make the AUC sum up to 1; so now we say the posterior is proportional to the right-hand side of the equation:\n\n\\[\np(\\theta|n=100,k=80) \\propto   [\\theta^{80} (1-\\theta)^{20} \\times \\theta^{3} (1-\\theta)^{3} ]\n\\tag{2.8}\n\\]\n\nin other words:\n\n\\[\n\\hbox{Posterior} \\propto \\hbox{Likelihood} \\times \\hbox{Prior}\n\\]\n\nnow we just have to add up the exponents\n\n\\[\np(\\theta|n=100,k=80) \\propto   [\\theta^{80+3} (1-\\theta)^{20+3}] = \\theta^{83} (1-\\theta)^{23}\n\\tag{2.9}\n\\]\n\nrecall that the beta distribution involves \\(\\theta\\) exponentiated to the power of a-1 and b-1 (see equation 2.4)\n\ntherefore, the expression in 2.9 above corresponds to a beta distribution with parameters a = 84 and b = 24 (because 83 and 23 +1 is 84 and 24)\nall we need now is our normalising constant to make the AUC sum to one; let’s check this:\n\n\n\nPostFun &lt;- function(theta) {\n  theta^83 * (1 - theta)^23\n}\n(AUC &lt;- integrate(PostFun, lower = 0, upper = 1)$value)\n\n[1] 0.0000000000000000000000000831619\n\n\n\nthis doesn’t add up to 1, it’s not a probability distribution\nbut we can use it to figure out what our normalising constant is; what is the constant k such that the AUC sums to 1:\n\n\\[\nk \\int_{0}^{1} \\theta^{83} (1-\\theta)^{23} = 1\n\\]\n\nwe know what _{0}^{1} ^{83} (1-)^{23} is, because we just computed it above (and called it AUC), so:\n\n\\[\nk  = \\frac{1}{\\int_{0}^{1} \\theta^{83} (1-\\theta)^{23}} = \\frac{1}{AUC}\n\\]\n\nwe now have the distribution or \\(\\theta\\) given the data, expressed as a PDF:\n\n\\[\np(\\theta|n=100,k=80) = \\frac{1}{B(83,23)} \\theta^{84-1} (1-\\theta)^{24-1}\n\\]\n\nand our function will now sum to one if we divide it all by AUC\n\n\nPostFun &lt;- function(theta) {\n  theta^83 * (1 - theta)^23 / AUC\n}\nintegrate(PostFun, lower = 0, upper = 1)$value\n\n[1] 1",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html#summary-of-the-procedure",
    "href": "book_notes/ch2.html#summary-of-the-procedure",
    "title": "2  Ch. 2",
    "section": "3.6 Summary of the procedure",
    "text": "3.6 Summary of the procedure\n\nwe started with a binomial likelihood\n\nmultiplied it with the prior \\(\\theta \\sim \\mathit{Beta}(4,4)\\)\nobtained the posterior p(\\(\\theta\\)|n,k) \\(\\sim \\mathit{Beta}(4,4)\\)\nwe ignored the constants when carrying out the multiplication (i.e., computer the posterior up to proportionality)\nthen we rescaled the posterior to become a probability distribution by including a proportionality constant (AUC)\n\nthis was an example of a conjugate analysis: the posterior on the parameter has thes ame form (belongs to the same family of probability distributions) as the prior\nthis combo of likelihood and prior is called the beta-binomial conjugate case\n\nconjugacy is defined as: Given the likelihood p(y|\\(\\theta\\)), if the prior p(\\(\\theta\\)*)( results in a posterior \\(p(\\theta|y)\\) that has some form as \\(p(\\theta)\\), then we call \\(p(\\theta)\\) a conjugate prior\ngiven a \\(Binomial(n,k|\\theta)\\) likelihood, and a \\(Beta(a,b)\\) prior on \\(\\theta\\), the posterior will be \\(Beta(a + k, b + n - k)\\)",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html#visualising-the-prior-likelihood-and-the-posterior",
    "href": "book_notes/ch2.html#visualising-the-prior-likelihood-and-the-posterior",
    "title": "2  Ch. 2",
    "section": "3.7 Visualising the prior, likelihood, and the posterior",
    "text": "3.7 Visualising the prior, likelihood, and the posterior\n\nk &lt;- 80\nn &lt;- 100\n## Prior\na &lt;- 4\nb &lt;- 4\nbinom_lh &lt;- function(theta) {\ndbinom(x=k, size =n, prob = theta)\n}\nK &lt;- integrate(f = binom_lh, lower = 0, upper = 1)$value\nbinom_scaled_lh &lt;- function(theta) 1/K * binom_lh(theta)\n  \np_beta &lt;- ggplot(data = tibble(theta = c(0, 1)), aes(theta)) +\n  stat_function(\n    fun = dbeta,\n    args = list(shape1 = a, shape2 = b),\n    aes(linetype = \"Prior\")\n  ) +\n  ylab(\"density\") +\n  stat_function(\n    fun = dbeta,\n    args = list(shape1 = k + a, shape2 = n - k + b), aes(linetype = \"Posterior\")\n  ) +\n  stat_function(\n    fun = binom_scaled_lh,\n    aes(linetype = \"Scaled likelihood\")\n  ) +\n  theme_bw() +\n  theme(legend.title = element_blank())\np_beta\n\n\n\n\n\n\n\n\n\nif we wanted to produce the 95% credible interval, i.e., the range over which we are 95% certain the true value of \\(\\theta\\) lies, give a = 84 and b = 24:\n\n\nround(\n  qbeta(c(0.025, 0.975), shape1 = 84, shape2 = 24)\n  ,3)\n\n[1] 0.695 0.851",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html#the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood",
    "href": "book_notes/ch2.html#the-posterior-distribution-is-ac-ompromise-between-the-prior-and-the-likelihood",
    "title": "2  Ch. 2",
    "section": "3.8 The posterior distribution is ac ompromise between the prior and the likelihood",
    "text": "3.8 The posterior distribution is ac ompromise between the prior and the likelihood\n\nlet’s take four different beta priors with increasing certainty:\n\n\\(Beta(a = 2, b = 2)\\)\n\\(Beta(a = 3, b = 3)\\)\n\\(Beta(a = 6, b = 6)\\)\n\\(Beta(a = 21, b = 21)\\)\n\neach reflects a believe that \\(\\theta\\) = 0.5 but with a varying degree of certainty\n\nwe can now “just” plug in the likelihood and the prior to the beta-binomial case to get the posterior:\n\n\n\\[\np(\\theta | n,k) \\propto p(k |n,\\theta) p(\\theta)\n\\]\n\nif we plot the tightest case (\\(a = 21, b = 21\\)), we see how the posterior is affected\n\n\nk &lt;- 80\nn &lt;- 100\n## Prior\na &lt;- 21\nb &lt;- 21\nbinom_lh &lt;- function(theta) {\ndbinom(x=k, size =n, prob = theta)\n}\nK &lt;- integrate(f = binom_lh, lower = 0, upper = 1)$value\nbinom_scaled_lh &lt;- function(theta) 1/K * binom_lh(theta)\n  \np_beta &lt;- ggplot(data = tibble(theta = c(0, 1)), aes(theta)) +\n  stat_function(\n    fun = dbeta,\n    args = list(shape1 = a, shape2 = b),\n    aes(linetype = \"Prior\")\n  ) +\n  ylab(\"density\") +\n  stat_function(\n    fun = dbeta,\n    args = list(shape1 = k + a, shape2 = n - k + b), aes(linetype = \"Posterior\")\n  ) +\n  stat_function(\n    fun = binom_scaled_lh,\n    aes(linetype = \"Scaled likelihood\")\n  ) +\n  theme_bw() +\n  theme(legend.title = element_blank())\np_beta\n\n\n\n\n\n\n\n\n\nwe can say the following about the likelihood-prior-posterior relationship:\n\nthe posterior distribution is ac ompromise between the prior and the likelihood\nfor a given set of data, the great the certainty in the prior, the more heavily the posterior will be influenced by the prior mean\nconversely, for a given set of data, the greater the uncertainty in the prior, the more heavily the posterior will be influenced by the likelihood\nbut because n and k are included in the posterior Beta distribution (\\(Beta(a + k, b + n - k)\\)), the posterior mean will be influenced more heavily by larger sample sizes\n\nsensitivity analyses can help check whether your parameter of interest is sensitive to the prior specification",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html#incremental-knowledge-gain-using-prior-knowledge",
    "href": "book_notes/ch2.html#incremental-knowledge-gain-using-prior-knowledge",
    "title": "2  Ch. 2",
    "section": "3.9 Incremental knowledge gain using prior knowledge",
    "text": "3.9 Incremental knowledge gain using prior knowledge\n\nwe can incrementally gain information about a research question by using information from previous studies and deriving a position, and then using that posterior as a prior for the next experiment\ne.g., in the example above, we currently had a prior \\(Beta(4,4)\\) and observed \\(k = 80\\) successes of \\(n = 100\\) observations, deriving a posterior \\(Beta(84,24)\\)\n\nif we were to run this experiment again and had \\(k = 60, n = 100\\), we cwould have a posterior as follows \\(\\mathit{Beta}(a+k,b+n-k) = \\mathit{Beta}(84+60,24+100-60)=\\mathit{Beta}(144,64)\\)\nalternatively, if we collected all this data in the first place and had a prior \\(Beta(4,4)\\) and for data \\(k = 140, n = 200\\), we’d have the same posterior: \\(\\mathit{Beta}(4+140,4+200-140)=\\mathit{Beta}(144,64)\\)\n\nso, we can keep building on our previous findings to inform future priors",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch2.html#summary",
    "href": "book_notes/ch2.html#summary",
    "title": "2  Ch. 2",
    "section": "3.10 Summary",
    "text": "3.10 Summary\n\nwe’ll continue down the same path we followed in this chapter moving forward:\n\ndecide on an appropriate likelihood function\ndecide on prior for all the parameters involved in the likelihood function\nusing this model (the likelihood and the priors) derive the posterior distribution of each parameter\ndraw inferences about our research question basedon the posterior distribution of the parameter",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Ch. 2</span>"
    ]
  },
  {
    "objectID": "book_notes/ch3.html",
    "href": "book_notes/ch3.html",
    "title": "3  Ch. 3",
    "section": "",
    "text": "Set up\n# set global knit options\nknitr::opts_chunk$set(echo = T, # print chunks?\n                      eval = T, # run chunks?\n                      error = F, # print errors?\n                      warning = F, # print warnings?\n                      message = F, # print messages?\n                      cache = F # cache?; be careful with this!\n                      )\n\n# suppress scientific notation\noptions(scipen=999)\n\n# play a sound if error encountered\noptions(error = function() {beepr::beep(9)})\n\n# load packages\n## create list of package names\npackages &lt;- c( #\"SIN\", # this package was removed from the CRAN repository\n               \"MASS\", \"dplyr\", \"tidyr\", \"purrr\", \"extraDistr\", \"ggplot2\", \"loo\", \"bridgesampling\", \"brms\", \"bayesplot\", \"tictoc\", \"hypr\", \"bcogsci\", \"papaja\", \"grid\", \"kableExtra\", \"gridExtra\", \"lme4\", \"cowplot\", \"pdftools\", \"cmdstanr\", \"rootSolve\", \"rstan\"\n  )\n\n# NB: if you haven't already installed bcogsci through devtools, it won't be loaded\n## Now load or install & load all\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n    }\n  }\n)\n\n# this is also required, taken from the textbook\n\n## Save compiled models:\nrstan_options(auto_write = FALSE)\n## Parallelize the chains using all the cores:\noptions(mc.cores = parallel::detectCores())\n# To solve some conflicts between packages\nselect &lt;- dplyr::select\nextract &lt;- rstan::extract",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ch. 3</span>"
    ]
  },
  {
    "objectID": "book_notes/ch3.html#deriving-the-posterior-through-sampling",
    "href": "book_notes/ch3.html#deriving-the-posterior-through-sampling",
    "title": "3  Ch. 3",
    "section": "4.1 Deriving the posterior through sampling",
    "text": "4.1 Deriving the posterior through sampling\n\nrecall the example cloze task for It’s raining, I’m going to take the…, with the ‘correct’ answer bus (‘umbrella’ in the book but to me ‘bus’ is the most natural completion)\n\nimagine 80 ‘successes’ and 20 ‘failures’\nassuming a binomial distribution as the likelihood function, and \\(Beta(a = 4, b = 4)\\) as a prior distribution for the cloze probability\nif we can obtain samples from the posterior distribution or \\(\\theta\\), instead of an analystically derived posterior distribution, given enough samples we will have a good approximation of the posterior distribution\n‘obtain samples’ here means a situation similar to when we use rbinom or rnorm to obtain samples from a particular distribution\nassume we used some probabilistic prgramming langauge to obtain 20,000 samples from the posterior distribution of the cloze probability \\(\\theta\\)",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ch. 3</span>"
    ]
  },
  {
    "objectID": "book_notes/ch3.html#bayesian-regression-models-using-stan-brms",
    "href": "book_notes/ch3.html#bayesian-regression-models-using-stan-brms",
    "title": "3  Ch. 3",
    "section": "4.2 Bayesian regression models using Stan: brms",
    "text": "4.2 Bayesian regression models using Stan: brms\n\nbecause of increased computing power and probabilistic programming languages (e.g., WinBUGS, JAGS, R-INLA, pymc3, Turing, Stan), Bayesian statistics is now more popular\n\nthese languages allow th euser to define models without the complexities of the sampling process\nhowever, they require learning a new language as te statistical model must be specified using a specific syntax\nadditionally, some knowledge of the sampling process is needed to correctly parametrize the models and avoid convergence issues\n\nBayesian inference in R is possible without having the fully specify the model thanks to stanarm and brms packages\n\nboth packages provide Bayesian equivalents of R model-fitting functions like (g)lmer\nboth use Stan as the back-end for estimation and sampling\n\nfor this part of the book we will focus on brms\n\nit can be useful for a smooth transition from frequentist models to their Bayesian equivalents\nit has the added benefit that the Stan code can be inspected via brms::make_stancode() and brms::make_standata()\nusers can then customatize their models or learn from the code produced internally by brms\n\n\n\n4.2.1 A simple linear model: A single subject pressing a button repeatedly\n\nimagine having data from a single participant repeatedly pressing the spacebar as fast as possible\n\nthe data are response times in imilliseconds in each trial; we want to know how long it takes to press a key for this subject\n\nlet’s model the data with thef ollowing assumptions:\n\nTehre is a true (unknown) underlying time, \\(\\mu\\) ms, that the subject needs to press the psace bar\nThere is some noise in this process\nThe noise is normally distributed (this assumption is questionable given that response times are generally skewed, we will fix this assumption later)\n\n\nThis means that the likelihood for each observation \\(n\\) will be:\n\\[\nrt_{n} \\sim Normal(\\mu, \\sigma)\n\\tag{3.2}\n\\]\n\nwhere \\(n\\) = 1, …, \\(N\\), and \\(rt\\) is the dependent variable (RTs in ms)\n\nthe variable \\(N\\) indexes the total number of data points\n\\(\\mu\\) indicates the location of the normal distirbution function; the lcoation parameter shifts the distribution left or right on the horizontal axis\nin the normal distribution, the location is also the mean of the distribution\n\\(\\sigma\\) indicates the scale of the distribution; as the scale decreases, the distribution gets narrower\nfor the normal distribution, the scale is also the standard deviation\n\nthis same equation can be expressed as:\n\n\\[\nrt_n = \\mu + \\varepsilon \\hbox{, where } \\varepsilon_n \\stackrel{iid}{\\sim} \\mathit{Normal}(0,\\sigma) \\tag{3.3}\n\\]\n\nthis version of the model should be understood to mean that each data point \\(rt_n\\) has some variability around a mean value \\(\\mu\\), and that variability has standard deviation \\(\\sigma\\)\n\nthe term \\(iid\\) (‘independent and identically distributed’) implies that each data point \\(rt_n\\) is independently generated (i.e., not correlated with any of the other data points), and is coming from the same distribution (\\(Normal(\\mu,\\sigma)\\))\n\nFrequentist model: that will give us the maximu likelihood estimate (the sample mean) of the time it takes to press the space bar\n\nthis owuld be enough ifnmroamtion to write the formular in R, lm(rt ~ 1)\n\nBayesian linear model: we will also need to define priors for the two parameters of our model\n\nlet’s say we know for sure that the time it takes to press a key will be positive and lower than a minute (0-60,000ms), but we don’t want to make a commitment regarding which values are more likely\nwe encode what we know about the noise in the task in \\(\\sigma\\): this parameter must be positive and we’ll assume any value below 2000ms is equally likely; such flat or uniformative priors are generaly strongly discouraged: it will almost never be the best approximation of what we know\nlet’s start with such priors, regardless:\n\n\n\\[\n\\begin{aligned}\n\\mu &\\sim \\mathit{Uniform}(0, 60000) \\\\\n\\sigma &\\sim \\mathit{Uniform}(0, 2000)\n\\end{aligned}\n\\tag{3.4}\n\\]\n\nload the data from the bcogsci package\n\n\ndata(\"df_spacebar\")\ndf_spacebar &lt;- df_spacebar %&gt;%\n  rename(rt = t)\nhead(df_spacebar)\n\n# A tibble: 6 × 2\n     rt trial\n  &lt;int&gt; &lt;int&gt;\n1   141     1\n2   138     2\n3   128     3\n4   132     4\n5   126     5\n6   134     6\n\n\n\nplot the data before you do anything else; as we suspected, the data lock a bit (positively) skewed, but let’s ignore that for now\n\n\ndf_spacebar %&gt;%\n  ggplot(aes(rt)) +\n  labs(title = \"Button-press data\",\n       x = \"response times\") +\n  geom_density() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n4.2.1.1 Specifying the model in brms\n\nfit the model defined by equations \\(\\ref{3.2}\\) and \\(\\ref{3.4}\\)\n\n\nfit_press &lt;- brm(\n  rt ~ 1,\n  data = df_spacebar,\n  family = gaussian(),\n  prior = c(\n    prior(\n      uniform(0, 60000),\n      class = Intercept, # mean\n      lb = 0,\n      ub = 60000\n    ),\n    prior(\n      uniform(0, 2000),\n      class = sigma, # sd\n      lb = 0,\n      ub = 2000\n    )\n  ),\n  chains = 4,\n  iter = 2000,\n  warmup = 1000,\n  file = here::here(\"models\", \"notes\", \"ch3\", \"fit_press_1\")\n)\n\n\nsome differences between this syntax and lm():\n\nfamily = gaussian() makes it explicity that the underlying likelihood function is a normal distribution\n\n\nthis is implicit in lm()\nthe default for brms is gaussian()\nother linking function are possible, just like in the glm() function\n\n\nprior takes as argument a vector of priors\n\n\nthis is optional, but we should always explicitly specify each prior; otherwise brms will define priors but they may or may not be appropriate\nthis is why we need lb (lower bound) and upper bound to specify the plausible range of values to sample from in cases where the distribution is restricted (e.g., reaction times cannot be negative, so lb must be at least 0)\n\n\nchains refers to the number of independent runs for sampling\n\n\ndefault = 4\n\n\niter refers to the number of iteratiosn that a sampler makes to sample from the posterior distribution of each paramter\n\n\ndefault = 2000\n\n\nwarmup refers to the number of iterations from the start of sampling that are eventually discarded\n\n\ndefault = \\(\\frac{`iter`}{2}\\)\n\nthe last 3 options determine the behaviour of the sampling algorithm\n\n\n\n4.2.1.2 Sampling and convergence in a nutshell\n\nour 4 chains start independently from each other\n\neach chain “searches” for samples of the posterior distribution in a multidimensional space, where each parameter corresponds to a dimension\nthe shape of this space is determined by the priors and likelihood\nchains start at a random location and each iteraton takes one sample each\nwhen sampling begins, the samples may or may not belong to the posterior distributions of the parameters; eventually the chains end up in the vicinity of the posterior and from then on the samples will belong to the posterior\n\ntherefore, when sampling starts the samples from the different chains can be far from each other; at some point they will converge and start delivering samples from the posterior distributions\n\ntypically the default values of brms will be sufficient to achieve convergence\nif not, brms (but really Stan) will print out warnings with suggestions for fixin the convergence problems\nthis is why we remove the warmup samples, because the chains can start far apart and not in the posterior distribution\nso, if we run 4 chains with 2000 iterations, we will obtain a total of 4000 iterations (\\(\\frac{4 chains * 2000 iterations}{2} = \\frac{8000}{2}\\))\n\n\n\n\n4.2.1.3 Output of brms\n\nonce the model has ben fit (and assuming we didn’t get any warning messages about convergence), we can print out the samples of the posterior distributions using as_draws_df()\n\n\nas_draws_df(fit_press) %&gt;%\n  head(3)\n\n# A draws_df: 3 iterations, 1 chains, and 5 variables\n  b_Intercept sigma Intercept lprior  lp__\n1         166    25       166    -19 -1685\n2         167    25       167    -19 -1684\n3         166    26       166    -19 -1685\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\n\nb_Intercept corresponds to our \\(\\mu\\); we can ignore the last 2 columns\nplot the density and trace plot of each paramter after warmup:\n\n\nplot(fit_press)\n\n\n\n\n\n\n\n\n\nand print the object with the brms fit\n\n\nfit_press\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: rt ~ 1 \n   Data: df_spacebar (Number of observations: 361) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   168.68      1.33   166.04   171.27 1.00     2773     2839\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    24.98      0.92    23.29    26.89 1.00     3201     2719\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nor with posterior_summary()\n\n\nposterior_summary(fit_press)\n\n               Estimate Est.Error        Q2.5       Q97.5\nb_Intercept   168.67592 1.3341598   166.03664   171.27276\nsigma          24.98047 0.9160944    23.28801    26.89033\nIntercept     168.67592 1.3341598   166.03664   171.27276\nlprior        -18.60300 0.0000000   -18.60300   -18.60300\nlp__        -1683.74586 0.9681534 -1686.26917 -1682.77752\n\n\n\nEstimate is just the mean of the posterior samples\nEst.Error is the standard deviation of the posterior\nCIs mark the upper and lower bounds of the 95% credible intervals\n\n\nas_draws_df(fit_press)$b_Intercept %&gt;% \n  mean()\n\n[1] 168.6759\n\n\n\nas_draws_df(fit_press)$b_Intercept %&gt;% \n  sd()\n\n[1] 1.33416\n\n\n\nas_draws_df(fit_press)$b_Intercept %&gt;%\n  quantile(c(.025,.975))\n\n    2.5%    97.5% \n166.0366 171.2728 \n\n\n\nsummary also provides:\n\nRhat: compares between- and within-chain estimate of each parameter\n\nis &gt;1 when chains have not mixed well; we can only rely on the model if the R-hats for all parameters are &lt;1.05 (warnings will appear otherwise)\n\nBulk_ESS: ‘bulk effective sample size’ is a measure of sampling efficienty in the bulk of the posterior distribution\n\ni.e., the effectice sample size for the mean and median estimates\n\nTail_ESS: ‘tail effective sample size’: the sampling efficiency at the tails of the distribution\n\ni.e., the minimum of effective sample sizes for 5% and 95% quantiles\n\nthe number of post-warmup samples is generally lower than the effective sample size, because the samples from the chains are not independent (they are correlated to some extent) , and carry less information about the posterior distribution in comparison to independent samples\n\nvery low sample size indicates sampling problems (and will produce warnings) and in general appear when chains are not properly mixed\n\nas a rule of thumb, a minimum of 400 effective sample size is required for statistical summaries\n\nwe wee our model fits without problems, and we get some posterior distribution for our parameters, but we should ask the following questions:\n\n\nWhat informationa re the priors encoding? Do the priors make sense?\nDoes the likelihood assumed int he model make sense for the data?\n\n\nto answer these questions we can look at the prior and posterior distributions and we can do sensitivity analyses",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ch. 3</span>"
    ]
  },
  {
    "objectID": "book_notes/ch3.html#prior-predictive-distribution",
    "href": "book_notes/ch3.html#prior-predictive-distribution",
    "title": "3  Ch. 3",
    "section": "4.3 Prior predictive distribution",
    "text": "4.3 Prior predictive distribution\n\nwe had the following priors in our linear model:\n\n\\[\n\\begin{aligned}\n\\mu &\\sim \\mathit{Uniform}(0, 60000) \\\\\n\\sigma &\\sim \\mathit{Uniform}(0, 2000)\n\\end{aligned}\n\\tag{3.5}\n\\]\n\nthese priors encode assumptions about our data\nto understand these assumptions, we are going to generate data from the model\n\nsuch data, which is generated entirely by the prior distributions, is called the prior predictive distribution\ngenerating prior predictive distributions repeatedly helps us to check whether the priors make sense; we want to know whether the priors generate realistic-looking data\n\nto do this, repeat the following many times:\n\nTae one sample from each of the priors\nPlug those samples into the porbability density/mass function used as the likelihood int he model to generate a dataset \\(y_{pred_1}, ..., y_{pred_n}\\)\n\n\neach sample is an imaginary or potential data set\n\ncreate a function that does this:\n\n\nnormal_predictive_distribution &lt;-\n  function(mu_samples, sigma_samples, N_obs) {\n    # empty data frame with headers:\n    df_pred &lt;- tibble(\n      trialn = numeric(0),\n      rt_pred = numeric(0),\n      iter = numeric(0)\n    )\n    # i iterates from 1 to the length of mu_samples,\n    # which we assume is identical to\n    # the length of the sigma_samples:\n    for (i in seq_along(mu_samples)) {\n      mu &lt;- mu_samples[i]\n      sigma &lt;- sigma_samples[i]\n      df_pred &lt;- bind_rows(\n        df_pred,\n        tibble(\n          trialn = seq_len(N_obs), # 1, 2,... N_obs\n          rt_pred = rnorm(N_obs, mu, sigma),\n          iter = i\n        )\n      )\n    }\n    df_pred\n  }\n\n\nthe code below produces 1000 samples of the prior predictive distribution of the model we defined for fit_press from the df_spacebar data, that had 361 trials\n\nthis code will produce 361,000 predicted values (361 observations x 1000 simulations)\nwe could also use the option sample_prior = \"only\" in our brms model, but it still depends on Stam’s sampler which uses Hamiltonian Monte Carlo, and can fail to converge especially with uninformative priors\n\n\n\nN_samples &lt;- 1000\nN_obs &lt;- nrow(df_spacebar)\nmu_samples &lt;- runif(N_samples, 0, 60000)\nsigma_samples &lt;- runif(N_samples, 0, 2000)\ntic()\nprior_pred &lt;- normal_predictive_distribution(\n  mu_samples = mu_samples,\n  sigma_samples = sigma_samples,\n  N_obs = N_obs\n)\ntoc()\n\n2.118 sec elapsed\n\n\n\nprior_pred\n\n# A tibble: 361,000 × 3\n   trialn rt_pred  iter\n    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1      1  26813.     1\n 2      2  27298.     1\n 3      3  28224.     1\n 4      4  28051.     1\n 5      5  28176.     1\n 6      6  27918.     1\n 7      7  28332.     1\n 8      8  28241.     1\n 9      9  27841.     1\n10     10  27232.     1\n# ℹ 360,990 more rows\n\n\n\n\n\n\n\n\nBox 3.1: A more efficint prior predictive distribution function\n\n\n\n\nalternatively, we could use the purr::map2_dfr() functions as below, which would run a bit faster:\n\n\nlibrary(purrr)\n# Define the function:\nnormal_predictive_distribution &lt;- function(mu_samples,\n                                           sigma_samples,\n                                           N_obs) {\n  map2_dfr(mu_samples, sigma_samples, function(mu, sigma) {\n    tibble(\n      trialn = seq_len(N_obs),\n      rt_pred = rnorm(N_obs, mu, sigma)\n    )\n  }, .id = \"iter\") %&gt;%\n    # .id is always a string and\n    # needs to be converted to a number\n    mutate(iter = as.numeric(iter))\n}\n# Test the timing:\ntic()\nprior_pred &lt;- normal_predictive_distribution(\n  mu_samples = mu_samples,\n  sigma_samples = sigma_samples,\n  N_obs = N_obs\n)\ntoc()\n\n\n\n\nlet’s look at the first 18 samples of the prior predictive distribution\n\n\nprior_pred %&gt;%\n  filter(iter &lt;= 18) %&gt;%\n  ggplot(aes(rt_pred)) +\n  labs(title = \"18 samples\",\n      x=\"predicted rt (ms)\") +\n  geom_histogram(aes(y = ..density..)) +\n  \n  theme(\n    axis.text.x =\n      element_text(angle = 40, vjust = 1, hjust = 1, size = 14)\n  ) +\n  scale_y_continuous(\n    limits = c(0, 0.0005),\n    breaks = c(0, 0.00025, 0.0005), name = \"density\"\n  ) +\n  facet_wrap(~iter, ncol = 3)\n\n\n\n\n\n\n\nAbbildung 4.1: 18 samples\n\n\n\n\n\n\nFigure @fig-samples18 shows prior data sets that are not realistic: the data shows RT distributions are symmetrical (and we know they are generally right-skewed)\n\nworse, a few have negative RT values\n\nso, our priors led to unrealistic values in our prior predictive distribution\n\nso our priors weren’t very useful\n\nso, what priors should we have used?",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ch. 3</span>"
    ]
  },
  {
    "objectID": "book_notes/ch3.html#the-influence-of-priors-sensitivity-analysis",
    "href": "book_notes/ch3.html#the-influence-of-priors-sensitivity-analysis",
    "title": "3  Ch. 3",
    "section": "4.4 The influence of priors: sensitivity analysis",
    "text": "4.4 The influence of priors: sensitivity analysis\n\nthere are 4 main classes of priors in this book\n\nbut there is no fixed nomenclature for these kind of priors, there’s no current naming convention in the field\n\n\n\n4.4.1 Flat, uninformative priors\n\nthe idea behind uninformative priors is to let the data ‘speak fo ritself’ and to not bias the statistical inference iwth ’subjective priors\nissues with this approach:\n\nthe prior is as subjective as the likelihood, and different choices of likelihood might have a stronger mpace on the posterior than choice of priors\nuninformative priors are in general unrealistic and give equal weight to all values within the support of the prior distribution\nunifnromative priors m ake the sampling slower and might lead to convergence problems\nit is not always clear which parametrization of a given distribution the flat priors should be assigned to\n\nin our space bar button press example, and uniformative prior would be:\n\n\\[\n\\mu \\sim Uniform(-10^{20}, 10^{20})\n\\] - this is a strange prior because it’s on them millisecond scale, and allows for impossibly large positive values, as well as negative values which are not possible at all\n\n\n4.4.2 Regularising priors\n\nused when we don’t have much prior information or knowledge\n\nsometimes called weakly informative or mildly informative\n\nthese are priors that down-weight extreme values (they provide regularization)\n\nusually not very informative, and mostly let the likelihood dominate in determining the posteriors\n\nthese are theory-neutral priors; they do not bias the parameters to values spported by any prior belief or theory\nthese priors help stabilize computation\nin our button press example, a regularizing prior owuld be\n\n\\[\n\\mu \\sim Normal_+(0,1000)\n\\] - where \\(Normal_+\\) indicates that the normal distribution is truncated at 0ms (i.e., is cut off at 0, so no negative values are possible) - this is regularizing because it rules out negative button-pressing times and down-weights extreme values over 2000ms\n\n\n4.4.3 Principled priors\n\nthese priors encode all (or most of) the theory-neutral information\n\none generally knows what one’s data do and do not look like, it is possible to build priors that truly reflect the properties of potential data sets\n\nin our button press example, a principled prior could be\n\n\\[\n\\mu \\sim Normal_+(250,100)\n\\] - it is not overly restrictive, but represents a guess about plausible button-pressing tiems - prior predictive checks using principled priors should produce realisitic distributions of the dependent variable\n\n\n4.4.4 Informative priors\n\nfor cases wehre a lot of prior knowledge exists, and not much data\nunless there is a very good reason to use informative priors, it is not a good idea to let the priors have too much influence on the posterior\n\ne.g., investigating a language-imparied population from which we can’t get many subjects, but a lot of previous published work exists on the topic\n\nin our button press data, an informative prior could be based on the meta-analysis of previously published or existing data, or the result of prior elicitation from an expert on the topic under investigation\n\ne.g., the following prior:\n\n\n\\[\n\\mu \\sim Normal_+(200,20)\n\\]\n\nthis will have some influence ont he posterior for \\(\\mu\\), especially when one has relatively sparse data",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ch. 3</span>"
    ]
  },
  {
    "objectID": "book_notes/ch3.html#re-visiting-the-button-press-example-with-different-priors",
    "href": "book_notes/ch3.html#re-visiting-the-button-press-example-with-different-priors",
    "title": "3  Ch. 3",
    "section": "4.5 Re-visiting the button-press example with different priors",
    "text": "4.5 Re-visiting the button-press example with different priors\n\nwhat would happen if even wider priors were used for the model we defined earlier?\n\nsuppose every mean between -10^6 and 10^6 is assumed to be equally likely\nthis is clearly unrealistic and nonsensical; we don’t expect negative values\nfor the sd, we could assume any value between 0 and 10^6 is equally likely; the likelihood remains unchanged\n\n\n\\[\n\\begin{aligned}\n\\mu &\\sim \\mathit{Uniform}(-10^{6}, 10^{6}) \\\\\n\\sigma &\\sim \\mathit{Uniform}(0,  10^{6})\n\\end{aligned}\n\\tag{3.6}\n\\]\n\n# The default settings are used when they are not set explicitly:\n# 4 chains, with half of the iterations (set as 3000) as warmup.\nfit_press_unif &lt;- brm(rt ~ 1,\n  data = df_spacebar,\n  family = gaussian(),\n  prior = c(\n    prior(uniform(-10^6, 10^6),\n          class = Intercept,\n          lb = -10^6,\n          ub = 10^6),\n    prior(uniform(0, 10^6),\n          class = sigma,\n          lb = 0,\n          ub = 10^6)\n  ),\n  iter = 3000,\n  # the following needed to be changed to achieve convergence\n  control = list(adapt_delta = .99,\n                 max_treedepth = 15),\n  file = here::here(\"models\", \"notes\", \"ch3\", \"fit_press_unif\")\n)\n\n\neven with these priors, the output of the model is virtually dientical to the previous one\n\n\nfit_press_unif\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: rt ~ 1 \n   Data: df_spacebar (Number of observations: 361) \n  Draws: 4 chains, each with iter = 3000; warmup = 1500; thin = 1;\n         total post-warmup draws = 6000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   168.62      1.33   166.02   171.27 1.00     4176     2981\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    25.00      0.90    23.37    26.91 1.00      600      710\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nfit_press\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: rt ~ 1 \n   Data: df_spacebar (Number of observations: 361) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   168.68      1.33   166.04   171.27 1.00     2773     2839\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    24.98      0.92    23.29    26.89 1.00     3201     2719\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nwhat about very informative priors?\n\nassume the mean values very close to 400ms are the most likely, and that the sd of RTs is very close to 100ms\nthis is not very sensical, 200ms seems like a more realistic mean for button-press\n\n\n\\[\n\\begin{aligned}\n\\mu &\\sim \\mathit{Normal}(400, 10) \\\\\n\\sigma &\\sim \\mathit{Normal}_+(100, 10) \\end{aligned}\n\\tag{3.7}\n\\] - if we refit our model:\n\nfit_press_inf &lt;- brm(rt ~ 1,\n  data = df_spacebar,\n  family = gaussian(),\n  prior = c(\n    prior(normal(400, 10), class = Intercept),\n    # brms knows that SDs need to be bounded\n    # to exclude values below zero:\n    prior(normal(100, 10), class = sigma)\n  ),\n  file = here::here(\"models\", \"notes\", \"ch3\", \"fit_press_inf\")\n)\n\n\nwe see that the likelihood mostly dominates again, and the new posterior means and CrIs are only shifted by a few milliseconds when these unrealistic but informative priors are used:\n\n\nfit_press_inf\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: rt ~ 1 \n   Data: df_spacebar (Number of observations: 361) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   172.90      1.38   170.20   175.63 1.00     2994     2659\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    26.09      1.07    24.12    28.28 1.00     2507     2165\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nas a final example of sensitivity analysis, let’s choose some principled priors\nassuming we have some prior experience, let’s suppose the mean RT is expected to be arround 200ms, with a 95% probability of the mean ranging from 0 to 400ms\n\nthis uncertainty is perhaps unreasonably large, but one might want to allow a bit more uncertainty than one really thinks is reasonable (sometimes called Cromwell’s rules)\nlet’s then decide on the prior \\(Normal(200,100)\\)\nwith just a single participnt and a simple task, the residual standard deviation \\(\\sigma\\) shouldn’t be very large: let’s settle on a location of 50ms for a trucnated normal distribution, but still allow for relatively large uncertainty:\n\n\n\\[\n\\begin{aligned}\n\\mu &\\sim \\mathit{Normal}(200, 100) \\\\\n\\sigma &\\sim \\mathit{Normal}_+(50, 50)\n\\end{aligned}\n\\]\n\nfit_press_prin &lt;- brm(rt ~ 1,\n  data = df_spacebar,\n  family = gaussian(),\n  prior = c(\n    prior(normal(200, 100), class = Intercept),\n    prior(normal(50, 50), class = sigma)\n  ),\n  file = here::here(\"models\", \"notes\", \"ch3\", \"fit_press_prin\")\n)\n\n\nagain, the estimates are virtually the same as before:\n\n\nfit_press_prin\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: rt ~ 1 \n   Data: df_spacebar (Number of observations: 361) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   168.69      1.30   166.15   171.18 1.00     4101     2734\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    25.00      0.96    23.16    26.95 1.00     4219     2608\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nthese examples do not mean priors never matter\nwhen there is enough data, the likelihood will dominate in determing the posterior distributions\n\nwhat constitutes ‘enough’ data is also a function of the complexity of the model; more complex models require more data, as a rule\n\nregularized, principled priors (i.e., those that are more consistent with our a priori beliefs about the data) in general speed-up model convergence\nto see how influenced by the priors the posterior is, it’s wise to carry out a sensitivity analysis: try different priors and either verify that the posterior doesn’t chagne drastically, or report how the posterior is affected by some specific priors",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ch. 3</span>"
    ]
  },
  {
    "objectID": "book_notes/ch3.html#posterior-predictive-distribution",
    "href": "book_notes/ch3.html#posterior-predictive-distribution",
    "title": "3  Ch. 3",
    "section": "4.6 Posterior predictive distribution",
    "text": "4.6 Posterior predictive distribution\n\nthe posterior predictive distribution is a collection of data sets generated from the model (the likelihood and the priors)\nhaving obtained the posterior distributions of the parameters after taking into account the data, the posterior distributions can be used to generate future data from the model\n\ni.e., given the posterior distribution of the parameters of the model, the posterior predictive distribution gives us some indication of what future data might look like\nonce the posterior distributions \\(p(\\theta|y)\\) are available, the predictions based on these distributions, by integrating out the parameters\n\n\n\\[\np(\\boldsymbol{y_{pred}}\\mid \\boldsymbol{y} ) = \\int_{\\boldsymbol{\\Theta}} p(\\boldsymbol{y_{pred}}, \\boldsymbol{\\Theta}\\mid \\boldsymbol{y})\\, d\\boldsymbol{\\Theta}= \\int_{\\boldsymbol{\\Theta}}\np(\\boldsymbol{y_{pred}}\\mid \\boldsymbol{\\Theta},\\boldsymbol{y})p(\\boldsymbol{\\Theta}\\mid \\boldsymbol{y})\\, d\\boldsymbol{\\Theta}\n\\] - assuming the past and future observations are conditionally independent given \\(\\theta\\), the above equation can be written as:\n\\[\np(\\boldsymbol{y_{pred}}\\mid \\boldsymbol{y} )=\\int_{\\boldsymbol{\\Theta}} p(\\boldsymbol{y_{pred}}\\mid \\boldsymbol{\\Theta}) p(\\boldsymbol{\\Theta}\\mid \\boldsymbol{y})\\, d\\boldsymbol{\\Theta}\n\\tag{3.8}\n\\]\n\nthis posterior predictive distribution has important differences from predictions obtained with the frequentist approach\n\nfrequentist: gives a point estimate of each predicted observation given the maximum likelihood estimate of \\(\\theta\\) (a point value)\nBayesian: gives a distribution of values for each predicated observation\n\nas with the prior predictive distribution, the integration can be carried out computationally by generating samples from the posterior predictive distribution\n\nwe can use the same function normal_predictive_distribution() as created above; the only difference is that the samples come from the posterior, not from mu and sigma\n\n\n\nN_obs &lt;- nrow(df_spacebar)\nmu_samples &lt;- as_draws_df(fit_press)$b_Intercept\nsigma_samples &lt;- as_draws_df(fit_press)$sigma\nnormal_predictive_distribution(\n  mu_samples = mu_samples,\n  sigma_samples = sigma_samples,\n  N_obs = N_obs\n)\n\n# A tibble: 1,444,000 × 3\n   trialn rt_pred  iter\n    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1      1    170.     1\n 2      2    171.     1\n 3      3    165.     1\n 4      4    165.     1\n 5      5    214.     1\n 6      6    206.     1\n 7      7    165.     1\n 8      8    149.     1\n 9      9    122.     1\n10     10    177.     1\n# ℹ 1,443,990 more rows\n\n\n\nthe function brms::posterior_predict() is convenient, as it delivers samples from the posterior predictive distribution\n\nin a matrix, with the samples as rows and observations (data-points) as columns; so for fit_press there’d be 361 columns\nN.B., if the model is fit with sample_prior = \"only\", the dependent variable is ignored and posterior_predict will give samples from the prior predictive distribution\n\nthe posterior predictive distirubtion can be used to examine the ‘descriptive adequacy’ of the model under consideration\n\nthis is called posterior predictive checks\nthe goal is to establish that the posterior predictive data look more or less similar to the observed data\nachieveing ‘descriptive adequacy’ means the current data could have been generated by the model\n\npass a test of descriptive adequacy is not strong evidence in favour of a model, but a major failure in descriptive adequacy can be interpreted as strong evidence against a model (i.e., passing the test is necessary but not sufficient evidence in favour of the model)\nin addition, one should check that the range of predictions that the model makes is reasonably constrained\n\nif a model can capture any possible outcome, then the model fit to a particular data set is not so informative\nthus, posterior predictive checking is important but only a sanity check to assess whether the model behaviour is reasonable\n\nwe can usually just use the plot functions from brms\n\ne.g., ppcheck() takes as arguments the model, number of predicted data sets, and the type of visualisation\n\nin these plots, the observed data are plotted as \\(y\\), and predicted data as \\(y_{rep}\\)\n\n\n\n\n# histograms\npp_check(fit_press, # model\n         ndraws = 11, # n of predicted data sets\n         type = \"hist\" # plot type\n         )\n\n\n\n\n\n\n\n\n\n# layered density plots\npp_check(fit_press, # model\n         ndraws = 100, # n of predicted data sets\n         type = \"dens_overlay\" # plot type\n         )\n\n\n\n\n\n\n\n\n\nwe see the data (\\(y\\)) is slightly skewed and has no values smaller than 100ms, but the predictive distributions are centered and symmetrical\n\nso the posterior predictive check shows a slight mismatch between the observed and predicted data\n\nCan we build a better model? Let’s see…\n\n\n4.6.1 Comparing different likelihoods\n\nresponse times are not usually normally distributed\n\nlog-normal distribution would be more realistic\n\n\n\n\n4.6.2 The log-normal likelihood\n\nif \\(y\\) is log-normally distributed, that means that \\(log(y)\\) is normally distributed\n\nthe log-normal distribution is also defined using the parameters location (\\(\\mu\\)) and scale (\\(\\sigma\\)), but these are on the log ms scale and correspond to the mean and standard deviation of the logarithm of the data \\(y\\), \\(log(y)\\), which will be normally distributed\ntherefore, when we model some data \\(y\\) using the log-normal likelihood, the parameters \\(\\mu\\) and \\(\\sigma\\) are on a different scale than the data \\(y\\), which is represented here:\n\n\n\\[\n\\begin{aligned}\n\\log(\\boldsymbol{y}) &\\sim \\mathit{Normal}( \\mu, \\sigma)\\\\\n\\boldsymbol{y} &\\sim \\mathit{LogNormal}( \\mu, \\sigma)\n\\end{aligned}\n\\tag{3.9}\n\\]\n\nwe can obtain samples from the log-normal distribution, using the normal distribution by first setting an auxiliary variable, \\(z\\), so that \\(z = log(y)\\)\n\nso, \\(z \\sim Normal(\\mu, \\sigma)\\)\nthen we can use \\(exp(z)\\) as samples from the \\(LogNormal(\\mu,\\sigma)\\)\nsince exp(\\(z\\)) = exp(log(\\(y\\))) = \\(y\\)\n\n\n\nmu &lt;- 6\nsigma &lt;- 0.5\nN &lt;- 500000\n# Generate N random samples from a log-normal distribution\nsl &lt;- rlnorm(N, mu, sigma)\nggplot(tibble(samples = sl), aes(samples)) +\n  geom_histogram(aes(y = ..density..), binwidth = 50) +\n  ggtitle(\"Log-normal distribution\\n\") +\n  coord_cartesian(xlim = c(0, 2000))\n\n\n\n\n\n\n\n# Generate N random samples from a normal distribution,\n# and then exponentiate them\nsn &lt;- exp(rnorm(N, mu, sigma))\nggplot(tibble(samples = sn), aes(samples)) +\n  geom_histogram(aes(y = ..density..), binwidth = 50) +\n  ggtitle(\"Exponentiated samples from\\na normal distribution\") +\n  coord_cartesian(xlim = c(0, 2000))\n\n\n\n\n\n\n\n\n\n\n4.6.3 Re-fitting a single subject pressing a button repeatedly with a log-normal likelihood\n\nif we assume that response times are log-normally distributed, we’ll need to change our likelihood function as follows:\n\n\\[\nrt_n \\sim LogNormal(\\mu, \\sigma)\n\\]\n\nbut now the scale of our priors needs to change!\n\nstarting with uniform priors for ease of exposition, although these are really not appropriate:\n\n\n\\[\n\\begin{align}\n\\mu &\\sim Uniform(0,11)\\\\\n\\sigma &\\sim Uniform(0,1)\n\\end{align}\n\\]\n\nbecause the parameters are on a different scale than the dependent variable, their interpretation chagnes and it is more complex than dealing with a linear model that assumes a normal likelihood (location and scale do not coincide with the mean and standard deviation of the log-normal)\n\nthe location, \\(\\mu\\): in our previous linear model, \\(\\mu\\) represented the mean\n\nnow the mean needs to be calculated in the following way: exp(\\(\\frac{\\mu + \\sigma^2}{2}\\))\ni.e., in the log-normal, the mean is dependent on both \\(\\mu\\) and \\(\\sigma\\)\nthe median is just exp(\\(\\mu\\))\nN.B., the prior of \\(\\mu\\) is not on the milliseconds scale, but the log milliseconds scale\n\nthe scale, \\(\\sigma\\): the standard deviation of the normal distribution of log(\\(y\\))\n\nthe standard deviation of a log-normal distribution with location \\(\\mu\\) and scale \\(\\sigma\\) will be exp(\\(\\frac{\\mu + \\sigma^2}{2} \\times \\sqrt{exp(\\sigma^2) - 1}\\))\nunlike the normal distribution, the spread of the log-normal distribution depends on both \\(\\mu\\) and \\(\\sigma\\)\n\n\nto understand the meaning of our priors on the millisecond scale, we need to take into account both the priors and the likelihood; this can be done by generating a prior predictive distribution\n\nwe can just exponentiate the samples produced by normal_predictive_distribution()\n\n\n\nN_samples &lt;- 1000\nN_obs &lt;- nrow(df_spacebar)\nmu_samples &lt;- runif(N_samples, 0, 11)\nsigma_samples &lt;- runif(N_samples, 0, 1)\nprior_pred_ln &lt;- normal_predictive_distribution(\n  mu_samples = mu_samples,\n  sigma_samples = sigma_samples,\n  N_obs = N_obs\n) %&gt;%\n  mutate(rt_pred = exp(rt_pred))\n\n\nwe can’t generate negative values anymore (exp(any finite number) &gt; 0)\n\nthese priors might work in the sense that the model might converge, but it would be better to have regularizing priors for the model, such as:\n\n\n\\[\n\\begin{align}\n\\mu &\\sim Normal(6,1.5)\\\\\n\\sigma &\\sim Normal_+(0,1)\n\\end{align}\n\\]\n\nthe prior for \\(\\sigma\\) is a truncated distribution\n\nalthough its location is 0, this is not the mean\nwe can calculate its approximate mean from a large number of random samples of the prior distribution using the function extraDistr::rtnorm(), where the parameter a = 0 expresses the fact that the normal distribution is truncated from the left at 0\n\n\n\nmean(rtnorm(100000, # generate n = 100,000\n            0, 1,\n            a = 0 # truncate at 0\n)\n)\n\n[1] 0.7983271\n\n\n\nand even before generating the prior predictive distribution, we can calculate the values within which we are 95% sure the expected median of the observations will lie\n\nwe can do this by looking at what happens at 2 standard deviations away from the mean of the prior, \\(\\mu\\), that is \\(6 - 2 \\times 1.5\\) and \\(6 + 2 \\times 1.5\\), and exponentiating these values\n\n\n\nround(c(lower = exp(6 - 2 * 1.5),\n        higher = exp(6 + 2 * 1.5)),\n      1)\n\n lower higher \n  20.1 8103.1 \n\n\n\nso our prior for \\(\\mu\\) is still not too informative (these are medians, the actual values generated by the log-normal distribution can be much more spread out)\n\nwe can now plot the distribution of some representative statistics of the prior preditive distributions using brms to sample from the priors ignoring the rt data, by setting sample_prior = \"only\"\nif we want to use brms to generate prior predictive data before collecting the data, we do need to have some non-NA vlaues as the dependent variable, rt\nsetting sample_prior = \"only\" will ignore the data, but we still need to add it: in this case, we add a vector of 1 as “data”\nwe need to specify that the familiy is lognormal()\n\n\n\n# create place-holder data (for cases where we don't yet have any data but want to check out the prior predictive distribution)\ndf_spacebar_ref &lt;- df_spacebar %&gt;%\n  mutate(rt = rep(1, n()))\n\n# now run a model that runs only prior samples\nfit_prior_press_ln &lt;- brm(rt ~ 1,\n  data = df_spacebar_ref,\n  family = lognormal(),\n  prior = c(\n    prior(normal(6, 1.5), class = Intercept),\n    prior(normal(0, 1), class = sigma)\n  ),\n  sample_prior = \"only\", # this is how we tell the model to only produce priors!\n  control = list(adapt_delta = .9),\n  file = here::here(\"models\", \"notes\", \"ch3\", \"fit_prior_press_ln\")\n)\n\n\nto avoid the warnings, we need to increase the adapt_delta parameter’s default value from 0.8 to 0.95 to simulate the data\nplot the prior predictive distribution of means with the following code\n\nto get a prior predictive distribution, we want to ignore the data, so set prefix = \"ppd\"\nIMPORTANTLY, this should be run on a model that had sample_prior = \"only\", and therefore ignored the data; otherwise we’d just be plotting the posterior\n\n\n\npp_check(fit_prior_press_ln, type = \"stat\", stat = \"mean\", prefix = \"ppd\") +\n  coord_cartesian(xlim = c(0.001, 300000)) +\n  scale_x_continuous(\"Response times [ms]\",\n    trans = \"log\",\n    breaks = c(0.001, 1, 100, 1000, 10000, 100000),\n    labels = c(\n      \"0.001\", \"1\", \"100\", \"1000\", \"10000\",\n      \"100000\"\n    )\n  ) +\n  ggtitle(\"Prior predictive distribution of means\")\n\n\n\n\n\n\n\n\n\nto plot the distribution of mimimum and maximum values, replace mean with min and max\n\n\np1 &lt;- pp_check(fit_prior_press_ln, type = \"stat\", stat = \"mean\", prefix = \"ppd\") +\n  coord_cartesian(xlim = c(0.001, 300000)) +\n  scale_x_continuous(\"Response times [ms]\",\n    trans = \"log\",\n    breaks = c(0.001, 1, 100, 1000, 10000, 100000),\n    labels = c(\n      \"0.001\", \"1\", \"100\", \"1000\", \"10000\",\n      \"100000\"\n    )\n  ) +\n  ggtitle(\"Prior predictive distribution of means\")\np2 &lt;- pp_check(fit_prior_press_ln, type = \"stat\", stat = \"min\", prefix = \"ppd\") +\n  coord_cartesian(xlim = c(0.001, 300000)) +\n  scale_x_continuous(\"Response times [ms]\",\n    trans = \"log\",\n    breaks = c(0.001, 1, 100, 1000, 10000, 100000),\n    labels = c(\n      \"0.001\", \"1\", \"100\", \"1000\", \"10000\",\n      \"100000\"\n    )\n  ) +\n  ggtitle(\"Prior predictive distribution of minimum values\")\np3 &lt;- pp_check(fit_prior_press_ln, type = \"stat\", stat = \"max\", prefix = \"ppd\") +\n  coord_cartesian(xlim = c(0.001, 300000)) +\n  scale_x_continuous(\"Response times [ms]\",\n    trans = \"log\",\n    breaks = c(0.001, 1, 100, 1000, 10000, 100000),\n    labels = c(\n      \"0.001\", \"1\", \"10\", \"1000\", \"10000\",\n      \"100000\"\n    )\n  ) +\n  ggtitle(\"Prior predictive distribution of maximum values\")\nplot_grid(p1, p2, p3, nrow = 3, ncol =1)\n\n\n\n\n\n\n\n\n\nthese plots show that the priors that we are using are still quite uninformative\n\nthe tails of the prior predictive distributions that correspond to our normal priors (shown above) are even further to the right, reaching more extreme values than for the prior predictive distributions generated by uniform priors\nour new priors are still far from representing our prior knowledge\nwe can use summary statistics to test whether the priors are in a plausible range by defining the extreme data that would be very implausible to ever observe\n\n\n\nfit_press_ln &lt;- brm(rt ~ 1,\n  data = df_spacebar,\n  family = lognormal(),\n  prior = c(\n    prior(normal(6, 1.5), class = Intercept),\n    prior(normal(0, 1), class = sigma)\n  ),\n  file = here::here(\"models\", \"notes\", \"ch3\", \"fit_press_ln\")\n)\n\n\nwhen we look at the summary of the posterior, the parameters are on the log-scale\n\n\nfit_press_ln\n\n Family: lognormal \n  Links: mu = identity; sigma = identity \nFormula: rt ~ 1 \n   Data: df_spacebar (Number of observations: 361) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     5.12      0.01     5.10     5.13 1.00     3528     2782\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.13      0.01     0.13     0.15 1.00     2971     2621\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nif we want to know how long it takes to press the space bar in milliseconds, we need to transform the \\(\\mu\\) (or Intercept in the model) to milliseconds; we know that the median of the log-normal distribution is exp(\\(\\mu\\)), so we do the following to calculate an estimate in milliseconds:\n\n\nestimate_ms &lt;- exp(as_draws_df(fit_press_ln)$b_Intercept)\n\n\nif we want to know the mean and 95% CrI of these samples:\n\n\nc(mean = mean(estimate_ms), quantile(estimate_ms, probs = c(.025, .975)))\n\n    mean     2.5%    97.5% \n167.0491 164.6491 169.4007 \n\n\n\nwe can now check whether our predicted data sets look similar to the observed data\n\n\npp_check(fit_press_ln, ndraws = 100)\n\n\n\n\n\n\n\n\n\nhere it seems the posterior predicted data are more similar to the observed data, compared to when we had the normal likelihood\n\nbut it’s not easy to tell\n\nanother way to examine the extent to which the prediced data looks similar to the observed data: look at the distribution of some summary statistics\n\njust like with the prior predictive distributions, examine the distribution of representative summary statistics for the data sets generated by different models\nhowever, unlike with prior predictive distributions, we now have a clear reference: our observed data (which we ignore/don’t have yet for prior predictive distributions)\n\nwe suspect that the normal distribution would generate response times that are too fast (since it’s symmetrical) and that the log-normal distribution may capture the long tail better than the normal model\n\nbased on this, we compute the distribution of minimum and maximum values for the posterior predictive distributions, adn compare them with the minimum and maximum values respectively in the data\nwe cn use pp_check() to do this, by using as stat min or max for our models fit_press (normal distribution) and fit_press_ln (log-normal distribution)\n\n\n\nggpubr::ggarrange(\n  # normal min\n  pp_check(fit_press, type = \"stat\", stat = \"min\") + \n    labs(title = \"Normal model (min)\") +\n    theme_bw() + theme(legend.position = \"none\"),\n  # normal max\n  pp_check(fit_press, type = \"stat\", stat = \"max\") + \n    labs(title = \"Normal model (max)\") +\n    theme_bw() + theme(legend.position = \"none\"),\n  # log-normal min\n    pp_check(fit_press_ln, type = \"stat\", stat = \"min\") + \n    labs(title = \"Log-normal model (min)\") +\n    theme_bw() + theme(legend.position = \"none\"),\n  # log-normal max\n  pp_check(fit_press_ln, type = \"stat\", stat = \"max\") + \n    labs(title = \"Log-normal model (max)\") +\n    theme_bw() + theme(legend.position = \"none\"),\n  cowplot::get_legend(pp_check(fit_press_ln, type = \"stat\", stat = \"max\") + theme(legend.position = \"bottom\")),\n  nrow = 3, ncol = 2, \n  heights = c(.45,.45,.1),\n  labels = c(\"A\",\"B\",\"C\",\"D\")\n)\n\n\n\n\n\n\n\n\n\nhere we see the log-normal does a slightly better job since the minimum value is contained in the bulk of the log-normal distribution and in the tai of the normal one",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ch. 3</span>"
    ]
  },
  {
    "objectID": "book_notes/ch3.html#list-of-most-important-commands",
    "href": "book_notes/ch3.html#list-of-most-important-commands",
    "title": "3  Ch. 3",
    "section": "4.7 List of most important commands",
    "text": "4.7 List of most important commands\n\ncore brms function for fitting models, for generating prior predictive and posterior predictive data\n\n\nfit_press &lt;- brm(rt ~ 1,\n  data = df_spacebar,\n  family = gaussian(),\n  prior = c(\n    prior(uniform(0, 60000), class = Intercept, lb = 0, ub = 60000),\n    prior(uniform(0, 2000), class = sigma, lb = 0, ub = 2000)\n  ),\n  chains = 4,\n  iter = 2000,\n  warmup = 1000,\n  file = here::here(\"models\", \"notes\", \"ch3\", \"fit_press\")\n  ## uncomment for prior predictive:\n  ## sample_prior = \"only\",\n  ## uncomment when dealing with divergent transitions\n  ## control = list(adapt_delta = .9)\n)\n\n\nextract samples from fitted model:\n\n\nas_draws_df(fit_press)\n\n# A draws_df: 1000 iterations, 4 chains, and 5 variables\n   b_Intercept sigma Intercept lprior  lp__\n1          167    25       167    -19 -1683\n2          171    26       171    -19 -1684\n3          167    26       167    -19 -1684\n4          168    26       168    -19 -1684\n5          170    25       170    -19 -1684\n6          169    25       169    -19 -1683\n7          169    25       169    -19 -1683\n8          168    25       168    -19 -1683\n9          171    25       171    -19 -1684\n10         167    24       167    -19 -1685\n# ... with 3990 more draws\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\n\nbasic plot of posteriors\n\n\nplot(fit_press)\n\n\n\n\n\n\n\n\n\nplot prior predictive/posterior predictive data\n\n\n## Posterior predictive check:\npp_check(fit_press, ndraws = 100, type = \"dens_overlay\")\n\n\n\n\n\n\n\n## Plot posterior predictive distribution of statistical summaries:\npp_check(fit_press, ndraws = 100, type = \"stat\", stat = \"mean\") +\n  labs(title = \"Posterior predictive distribution\")\n\n\n\n\n\n\n\n## Plot prior predictive distribution of statistical summaries:\npp_check(fit_press, ndraws = 100, type = \"stat\", stat = \"mean\",\n         prefix = \"ppd\") +\n  labs(title = \"Prior predictive distribution\")",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ch. 3</span>"
    ]
  },
  {
    "objectID": "book_notes/ch3.html#summary",
    "href": "book_notes/ch3.html#summary",
    "title": "3  Ch. 3",
    "section": "4.8 Summary",
    "text": "4.8 Summary\n\nin this chapter we:\n\nlearned how to fit and interpret a Bayesian model with a normal likelihood\nlooked at the effect of priors by means of prior predictive distributions and sensitivity analysis\nlooked at the fit of the posterior by inspecting the posterior predictive distribution (which givees us some idea about the descriptive adequacy of the model)\nlearned how to fit a Bayesian model with a log-normal likelihood, and how to compare the predictive accuracy of different models",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ch. 3</span>"
    ]
  },
  {
    "objectID": "book_notes/ch8.html",
    "href": "book_notes/ch8.html",
    "title": "4  Contrast Coding",
    "section": "",
    "text": "Set up\n# set global knit options\nknitr::opts_chunk$set(echo = T, # print chunks?\n                      eval = T, # run chunks?\n                      error = F, # print errors?\n                      warning = F, # print warnings?\n                      message = F, # print messages?\n                      cache = F # cache?; be careful with this!\n                      )\n\n# suppress scientific notation\noptions(scipen=999)\n\n# play a sound if error encountered\noptions(error = function() {beepr::beep(9)})\n\n# load packages\n## create list of package names\npackages &lt;- c( #\"SIN\", # this package was removed from the CRAN repository\n               \"MASS\", \"dplyr\", \"tidyr\", \"purrr\", \"extraDistr\", \"ggplot2\", \"loo\", \"bridgesampling\", \"brms\", \"bayesplot\", \"tictoc\", \"hypr\", \"bcogsci\", \"papaja\", \"grid\", \"kableExtra\", \"gridExtra\", \"lme4\", \"cowplot\", \"pdftools\", \"cmdstanr\", \"rootSolve\", \"rstan\"\n  )\n\n# NB: if you haven't already installed bcogsci through devtools, it won't be loaded\n## Now load or install & load all\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n    }\n  }\n)\n\n# this is also required, taken from the textbook\n\n## Save compiled models:\nrstan_options(auto_write = FALSE)\n## Parallelize the chains using all the cores:\noptions(mc.cores = parallel::detectCores())\n# To solve some conflicts between packages\nselect &lt;- dplyr::select\nextract &lt;- rstan::extract",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrast Coding</span>"
    ]
  },
  {
    "objectID": "book_notes/ch8.html#data",
    "href": "book_notes/ch8.html#data",
    "title": "4  Contrast Coding",
    "section": "4.1 Data",
    "text": "4.1 Data\nLoad in a simulated dataset with RTs for two conditions: F1 and F2.\n\ndata(\"df_contrasts1\")\n\n\nhead(df_contrasts1)\n\n# A tibble: 6 × 3\n  F        DV    id\n  &lt;fct&gt; &lt;dbl&gt; &lt;int&gt;\n1 F1    0.636     1\n2 F1    0.841     2\n3 F1    0.555     3\n4 F1    1.03      4\n5 F1    0.938     5\n6 F2    0.123     6",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrast Coding</span>"
    ]
  },
  {
    "objectID": "book_notes/ch8.html#basic-concepts-illustrated-using-a-two-level-factor",
    "href": "book_notes/ch8.html#basic-concepts-illustrated-using-a-two-level-factor",
    "title": "4  Contrast Coding",
    "section": "4.2 Basic concepts illustrated using a two-level factor",
    "text": "4.2 Basic concepts illustrated using a two-level factor\n\n4.2.1 Default contrast coding\n\n\n4.2.2 Defining comparions\n\n\n4.2.3 Sum contrasts\n\n\n4.2.4 Cell means parameterization",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrast Coding</span>"
    ]
  },
  {
    "objectID": "book_notes/ch8.html#the-hypohtesis-matrix",
    "href": "book_notes/ch8.html#the-hypohtesis-matrix",
    "title": "4  Contrast Coding",
    "section": "4.3 The hypohtesis matrix",
    "text": "4.3 The hypohtesis matrix\n\n4.3.1 Sum contrasts\n\n\n4.3.2 They hypothesis matrix\n\n\n4.3.3 Generating contrasts: the hypr package\n\nto use the 4-step procedure (i.e., to flexibly design contrasts to estimate specific comparisons), the authors developed the hypr package\n\ncan specify desired comparisons and generate contrast matrices",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrast Coding</span>"
    ]
  },
  {
    "objectID": "book_notes/ch8.html#other-types-of-contrasts",
    "href": "book_notes/ch8.html#other-types-of-contrasts",
    "title": "4  Contrast Coding",
    "section": "4.4 Other types of contrasts:",
    "text": "4.4 Other types of contrasts:\n\n4.4.1 Repeated contrasts\n\n\n4.4.2 Helmert contrasts\n\n\n4.4.3 Contrasts in linear regression\n\n\n4.4.4 Plynomial contrasts\n\n\n4.4.5 An alternative to contrasts",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrast Coding</span>"
    ]
  },
  {
    "objectID": "book_notes/ch8.html#what-makes-a-good-set-of-contrasts",
    "href": "book_notes/ch8.html#what-makes-a-good-set-of-contrasts",
    "title": "4  Contrast Coding",
    "section": "4.5 What makes a good set of contrasts",
    "text": "4.5 What makes a good set of contrasts\n\n4.5.1 Centered contrasts\n\n\n4.5.2 Orthogonal contrasts\n\n\n4.5.3 The role of the intercept",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrast Coding</span>"
    ]
  },
  {
    "objectID": "book_notes/ch8.html#computing-condition-means",
    "href": "book_notes/ch8.html#computing-condition-means",
    "title": "4  Contrast Coding",
    "section": "4.6 Computing condition means",
    "text": "4.6 Computing condition means",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrast Coding</span>"
    ]
  },
  {
    "objectID": "book_notes/ch8.html#summary",
    "href": "book_notes/ch8.html#summary",
    "title": "4  Contrast Coding",
    "section": "4.7 Summary",
    "text": "4.7 Summary",
    "crumbs": [
      "Book notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrast Coding</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch1_exercises.html",
    "href": "book_exercises/ch1_exercises.html",
    "title": "5  Ch. 1 Exercises",
    "section": "",
    "text": "Set options\nCode\n# set global knit options\nknitr::opts_chunk$set(echo = T,\n                      eval = T,\n                      error = F,\n                      warning = F,\n                      message = F,\n                      cache = F)\n\n# suppress scientific notation\noptions(scipen=999)\n\n# list of required packages\npackages &lt;- c( #\"SIN\", # this package was removed from the CRAN repository\n               \"MASS\", \"dplyr\", \"tidyr\", \"purrr\", \"extraDistr\", \"ggplot2\", \"loo\", \"bridgesampling\", \"brms\", \"bayesplot\", \"tictoc\", \"hypr\", \"bcogsci\", \"papaja\", \"grid\", \"kableExtra\", \"gridExtra\", \"lme4\", \"cowplot\", \"pdftools\", \"cmdstanr\", \"rootSolve\", \"rstan\"\n  )\n\n# NB: if you haven't already installed bcogsci through devtools, it won't be loaded\n## Now load or install & load all\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n    }\n  }\n)\n\n# this is also required, taken from the textbook\n\n## Save compiled models:\nrstan_options(auto_write = FALSE)\n## Parallelize the chains using all the cores:\noptions(mc.cores = parallel::detectCores())\n# To solve some conflicts between packages\nselect &lt;- dplyr::select\nextract &lt;- rstan::extract",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ch. 1 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch1_exercises.html#exercise-1.1-practice-using-the-pnorm-function---part-1",
    "href": "book_exercises/ch1_exercises.html#exercise-1.1-practice-using-the-pnorm-function---part-1",
    "title": "5  Ch. 1 Exercises",
    "section": "Exercise 1.1 Practice using the pnorm function - Part 1",
    "text": "Exercise 1.1 Practice using the pnorm function - Part 1\n\nGiven a normal distribution with mean 500 and standard deviation 100, use the pnorm function to calculate the probability of obtaining values between 200 and 800 from this distribution.\n\n\npnorm(800, 500, 100) - pnorm(200, 500, 100)\n\n[1] 0.9973002",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ch. 1 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch1_exercises.html#exercise-1.2-practice-using-the-pnorm-function---part-2",
    "href": "book_exercises/ch1_exercises.html#exercise-1.2-practice-using-the-pnorm-function---part-2",
    "title": "5  Ch. 1 Exercises",
    "section": "Exercise 1.2 Practice using the pnorm function - Part 2",
    "text": "Exercise 1.2 Practice using the pnorm function - Part 2\n\nCalculate the following probabilities. Given a normal distribution with mean 800 and standard deviation 150, what is the probability of obtaining:\n\na score of 700 or less\na score of 900 or more\na score of 800 or more\n\n\n\n# 700 or more\npnorm(700,800,150)\n\n[1] 0.2524925\n\n# 900, 800 or more\npnorm(c(900,800), 800,150, lower.tail=F)\n\n[1] 0.2524925 0.5000000",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ch. 1 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch1_exercises.html#exercise-1.3-practice-using-the-pnorm-function---part-3",
    "href": "book_exercises/ch1_exercises.html#exercise-1.3-practice-using-the-pnorm-function---part-3",
    "title": "5  Ch. 1 Exercises",
    "section": "Exercise 1.3 Practice using the pnorm function - Part 3",
    "text": "Exercise 1.3 Practice using the pnorm function - Part 3\n\nGiven a normal distribution with mean 600 and standard deviation 200, what is the probability of obtaining:\n\na score of 550 or less.\na score between 300 and 800.\na score of 900 or more.\n\n\n\n# 550 or less\npnorm(q = 550, \n      m = 600, sd = 200)\n\n[1] 0.4012937\n\n# 300-800\npnorm(q = 800, \n      m = 600, sd = 200) - pnorm(q = 300, m = 600, sd = 200)\n\n[1] 0.7745375\n\n# 900 or more\npnorm(q = 900, \n      m = 600, sd = 200, lower.tail=F)\n\n[1] 0.0668072",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ch. 1 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch1_exercises.html#exercise-1.4-practice-using-the-qnorm-function---part-1",
    "href": "book_exercises/ch1_exercises.html#exercise-1.4-practice-using-the-qnorm-function---part-1",
    "title": "5  Ch. 1 Exercises",
    "section": "Exercise 1.4 Practice using the qnorm function - Part 1",
    "text": "Exercise 1.4 Practice using the qnorm function - Part 1\n\nConsider a normal distribution with mean 1 and standard deviation 1. Compute the lower and upper boundaries such that:\n\nthe area (the probability) to the left of the lower boundary is 0.10.\nthe area (the probability) to the left of the upper boundary is 0.90.\n\n\n\n# lower bound is .1\nqnorm(p = .1,\n      mean = 1, sd = 1)\n\n[1] -0.2815516\n\n# lower bound is .9\nqnorm(p = .9,\n      mean = 1, sd = 1)\n\n[1] 2.281552",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ch. 1 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch1_exercises.html#exercise-1.5-practice-using-the-qnorm-function---part-2",
    "href": "book_exercises/ch1_exercises.html#exercise-1.5-practice-using-the-qnorm-function---part-2",
    "title": "5  Ch. 1 Exercises",
    "section": "Exercise 1.5 Practice using the qnorm function - Part 2",
    "text": "Exercise 1.5 Practice using the qnorm function - Part 2\n\nGiven a normal distribution with mean 650 and standard deviation 125. There exist two quantiles, the lower quantile q1 and the upper quantile q2, that are equidistant from the mean 650, such that the area under the curve of the normal between q1 and q2 is 80%. Find q1 and q2.\n\n\nq1 &lt;- qnorm(p =.1,\n            mean = 650, sd = 125)\nq2 &lt;- qnorm(p =.9,\n            mean = 650, sd = 125)\nq1; q2\n\n[1] 489.8061\n\n\n[1] 810.1939\n\n# check this is right\npnorm(q = q2, \n      m = 650, sd = 125) - pnorm(q = q1, m = 650, sd = 125)\n\n[1] 0.8",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ch. 1 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch1_exercises.html#exercise-1.6-practice-getting-summaries-from-samples---part-1",
    "href": "book_exercises/ch1_exercises.html#exercise-1.6-practice-getting-summaries-from-samples---part-1",
    "title": "5  Ch. 1 Exercises",
    "section": "Exercise 1.6 Practice getting summaries from samples - Part 1",
    "text": "Exercise 1.6 Practice getting summaries from samples - Part 1\n\nGiven data that is generated as follows:\n\n\ndata_gen1 &lt;- rnorm(1000, 300, 200)\n\n\nCalculate the mean, variance, and the lower quantile q1 and the upper quantile q2, that are equidistant and such that the range of probability between them is 80%.\n\n\nmean &lt;- mean(data_gen1)\nsd &lt;- sd(data_gen1)\n\nq1 &lt;- qnorm(.1,\n            mean,sd)\nq2 &lt;- qnorm(.9,\n            mean,sd)\nq1; q2\n\n[1] 51.17821\n\n\n[1] 566.0027\n\n# check\npnorm(q2,mean,sd) - pnorm(q1,mean,sd)\n\n[1] 0.8",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ch. 1 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch1_exercises.html#exercise-1.7-practice-getting-summaries-from-samples---part-2.",
    "href": "book_exercises/ch1_exercises.html#exercise-1.7-practice-getting-summaries-from-samples---part-2.",
    "title": "5  Ch. 1 Exercises",
    "section": "Exercise 1.7 Practice getting summaries from samples - Part 2.",
    "text": "Exercise 1.7 Practice getting summaries from samples - Part 2.\n\nThis time we generate the data with a truncated normal distribution from the package extraDistr. The details of this distribution will be discussed later in section 4.1 and in the Box 4.1, but for now we can treat it as an unknown generative process:\n\n\ndata_gen1 &lt;- extraDistr::rtnorm(1000, 300, 200, a = 0)\n\n\nCalculate the mean, variance, and the lower quantile q1 and the upper quantile q2, that are equidistant and such that the range of probability between them is 80%.\n\n\nmean &lt;- mean(data_gen1)\nsd &lt;- sd(data_gen1)\n\nq1 &lt;- qnorm(.1,\n            mean,sd)\nq2 &lt;- qnorm(.9,\n            mean,sd)\nq1; q2\n\n[1] 104.5784\n\n\n[1] 547.3193\n\n# check\npnorm(q2,mean,sd) - pnorm(q1,mean,sd)\n\n[1] 0.8",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ch. 1 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch1_exercises.html#exercise-1.8-practice-with-a-variance-covariance-matrix-for-a-bivariate-distribution.",
    "href": "book_exercises/ch1_exercises.html#exercise-1.8-practice-with-a-variance-covariance-matrix-for-a-bivariate-distribution.",
    "title": "5  Ch. 1 Exercises",
    "section": "Exercise 1.8 Practice with a variance-covariance matrix for a bivariate distribution.",
    "text": "Exercise 1.8 Practice with a variance-covariance matrix for a bivariate distribution.\n\nSuppose that you have a bivariate distribution where one of the two random variables comes from a normal distribution with mean \\(\\mu\\)X = 600 and standard deviation \\(\\sigma\\)X = 100, and the other from a normal distribution with mean \\(\\mu\\)Y = 400 and standard deviation \\(\\sigma\\)Y = 50. The correlation \\(\\rho\\)XY between the two random variables is 0.4. Write down the variance-covariance matrix of this bivariate distribution as a matrix (with numerical values, not mathematical symbols), and then use it to generate 100 pairs of simulated data points.\n\n\n# generate simulated bivariate data\n\n## define two RVs\n\n## define a VarCorr matrix, where rho = .6, variance\nSigma &lt;- matrix(c(\n  100^2, 100 * 50 * .4, \n  100 * 50 * .4, 100^2 \n  ),\n  byrow = F, ncol = 2\n  )\n\n## generate data\nu &lt;- as.data.frame(MASS::mvrnorm(n = 100, mu = c(600,400), Sigma = Sigma))\nhead(u, n=3)\n\n        V1       V2\n1 604.6691 451.5096\n2 507.7799 244.9854\n3 708.3528 516.4206\n\n\n\nPlot the simulated data such that the relationship between the random variables X and Y is clear.\n\n\nGenerate two sets of new data (100 pairs of data points each) with correlation −0.4 and 0, and plot these alongside the plot for the data with correlation 0.4.\n\n\n# generate simulated bivariate data\nrho &lt;- -.4\n## define a VarCorr matrix, where rho = 0, variance\nSigma &lt;- matrix(c(\n  100^2, 100 * 50 * rho, \n  100 * 50 * rho, 100^2 \n  ),\n  byrow = F, ncol = 2\n  )\n\n## generate data\nu4 &lt;- as.data.frame(MASS::mvrnorm(n = 100, mu = c(600,400), Sigma = Sigma))\n\n# generate simulated bivariate data\nrho &lt;- 0\n## define a VarCorr matrix, where rho = 0, variance\nSigma &lt;- matrix(c(\n  100^2, 100 * 50 * rho, \n  100 * 50 * rho, 100^2 \n  ),\n  byrow = F, ncol = 2\n  )\n\n## generate data\nu0 &lt;- as.data.frame(MASS::mvrnorm(n = 100, mu = c(600,400), Sigma = Sigma))\n\n\nggpubr::ggarrange(\n  ggplot2::ggplot(u, aes(x = V1, y = V2)) +\n    labs(title = \"rho = .4\") + \n    geom_point(),\n  ggplot2::ggplot(u4, aes(x = V1, y = V2)) +\n    labs(title =\"rho = .-4\") + \n    geom_point(),\n  ggplot2::ggplot(u0, aes(x = V1, y = V2)) +\n    labs(title =\"rho = 0\") + \n    geom_point(),\n  nrow = 1, labels = c(\"A\", \"B\", \"C\")\n)",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ch. 1 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch5_exercises.html",
    "href": "book_exercises/ch5_exercises.html",
    "title": "6  Ch. Exercises",
    "section": "",
    "text": "Set options\nCode\n# set global knit options\n# knitr::opts_chunk$set(echo = T,\n#                       eval = T,\n#                       error = F,\n#                       warning = F,\n#                       message = F,\n#                       cache = T)\n\n# suppress scientific notation\noptions(scipen=999)\n\n# list of required packages\npackages &lt;- c( #\"SIN\", # this package was removed from the CRAN repository\n               \"MASS\", \"dplyr\", \"tidyr\", \"purrr\", \"extraDistr\", \"ggplot2\", \"loo\", \"bridgesampling\", \"brms\", \"bayesplot\", \"tictoc\", \"hypr\", \"bcogsci\", \"papaja\", \"grid\", \"kableExtra\", \"gridExtra\", \"lme4\", \"cowplot\", \"pdftools\", \"cmdstanr\", \"rootSolve\", \"rstan\"\n  )\n\n# NB: if you haven't already installed bcogsci through devtools, it won't be loaded\n## Now load or install & load all\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n    }\n  }\n)\n\n# this is also required, taken from the textbook\n\n## Save compiled models:\nrstan_options(auto_write = FALSE)\n## Parallelize the chains using all the cores:\noptions(mc.cores = parallel::detectCores())\n# To solve some conflicts between packages\nselect &lt;- dplyr::select\nextract &lt;- rstan::extract",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ch. Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch5_exercises.html#exercise-5.1-a-hierarchical-model-normal-likelihood-of-cognitive-load-on-pupil-.",
    "href": "book_exercises/ch5_exercises.html#exercise-5.1-a-hierarchical-model-normal-likelihood-of-cognitive-load-on-pupil-.",
    "title": "6  Ch. Exercises",
    "section": "7.1 Exercise 5.1 A hierarchical model (normal likelihood) of cognitive load on pupil .",
    "text": "7.1 Exercise 5.1 A hierarchical model (normal likelihood) of cognitive load on pupil .\nAs in section 4.1, we focus on the effect of cognitive load on pupil , but this time we look at all the subjects of Wahn et al. (2016):\n\ndata(\"df_pupil_complete\")\ndf_pupil_complete\n\n# A tibble: 2,228 × 4\n    subj trial  load p_size\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;\n 1   701     1     2  1021.\n 2   701     2     1   951.\n 3   701     3     5  1064.\n 4   701     4     4   913.\n 5   701     5     0   603.\n 6   701     6     3   826.\n 7   701     7     0   464.\n 8   701     8     4   758.\n 9   701     9     2   733.\n10   701    10     3   591.\n# ℹ 2,218 more rows\n\n\nYou should be able to now fit a “maximal” model (correlated varying intercept and slopes for subjects) assuming a normal likelihood. Base your priors in the priors discussed in section 4.1.\n\n\n\n\n\n\nMaximal model\n\n\n\n\nfirst centre the predictor\n\n\ndf_pupil_complete &lt;- df_pupil_complete %&gt;%\n  mutate(c_load = load-mean(load))\n\n\nthen run the model\n\n\nfit_pupil &lt;- brm(p_size ~ 1 + c_load + \n                   (1 +c_load | subj), \n                 data = df_pupil_complete,\n                 family = gaussian(),\n                 prior = c(\n                   prior(normal(1000, 500), class = Intercept),\n                   prior(normal(0, 1000), class = sigma),\n                   prior(normal(0, 100), class = b, coef = c_load),\n                   prior(normal(0, 1000), class = sd),\n                   prior(lkj(2), class = cor)\n                 ),\n                 file = here::here(\"models\", \"exercises\", \"ch5\", \"fit_pupil\")\n                 )\n\n\n\n\nExamine the effect of load on pupil size, and the average pupil size. What do you conclude?\n\n\n\n\n\n\n\nMy solution\n\n\n\n\nfit_pupil\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: p_size ~ 1 + c_load + (1 + c_load | subj) \n   Data: df_pupil_complete (Number of observations: 2228) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~subj (Number of levels: 20) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)          3307.53    441.75  2508.84  4235.77 1.01      646\nsd(c_load)               70.18     14.34    46.89   102.39 1.00     1269\ncor(Intercept,c_load)     0.30      0.23    -0.18     0.69 1.00     1327\n                      Tail_ESS\nsd(Intercept)              658\nsd(c_load)                2262\ncor(Intercept,c_load)     1906\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept  2509.25    490.72  1527.81  3439.77 1.00      488      737\nc_load       40.46     22.95    -6.86    84.83 1.00     1260     1734\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma   505.27      7.61   490.27   520.55 1.00     5434     2639\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n95% CrI crosses 0: quite a bit of uncertainty\nalternatively, to only print c_load\n\n\nposterior_summary(fit_pupil, variable = \"b_c_load\")\n\n         Estimate Est.Error      Q2.5    Q97.5\nb_c_load 40.46367  22.94823 -6.863523 84.82657\n\n\n\nbut the intercept is quite large:\n\n\nposterior_summary(fit_pupil, variable = \"b_Intercept\")\n\n            Estimate Est.Error     Q2.5    Q97.5\nb_Intercept 2509.251  490.7152 1527.807 3439.766\n\n\n\neven though we assumed it wouldn’t be\n\n\nbrms::prior_summary(fit_pupil)\n\n                prior     class      coef group resp dpar nlpar lb ub\n               (flat)         b                                      \n       normal(0, 100)         b    c_load                            \n    normal(1000, 500) Intercept                                      \n lkj_corr_cholesky(2)         L                                      \n lkj_corr_cholesky(2)         L            subj                      \n      normal(0, 1000)        sd                                  0   \n      normal(0, 1000)        sd            subj                  0   \n      normal(0, 1000)        sd    c_load  subj                  0   \n      normal(0, 1000)        sd Intercept  subj                  0   \n      normal(0, 1000)     sigma                                  0   \n       source\n      default\n         user\n         user\n         user\n (vectorized)\n         user\n (vectorized)\n (vectorized)\n (vectorized)\n         user\n\n\n\noverly informative prior for the intercept?\n\n\n\n\nDo a sensitivity analysis for the prior on the intercept (\\(\\alpha\\)). What is the estimate of the effect (\\(\\beta\\)) under different priors?\n\n\n\n\n\n\n\nMy solution\n\n\n\n\ntry a wider prior for \\(\\alpha\\); I’m choosing 3000 and 1000ms\n\n\\[\n\\alpha \\sim Normal(3000,1000)\n\\]\n\nfit_pupil_2 &lt;- brm(p_size ~ 1 + c_load + \n                   (1 + c_load | subj), \n                 data = df_pupil_complete,\n                 family = gaussian(),\n                 prior = c(\n                   prior(normal(3000, 1000), class = Intercept),\n                   prior(normal(0, 1000), class = sigma),\n                   prior(normal(0, 100), class = b, coef = c_load),\n                   prior(normal(0, 1000), class = sd),\n                   prior(lkj(2), class = cor)\n                 ),\n                 file = here::here(\"models\", \"exercises\", \"ch5\", \"fit_pupil_2\")\n                 )\n\n\nposterior_summary(fit_pupil_2, variable = \"b_c_load\")\n\n         Estimate Est.Error     Q2.5    Q97.5\nb_c_load 56.46641  17.02009 22.75433 90.09126\n\n\n\nthe effect of c_load now ha more certainty\n\n\nposterior_summary(fit_pupil, variable = \"b_Intercept\")\n\n            Estimate Est.Error     Q2.5    Q97.5\nb_Intercept 2509.251  490.7152 1527.807 3439.766\n\n\n\n\n\nIs the effect of load consistent across subjects? Investigate this visually.\n\n\n\n\n\n\n\nMy solution\n\n\n\n\ncheck out overall effect; there are 3 peaks\n\n\npp_check(fit_pupil_2, ndraws = 50, type = \"dens_overlay\")\n\n\n\n\n\n\n\n\n\nnow by participants\n\n\nppc_dens_overlay_grouped(df_pupil_complete$p_size,\n  yrep =\n    posterior_predict(fit_pupil_2,\n      ndraws = 100\n    ),\n  group = df_pupil_complete$subj\n) +\n  xlab(\"Signal in the N400 spatiotemporal window\")\n\n\n\n\n\n\n\n\n\nand by sd\n\n\npp_check(fit_pupil_2,\n  type = \"stat_grouped\",\n  ndraws = 1000,\n  group = \"subj\",\n  stat = \"sd\"\n)\n\n\n\n\n\n\n\n\n\nand also:\n\n\n## For the hierarchical model is more complicated, # because we want the effect (beta) + adjustment: # we extract the overall group level effect:\nbeta &lt;- c(as_draws_df(fit_pupil_2)$b_c_load)\n# We extract the individual adjustments\nind_effects_v &lt;- paste0(\"r_subj[\", unique(df_pupil_complete$subj), \",c_load]\") \nadjustment &lt;- as.matrix(as_draws_df(fit_pupil)[ind_effects_v])\n# We get the by subject effects in a data frame where each adjustment # is in each column.\nby_subj_effect &lt;- as_tibble(beta + adjustment)\n# We summarize them by getting a table with the mean and the\n# quantiles for each column and then binding them.\npar_h &lt;- lapply(by_subj_effect, function(x) {\n  tibble(\n    Estimate = mean(x),\n    Q2.5 = quantile(x, .025),\n    Q97.5 = quantile(x, .975)\n  )\n}) %&gt;%\n  bind_rows() %&gt;%\n  # We add a column to identify that the model, # and one with the subject labels:\n  mutate(subj = unique(df_pupil_complete$subj)) %&gt;% arrange(Estimate) %&gt;%\n  mutate(subj = factor(subj, levels = subj))\nggplot(par_h,\n       aes(\n         ymin = Q2.5,\n         ymax = Q97.5,\n         x = subj,\n         y = Estimate\n       )) +\n  geom_errorbar() +\n  geom_point() +\n  # We'll also add the mean and 95% CrI of the overall difference # to the plot:\n  geom_hline(yintercept =\n               posterior_summary(fit_pupil_2)[\"b_c_load\", \"Estimate\"]) +\n  geom_hline(\n    yintercept =\n      posterior_summary(fit_pupil_2)[\"b_c_load\", \"Q2.5\"],\n    linetype = \"dotted\",\n    linewidth = .5\n  ) + geom_hline(\n    yintercept =\n      posterior_summary(fit_pupil_2)[\"b_c_load\", \"Q97.5\"],\n    linetype = \"dotted\",\n    linewidth = .5\n  ) +\n  coord_flip() +\n  ylab(\"Change in pupil size\") + \n  xlab(\"Participant ID\") +\n  theme_bw()",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ch. Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch5_exercises.html#exercise-5.2-are-subject-relatives-easier-to-process-than-object-relatives-log-normal-likelihood",
    "href": "book_exercises/ch5_exercises.html#exercise-5.2-are-subject-relatives-easier-to-process-than-object-relatives-log-normal-likelihood",
    "title": "6  Ch. Exercises",
    "section": "7.2 Exercise 5.2 Are subject relatives easier to process than object relatives (log-normal likelihood)?",
    "text": "7.2 Exercise 5.2 Are subject relatives easier to process than object relatives (log-normal likelihood)?\nWe begin with a classic question from the psycholinguistics literature: Are subject relatives easier to process than object relatives? The data come from Experiment 1 in a paper by Grodner and Gibson (2005).\nScientific question: Is there a subject relative advantage in reading?\nGrodner and Gibson (2005) investigate an old claim in psycholinguistics that object relative clause (ORC) sentences are more difficult to process than subject relative clause (SRC) sentences. One explanation for this predicted difference is that the distance between the relative clause verb (sent in the example below) and the head noun phrase of the relative clause (reporter in the example below) is longer in ORC vs. SRC. Examples are shown below. The relative clause is shown in square brackets.\n(1a) The reporter [who the photographer sent to the editor] was hoping for a good story. (ORC)\n(1b) The reporter [who sent the photographer to the editor] was hoping for a good story. (SRC)\nThe underlying explanation has to do with memory processes: Shorter linguistic dependencies are easier to process due to either reduced interference or decay, or both. For implemented computational models that spell this point out, see Lewis and Vasishth (2005) and Engelmann, Jäger, and Vasishth (2020).\nIn the Grodner and Gibson data, the dependent measure is reading time at the relative clause verb, (e.g., sent) of different sentences with either ORC or SRC. The dependent variable is in milliseconds and was measured in a self-paced reading task. Self-paced reading is a task where subjects read a sentence or a short text word-by-word or phrase-by-phrase, pressing a button to get each word or phrase displayed; the preceding word disappears every time the button is pressed. In 6.1, we provide a more detailed explanation of this experimental method.\nFor this experiment, we are expecting longer reading times at the relative clause verbs of ORC sentences in comparison to the relative clause verb of SRC sentences.\n\ndata(\"df_gg05_rc\")\ndf_gg05_rc\n\n# A tibble: 672 × 7\n    subj  item condition    RT residRT qcorrect experiment\n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt; &lt;chr&gt;     \n 1     1     1 objgap      320  -21.4         0 tedrg3    \n 2     1     2 subjgap     424   74.7         1 tedrg2    \n 3     1     3 objgap      309  -40.3         0 tedrg3    \n 4     1     4 subjgap     274  -91.2         1 tedrg2    \n 5     1     5 objgap      333   -8.39        1 tedrg3    \n 6     1     6 subjgap     266  -87.3         1 tedrg2    \n 7     1     7 objgap      327  -42.2         1 tedrg3    \n 8     1     8 subjgap     279  -90.2         1 tedrg2    \n 9     1     9 objgap      342  -23.2         1 tedrg3    \n10     1    10 subjgap     297  -52.3         0 tedrg2    \n# ℹ 662 more rows\n\n\nYou should use a sum coding for the predictors. Here, object relative clauses (“objgaps”) are coded +1, subject relative clauses -1.\n\n\n\n\n\n\nSet contrasts\n\n\n\n\ndf_gg05_rc$condition &lt;- factor(df_gg05_rc$condition, levels = c(\"subjgap\",\"objgap\"))\nclass(df_gg05_rc$condition)\n\n[1] \"factor\"\n\ncontrasts(df_gg05_rc$condition) &lt;- c(-.5,+.5)\ncontrasts(df_gg05_rc$condition)\n\n        [,1]\nsubjgap -0.5\nobjgap   0.5\n\n\n\nor, as in the book:\n\n\ndf_gg05_rc &lt;- df_gg05_rc %&gt;%\n  mutate(c_cond = if_else(condition == \"objgap\", .5, -.5))\n\n\n\nYou should be able to now fit a “maximal” model (correlated varying intercept and slopes for subjects and for items) assuming a log-normal likelihood.\n\n\n\n\n\n\nMaximal model\n\n\n\n\nfit_df_gg05_rc &lt;-\n  brm(\n    RT ~ condition + (condition |\n                     subj) + (condition | item),\n    family = lognormal(),\n    prior =\n      c(\n        prior(normal(6, 1.5), class = Intercept),\n        prior(normal(0, .1), class = b),\n        prior(normal(0, 1), class = sigma),\n        prior(normal(0, 1), class = sd),\n        prior(lkj(2), class = cor)\n      ),\n    data = df_gg05_rc,\n    file = here::here(\"models\", \"exercises\", \"ch5\", \"fit_df_gg05_rc\")\n  )\n\nfit_df_gg05_rc\n\n Family: lognormal \n  Links: mu = identity; sigma = identity \nFormula: RT ~ condition + (condition | subj) + (condition | item) \n   Data: df_gg05_rc (Number of observations: 672) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~item (Number of levels: 16) \n                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)                 0.04      0.02     0.00     0.09 1.00     1175\nsd(condition1)                0.09      0.05     0.01     0.19 1.00     1198\ncor(Intercept,condition1)     0.27      0.41    -0.63     0.89 1.00     1552\n                          Tail_ESS\nsd(Intercept)                 1284\nsd(condition1)                1456\ncor(Intercept,condition1)     1689\n\n~subj (Number of levels: 42) \n                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)                 0.33      0.04     0.26     0.41 1.00      884\nsd(condition1)                0.23      0.04     0.15     0.32 1.00     1831\ncor(Intercept,condition1)     0.51      0.16     0.15     0.79 1.00     1725\n                          Tail_ESS\nsd(Intercept)                 1545\nsd(condition1)                2535\ncor(Intercept,condition1)     1690\n\nRegression Coefficients:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      5.88      0.05     5.77     5.98 1.01      400      911\ncondition1     0.10      0.05     0.01     0.19 1.00     1329     2354\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.36      0.01     0.34     0.38 1.00     3195     2719\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\n\nExamine the effect of relative clause attachment site (the predictor c_cond) on reading times RT (\\(\\beta\\)).\n\n\n\n\n\n\n\nMy solution\n\n\n\n\nthe effect of RC attachment on RT on the log scale is\n\n\nposterior_summary(fit_df_gg05_rc, variable = \"b_condition1\")\n\n              Estimate  Est.Error       Q2.5     Q97.5\nb_condition1 0.1003678 0.04582792 0.01239481 0.1890053\n\n\n\n\n\nEstimate the median difference between relative clause attachment sites in milliseconds, and report the mean and 95% CI.\n\n\n\n\n\n\n\nMy solution\n\n\n\n\nalpha &lt;- as_draws_df(fit_df_gg05_rc)$b_Intercept\nbeta &lt;- as_draws_df(fit_df_gg05_rc)$b_condition1\n# Difference between object RC coded as .5 and subject RC coded as .5 \neffect &lt;- exp(alpha + beta * .5) - exp(alpha + beta * -.5)\nc(mean = mean(effect), quantile(effect, c(.025,.975)))\n\n     mean      2.5%     97.5% \n36.129476  4.483022 71.120079 \n\n\n\n\n\nDo a sensitivity analysis. What is the estimate of the effect (\\(\\beta\\)) under different priors? What is the difference in milliseconds between conditions under different priors?\n\n\n\n\n\n\n\nMy solution\n\n\n\n\nfirst let’s check out the fit of the model\n\n\npp_check(fit_df_gg05_rc, ndraws = 50, type = \"dens_overlay\")\n\n\n\n\n\n\n\n\n\nnow by participants\n\n\nppc_dens_overlay_grouped(df_gg05_rc$RT,\n  yrep =\n    posterior_predict(fit_df_gg05_rc,\n      ndraws = 100\n    ),\n  group = df_gg05_rc$subj\n) +\n  xlab(\"Signal in the N400 spatiotemporal window\")\n\n\n\n\n\n\n\n\n\nand by sd\n\n\npp_check(fit_df_gg05_rc,\n  type = \"stat_grouped\",\n  ndraws = 1000,\n  group = \"subj\",\n  stat = \"sd\"\n)\n\n\n\n\n\n\n\n\n\nposterior_summary(fit_df_gg05_rc, variable = \"b_condition1\")\n\n              Estimate  Est.Error       Q2.5     Q97.5\nb_condition1 0.1003678 0.04582792 0.01239481 0.1890053\n\n\n\nposterior_summary(fit_df_gg05_rc, variable = \"b_Intercept\")\n\n            Estimate Est.Error     Q2.5    Q97.5\nb_Intercept 5.875583 0.0535306 5.772643 5.982605\n\n\n\nour posteriors are pretty close to our priors\n\n\nbrms::prior_summary(fit_df_gg05_rc)\n\n                prior     class       coef group resp dpar nlpar lb ub\n       normal(0, 0.1)         b                                       \n       normal(0, 0.1)         b condition1                            \n       normal(6, 1.5) Intercept                                       \n lkj_corr_cholesky(2)         L                                       \n lkj_corr_cholesky(2)         L             item                      \n lkj_corr_cholesky(2)         L             subj                      \n         normal(0, 1)        sd                                   0   \n         normal(0, 1)        sd             item                  0   \n         normal(0, 1)        sd condition1  item                  0   \n         normal(0, 1)        sd  Intercept  item                  0   \n         normal(0, 1)        sd             subj                  0   \n         normal(0, 1)        sd condition1  subj                  0   \n         normal(0, 1)        sd  Intercept  subj                  0   \n         normal(0, 1)     sigma                                   0   \n       source\n         user\n (vectorized)\n         user\n         user\n (vectorized)\n (vectorized)\n         user\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n         user\n\n\n\nlet’s see if this is due to the influence of our priors. Let’s start with narrower prior\n\n\\[\n\\beta \\sim Normal(0,.01)\n\\]\n\nfit_df_gg05_rc_tight &lt;-\n  brm(\n    RT ~ condition + (condition |\n                     subj) + (condition | item),\n    family = lognormal(),\n    prior =\n      c(\n        prior(normal(6, 1.5), class = Intercept),\n        prior(normal(0, .01), class = b),\n        prior(normal(0, 1), class = sigma),\n        prior(normal(0, 1), class = sd),\n        prior(lkj(2), class = cor)\n      ),\n    data = df_gg05_rc,\n    file = here::here(\"models\", \"exercises\", \"ch5\", \"fit_df_gg05_rc_tight\")\n  )\n\nfit_df_gg05_rc_tight\n\n Family: lognormal \n  Links: mu = identity; sigma = identity \nFormula: RT ~ condition + (condition | subj) + (condition | item) \n   Data: df_gg05_rc (Number of observations: 672) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~item (Number of levels: 16) \n                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)                 0.04      0.02     0.00     0.09 1.00     1265\nsd(condition1)                0.11      0.05     0.01     0.22 1.00      907\ncor(Intercept,condition1)     0.31      0.39    -0.58     0.89 1.00     1197\n                          Tail_ESS\nsd(Intercept)                 1234\nsd(condition1)                 654\ncor(Intercept,condition1)     1763\n\n~subj (Number of levels: 42) \n                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)                 0.33      0.04     0.26     0.41 1.01      712\nsd(condition1)                0.24      0.04     0.16     0.33 1.01     1205\ncor(Intercept,condition1)     0.50      0.16     0.15     0.79 1.00     1143\n                          Tail_ESS\nsd(Intercept)                 1193\nsd(condition1)                1938\ncor(Intercept,condition1)     1808\n\nRegression Coefficients:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      5.84      0.05     5.74     5.95 1.01      508      805\ncondition1     0.00      0.01    -0.02     0.02 1.00     4631     3025\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.36      0.01     0.34     0.38 1.00     3557     2876\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nposterior_summary(fit_df_gg05_rc_tight, variable = \"b_condition1\")\n\n                Estimate   Est.Error        Q2.5      Q97.5\nb_condition1 0.003929963 0.009915301 -0.01567115 0.02344023\n\n\n\nand now a wider prior\n\n\\[\n\\beta \\sim Normal(0,1)\n\\]\n\nfit_df_gg05_rc_wide &lt;-\n  brm(\n    RT ~ condition + (condition |\n                     subj) + (condition | item),\n    family = lognormal(),\n    prior =\n      c(\n        prior(normal(6, 1.5), class = Intercept),\n        prior(normal(0, 1), class = b),\n        prior(normal(0, 1), class = sigma),\n        prior(normal(0, 1), class = sd),\n        prior(lkj(2), class = cor)\n      ),\n    data = df_gg05_rc,\n    file = here::here(\"models\", \"exercises\", \"ch5\", \"fit_df_gg05_rc_wide\")\n  )\n\nfit_df_gg05_rc_wide\n\n Family: lognormal \n  Links: mu = identity; sigma = identity \nFormula: RT ~ condition + (condition | subj) + (condition | item) \n   Data: df_gg05_rc (Number of observations: 672) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~item (Number of levels: 16) \n                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)                 0.04      0.02     0.00     0.09 1.00     1400\nsd(condition1)                0.09      0.05     0.01     0.18 1.00     1344\ncor(Intercept,condition1)     0.29      0.40    -0.60     0.89 1.00     2134\n                          Tail_ESS\nsd(Intercept)                 1510\nsd(condition1)                1348\ncor(Intercept,condition1)     1927\n\n~subj (Number of levels: 42) \n                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)                 0.33      0.04     0.26     0.42 1.00      917\nsd(condition1)                0.23      0.04     0.15     0.31 1.00     1961\ncor(Intercept,condition1)     0.51      0.17     0.14     0.79 1.00     1968\n                          Tail_ESS\nsd(Intercept)                 1677\nsd(condition1)                2799\ncor(Intercept,condition1)     2539\n\nRegression Coefficients:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      5.88      0.05     5.77     5.98 1.01      646     1326\ncondition1     0.12      0.05     0.02     0.22 1.00     1458     2394\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.36      0.01     0.34     0.38 1.00     3910     3020\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nposterior_summary(fit_df_gg05_rc_wide, variable = \"b_condition1\")\n\n              Estimate  Est.Error       Q2.5     Q97.5\nb_condition1 0.1202535 0.04996971 0.02286224 0.2188892\n\n\n\nprior &lt;- data.frame(posterior_summary(fit_df_gg05_rc, variable = \"b_condition1\")) %&gt;%\n  mutate(\"Prior for $\\\\beta$\" = \"Normal(0,.1)\")\ntight &lt;- data.frame(posterior_summary(fit_df_gg05_rc_tight, variable = \"b_condition1\")) %&gt;%\n  mutate(\"Prior for $\\\\beta$\" = \"Normal(0,.01)\")\nwide &lt;- data.frame(posterior_summary(fit_df_gg05_rc_wide, variable = \"b_condition1\")) %&gt;%\n  mutate(\"Prior for $\\\\beta$\" = \"Normal(0,1)\")\n\nsens_priors &lt;- rbind(prior,tight,wide)\n\nbrms::prior_summary(fit_df_gg05_rc_wide)\n\n                prior     class       coef group resp dpar nlpar lb ub\n         normal(0, 1)         b                                       \n         normal(0, 1)         b condition1                            \n       normal(6, 1.5) Intercept                                       \n lkj_corr_cholesky(2)         L                                       \n lkj_corr_cholesky(2)         L             item                      \n lkj_corr_cholesky(2)         L             subj                      \n         normal(0, 1)        sd                                   0   \n         normal(0, 1)        sd             item                  0   \n         normal(0, 1)        sd condition1  item                  0   \n         normal(0, 1)        sd  Intercept  item                  0   \n         normal(0, 1)        sd             subj                  0   \n         normal(0, 1)        sd condition1  subj                  0   \n         normal(0, 1)        sd  Intercept  subj                  0   \n         normal(0, 1)     sigma                                   0   \n       source\n         user\n (vectorized)\n         user\n         user\n (vectorized)\n (vectorized)\n         user\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n         user\n\nsens_priors %&gt;% \n  kbl() %&gt;%\n  kable_styling()\n\n\n\n\n\n\nEstimate\nEst.Error\nQ2.5\nQ97.5\nPrior for $\\beta$\n\n\n\n\nb_condition1\n0.1003678\n0.0458279\n0.0123948\n0.1890053\nNormal(0,.1)\n\n\nb_condition11\n0.0039300\n0.0099153\n-0.0156712\n0.0234402\nNormal(0,.01)\n\n\nb_condition12\n0.1202535\n0.0499697\n0.0228622\n0.2188892\nNormal(0,1)\n\n\n\n\n\n\n\n\n\nand now in milliseconds\n\n\nalpha1 &lt;- as_draws_df(fit_df_gg05_rc)$b_Intercept \nbeta1 &lt;- as_draws_df(fit_df_gg05_rc)$b_condition1\ndiff1 &lt;- exp(alpha1 + beta1/2) - exp(alpha1 - beta1/2)\nprior_ms &lt;- data.frame(mean = mean(diff1), quantile(diff1, .025), quantile(diff1, .975), row.names = NULL) %&gt;%\n  rename(\"Estimate (ms)\" = \"mean\",\n         \"2.5%\" = \"quantile.diff1..0.025.\",\n         \"97.5%\" = \"quantile.diff1..0.975.\")%&gt;%\n  mutate(\"Prior for $\\\\beta$\" = \"Normal(0,.1)\")\n\nalpha1 &lt;- as_draws_df(fit_df_gg05_rc_tight)$b_Intercept \nbeta1 &lt;- as_draws_df(fit_df_gg05_rc_tight)$b_condition1\ndiff1 &lt;- exp(alpha1 + beta1/2) - exp(alpha1 - beta1/2)\ntight_ms &lt;- data.frame(mean = mean(diff1), quantile(diff1, .025), quantile(diff1, .975), row.names = NULL) %&gt;%\n  rename(\"Estimate (ms)\" = \"mean\",\n         \"2.5%\" = \"quantile.diff1..0.025.\",\n         \"97.5%\" = \"quantile.diff1..0.975.\")%&gt;%\n  mutate(\"Prior for $\\\\beta$\" = \"Normal(0,.01)\")\n\nalpha1 &lt;- as_draws_df(fit_df_gg05_rc_wide)$b_Intercept \nbeta1 &lt;- as_draws_df(fit_df_gg05_rc_wide)$b_condition1\ndiff1 &lt;- exp(alpha1 + beta1/2) - exp(alpha1 - beta1/2)\nwide_ms &lt;- data.frame(mean = mean(diff1), quantile(diff1, .025), quantile(diff1, .975), row.names = NULL) %&gt;%\n  rename(\"Estimate (ms)\" = \"mean\",\n         \"2.5%\" = \"quantile.diff1..0.025.\",\n         \"97.5%\" = \"quantile.diff1..0.975.\") %&gt;%\n  mutate(\"Prior for $\\\\beta$\" = \"Normal(0,1)\")\n  \n\npriors_ms &lt;- rbind(prior_ms,tight_ms,wide_ms) %&gt;%\n  mutate(effect = \"b_condition1\") %&gt;%\n  relocate(effect, .before=\"Estimate (ms)\")\n\npriors_ms %&gt;% \n  kbl() %&gt;%\n  kable_styling()\n\n\n\n\n\neffect\nEstimate (ms)\n2.5%\n97.5%\nPrior for $\\beta$\n\n\n\n\nb_condition1\n36.129476\n4.483022\n71.120079\nNormal(0,.1)\n\n\nb_condition1\n1.362536\n-5.366546\n8.218174\nNormal(0,.01)\n\n\nb_condition1\n43.454009\n7.983291\n82.243742\nNormal(0,1)\n\n\n\n\n\n\n\n\n\nwe see lots of variation in estimates as a function of our priors\n\nwith the tight priors, there is a lot more uncertainty\nwith the regularised and wider priors the effects are a bit more similar\n\n\n\n# these are all the intercept, i'm interested in the slope though :/\nggpubr::ggarrange(\n  pp_check(fit_df_gg05_rc_wide, type = \"stat\") + theme_bw() + ggtitle(\"Wide priors N(0,1)\"),\n  pp_check(fit_df_gg05_rc_tight, type = \"stat\") + theme_bw() + ggtitle(\"Tight priors N(0,.01)\"),\n  pp_check(fit_df_gg05_rc, type = \"stat\") + theme_bw() + ggtitle(\"Original priors N(0,.1)\"),\nnrow = 3\n)",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ch. Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch5_exercises.html#exercise-5.3-relative-clause-processing-in-mandarin-chinese",
    "href": "book_exercises/ch5_exercises.html#exercise-5.3-relative-clause-processing-in-mandarin-chinese",
    "title": "6  Ch. Exercises",
    "section": "7.3 Exercise 5.3 Relative clause processing in Mandarin Chinese",
    "text": "7.3 Exercise 5.3 Relative clause processing in Mandarin Chinese\nLoad the following two data sets:\n\ndata(\"df_gibsonwu\")\ndata(\"df_gibsonwu2\")\n\nThe data are taken from two experiments that investigate (inter alia) the effect of relative clause type on reading time in Chinese. The data are from Gibson and Wu (2013) and Vasishth et al. (2013) respectively. The second data set is a direct replication attempt of the Gibson and Wu (2013) experiment.\nChinese relative clauses are interesting theoretically because they are prenominal: the relative clause appears before the head noun. For example, the English relative clauses shown above would appear in the following order in Mandarin. The square brackets mark the relative clause, and REL refers to the Chinese equivalent of the English relative pronoun who.\n(2a) [The photographer sent to the editor] REL the reporter was hoping for a good story. (ORC)\n(2b) [sent the photographer to the editor] REL the reporter who was hoping for a good story. (SRC)\nAs discussed in Gibson and Wu (2013), the consequence of Chinese relative clauses being prenominal is that the distance between the verb in relative clause and the head noun is larger in subject relatives than object relatives. Hsiao and Gibson (2003) were the first to suggest that the larger distance in subject relatives leads to longer reading time at the head noun. Under this view, the prediction is that subject relatives are harder to process than object relatives. If this is true, this is interesting and surprising because in most other languages that have been studied, subject relatives are easier to process than object relatives; so Chinese will be a very unusual exception cross-linguistically.\nThe data provided are for the critical region (the head noun; here, reporter). The experiment method is self-paced reading, so we have reading times in milliseconds. The second data set is a direct replication attempt of the first data set, which is from Gibson and Wu (2013).\nThe research hypothesis is whether the difference in reading times between object and subject relative clauses is negative. For the first data set (df_gibsonwu), investigate this question by fitting two “maximal” hierarchical models (correlated varying intercept and slopes for subjects and items). The dependent variable in both models is the raw reading time in milliseconds. The first model should use the normal likelihood in the model; the second model should use the log-normal likelihood. In both models, use \\(\\pm 0.5\\) sum coding to model the effect of relative clause type. You will need to decide on appropriate priors for the various parameters.\n\n\n\n\n\n\nContrasts\n\n\n\n\nobj-ext = -0.5, subj-ext = 0.5\n\n\nhead(df_gibsonwu)\n\n    subj item     type   rt\n94     1   13  obj-ext 1561\n221    1    6 subj-ext  959\n341    1    5  obj-ext  582\n461    1    9  obj-ext  294\n621    1   14 subj-ext  438\n753    1    4 subj-ext  286\n\ndf_gibsonwu$type &lt;- factor(df_gibsonwu$type, levels = c(\"obj-ext\",\"subj-ext\"))\n\ncontrasts(df_gibsonwu$type) &lt;- c(0.5,-0.5)\ncontrasts(df_gibsonwu$type)\n\n         [,1]\nobj-ext   0.5\nsubj-ext -0.5\n\n\n\n\n\n\n\n\n\n\nNormal likelihood\n\n\n\n\nfirst set priors\n\n\npriors_gw_norm &lt;- c(\n  set_prior(\"normal(500, 150)\", class = \"Intercept\"),\n  set_prior(\"normal(0,500)\", class = \"b\", coef = \"type1\"),\n  set_prior(\"normal(0,500)\", class = \"sd\"),\n  set_prior(\"normal(0,1000)\",class = \"sigma\"),\n  set_prior(\"lkj(2)\", class = \"cor\")\n)\n\n\nfit model\n\n\nfit_gw_norm &lt;- brm(rt ~ 1 + type + \n                   (1 + type | subj) +\n                   (1 + type | item), \n                 data = df_gibsonwu,\n                 family = gaussian(),\n                 prior = priors_gw_norm,\n                 file = here::here(\"models\", \"exercises\", \"ch5\", \"fit_gw_norm\"))\n\n\n\n\n\n\n\n\n\nLog-normal likelihood\n\n\n\n\nset priors\n\n\npriors_gw_log &lt;- c(\n  set_prior(\"normal(6, 1.5)\", class = \"Intercept\"),\n  set_prior(\"normal(0,1)\", class = \"b\", coef = \"type1\"),\n  set_prior(\"normal(0,1)\",class = \"sd\"),\n  set_prior(\"normal(0,1)\",class = \"sigma\"),\n  set_prior(\"lkj(2)\", class = \"cor\")\n)\n\n\nfit model\n\n\nfit_gw_log &lt;- brm(rt ~ 1 + type + \n                   (1 + type | subj) +\n                   (1 + type | item), \n                 data = df_gibsonwu,\n                 family = lognormal(),\n                 prior = priors_gw_log,\n                 file = here::here(\"models\", \"exercises\", \"ch5\", \"fit_gw_log\")\n                 )\n\n\n\n\nPlot the posterior predictive distributions from the two models. What is the difference in the posterior predictive distributions of the two models; and why is there a difference?\n\n\n\n\n\n\n\nPosterior predictive distributions\n\n\n\n\nggpubr::ggarrange(\n  pp_check(fit_gw_norm, ndraws = 1000) +\n    ggtitle(\"Normal distr\") +\n    theme(legend.position = \"none\"),\n  pp_check(fit_gw_log, ndraws = 1000) + \n    ggtitle(\"Log-normal distr\") +\n    theme(legend.position = \"none\"),\n  cowplot::get_legend(pp_check(fit_gw_log) +\n                        theme(legend.position = \"bottom\")),\n  ncol = 1,\n  heights = c(.45,.45,.1)\n)\n\n\n\n\n\n\n\n\n\nquite a mismatch in normal likelihood model, e.g., negative values are generated\nlog-normal better fit\n\n\n\n\nExamine the posterior distributions of the effect estimates (in milliseconds) in the two models. Why are these different?\n\n\n\n\n\n\n\nPosterior distribution\n\n\n\n\n# Normal distr\nplot(fit_gw_norm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Log distr\nplot(fit_gw_log)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.0.0.1 Effect estimates\n\nlook at effect estimates\n\n\n# normal distr\ngw_intercept_norm &lt;- as_draws_df(fit_gw_norm)$b_Intercept\ngw_slope_norm &lt;- as_draws_df(fit_gw_norm)$b_type1\n\ngw_RT_diff_norm &lt;- gw_slope_norm\nround(quantile(gw_RT_diff_norm,prob=c(0.025,0.975)),2)\n\n   2.5%   97.5% \n-249.37   17.18 \n\n\n\n# log distr\ngw_intercept_log &lt;- as_draws_df(fit_gw_log)$b_Intercept\ngw_slope_log &lt;- as_draws_df(fit_gw_log)$b_type1\n\ngw_RT_diff_log &lt;- exp(gw_intercept_log + gw_slope_log/2) -\nexp(gw_intercept_log - gw_slope_log/2)\nquantile(gw_RT_diff_log,prob=c(0.025,0.975))\n\n     2.5%     97.5% \n-79.89632  14.21774 \n\n\n\nboxplot(rt~type,df_gibsonwu)\n\n\n\n\n\n\n\n\n\n95% credible interval for estimates include 0 for both norm and log-norm distributions\nlog-norm model CrI is tighter, and includes smaller effect size (but includes 0)\n\n\n\n\n\nGiven the posterior predictive distributions you plotted above, why is the log-normal likelihood model better for carrying out inference and hypothesis testing?\n\n\n\n\n\n\n\nTipp\n\n\n\n\n# look at range per type\ndf_gibsonwu %&gt;%\n  group_by(type) %&gt;%\n  summarise(min(rt), max(rt))\n\n# A tibble: 2 × 3\n  type     `min(rt)` `max(rt)`\n  &lt;fct&gt;        &lt;int&gt;     &lt;int&gt;\n1 obj-ext        172      2308\n2 subj-ext       189      6217\n\n\n\nlibrary(ggrain) \ndf_gibsonwu %&gt;%\n  # filter(session!=\"bi\") %&gt;%\n  # mutate(px_list = paste0(participant,list)) %&gt;%\n  ggplot(data = ., \n         aes(x = type, y = rt, \n             fill = type, color = type, shape = type)) +\n  labs(title = \"Distribution of observations\") +\n  geom_rain(alpha = .5, rain.side = 'f1x1',\n            violin.args = list(color = NA, alpha = .5)) +\n  theme_bw() +\n  scale_fill_manual(values=c(\"dodgerblue\", \"darkorange\")) +\n  scale_color_manual(values=c(\"dodgerblue\", \"darkorange\")) \n\n\n\n\n\n\n\n\n\n7.3.0.1 My answer\n\nsubj-ext had extreme raw values; this would’ve biased the model with a normal distribution\n\n\n\n\nNext, work out a normal approximation of the log-normal model’s posterior distribution for the relative clause effect that you obtained from the above data analysis. Then use that normal approximation as an informative prior for the slope parameter when fitting a hierarchical model to the second data set. This is an example of incrementally building up knowledge by successively using a previous study’s posterior as a prior for the next study; this is essentially equivalent to pooling both data sets (check that pooling the data and using a Normal(0,1) prior for the effect of interest, with a log-normal likelihood, gives you approximately the same posterior as the informative-prior model fit above).\n\n\n\n\n\n\nDataset 1 log estimates\n\n\n\n\nfirst check 2nd dataset\n\n\nhead(df_gibsonwu2)\n\n   subj item condition pos   rt    region\n9   1m1   15   obj-ext   8  832 head noun\n20  1m1    8  subj-ext   8 2131 head noun\n33  1m1   11   obj-ext   8  553 head noun\n46  1m1   10  subj-ext   8 1091 head noun\n62  1m1   16  subj-ext   8  598 head noun\n75  1m1   14  subj-ext   8  645 head noun\n\ndf_gibsonwu2 &lt;- df_gibsonwu2 %&gt;%\n  rename(\"type\" = condition)\ndf_gibsonwu2$type &lt;- factor(df_gibsonwu2$type, levels = c(\"obj-ext\",\"subj-ext\"))\n\ncontrasts(df_gibsonwu2$type) &lt;- c(0.5,-0.5)\ncontrasts(df_gibsonwu2$type)\n\n         [,1]\nobj-ext   0.5\nsubj-ext -0.5\n\n\n\nremind ourselves of the estimates from the first dataset\n\n\nsummary(fit_gw_log)\n\n Family: lognormal \n  Links: mu = identity; sigma = identity \nFormula: rt ~ 1 + type + (1 + type | subj) + (1 + type | item) \n   Data: df_gibsonwu (Number of observations: 547) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~item (Number of levels: 15) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)            0.20      0.05     0.12     0.32 1.00     1220\nsd(type1)                0.07      0.05     0.00     0.20 1.00     1857\ncor(Intercept,type1)     0.00      0.42    -0.77     0.77 1.00     3914\n                     Tail_ESS\nsd(Intercept)            2098\nsd(type1)                1710\ncor(Intercept,type1)     2698\n\n~subj (Number of levels: 37) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)            0.25      0.04     0.18     0.33 1.00     1286\nsd(type1)                0.14      0.07     0.01     0.27 1.00     1415\ncor(Intercept,type1)    -0.46      0.31    -0.91     0.29 1.00     2380\n                     Tail_ESS\nsd(Intercept)            2128\nsd(type1)                1198\ncor(Intercept,type1)     1911\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     6.06      0.07     5.92     6.20 1.00      791     1214\ntype1        -0.07      0.05    -0.18     0.03 1.00     2529     2729\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.51      0.02     0.48     0.55 1.00     3927     2662\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nfor replication study, use:\n\ntype: \\(LogNormal(-0.07, 0.07)\\) (type1 Estimate and Est. Error?)\nIntercept: \\(LogNormal(6, 0.06)\\)\n\n\n\n7.3.0.2 Dataset 2 model\n\npriors_gw2_log &lt;- c(\n  set_prior(\"normal(6, 0.07)\", class = \"Intercept\"),\n  set_prior(\"normal(-0.7,0.06)\", class = \"b\", coef = \"type1\"),\n  set_prior(\"normal(0,1)\",class = \"sd\"),\n  set_prior(\"normal(0,1)\",class = \"sigma\"),\n  set_prior(\"lkj(2)\", class = \"cor\")\n)\n\n\nfit model; convergence warning (ESS too low)\n\n\nfit_gw2_log &lt;- brm(rt ~ 1 + type + \n                   (1 + type | subj) +\n                   (1 + type | item), \n                 data = df_gibsonwu2,\n                 family = lognormal(),\n                 prior = priors_gw2_log,\n                 file = here::here(\"models\", \"exercises\", \"ch5\", \"fit_gw2_log\")\n                 )\n\n\nsummary(fit_gw2_log)\n\n Family: lognormal \n  Links: mu = identity; sigma = identity \nFormula: rt ~ 1 + type + (1 + type | subj) + (1 + type | item) \n   Data: df_gibsonwu2 (Number of observations: 595) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~item (Number of levels: 15) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)            0.17      0.04     0.10     0.27 1.00     1486\nsd(type1)                0.61      0.14     0.38     0.95 1.00     1333\ncor(Intercept,type1)    -0.29      0.31    -0.80     0.39 1.01      435\n                     Tail_ESS\nsd(Intercept)            2355\nsd(type1)                1818\ncor(Intercept,type1)     1180\n\n~subj (Number of levels: 40) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)            0.24      0.04     0.18     0.32 1.00     1244\nsd(type1)                0.11      0.07     0.00     0.24 1.00      755\ncor(Intercept,type1)     0.03      0.34    -0.64     0.68 1.00     4172\n                     Tail_ESS\nsd(Intercept)            2371\nsd(type1)                1058\ncor(Intercept,type1)     2261\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     6.03      0.05     5.92     6.13 1.00      853     1685\ntype1        -0.61      0.06    -0.74    -0.49 1.00     3451     2808\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.43      0.01     0.40     0.46 1.00     3663     2768\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nplot(fit_gw2_log)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.0.2.1 Estimates\n\n# log distr\ngw2_intercept_log &lt;- as_draws_df(fit_gw2_log)$b_Intercept\ngw2_slope_log &lt;- as_draws_df(fit_gw2_log)$b_type1\n\ngw2_RT_diff_log &lt;- exp(gw2_intercept_log + gw2_slope_log/2) - exp(gw2_intercept_log - gw2_slope_log/2)\nquantile(gw2_RT_diff_log,prob=c(0.025,0.975))\n\n     2.5%     97.5% \n-321.2215 -202.9674 \n\n\n\n\n\n\n\n\n\n\n\n\nDatasets 1 and 2\n\n\n\n\n# make sure 2 datasets have same column names/order\nnames(df_gibsonwu); names(df_gibsonwu2)\n\n[1] \"subj\" \"item\" \"type\" \"rt\"  \n\n\n[1] \"subj\"   \"item\"   \"type\"   \"pos\"    \"rt\"     \"region\"\n\ndf_gibsonwu2 &lt;- df_gibsonwu2 %&gt;%\n  select(subj,item,type,rt) %&gt;%\n  mutate(subj = paste0(subj,\"_gw2\"),\n         item = paste0(item,\"_gw2\"))\n\ndf_gibsonwu &lt;- df_gibsonwu %&gt;%\n  mutate(subj = paste0(subj,\"_gw1\"),\n         item = paste0(item,\"_gw1\"))\n\nnames(df_gibsonwu) == names(df_gibsonwu2)\n\n[1] TRUE TRUE TRUE TRUE\n\n# combine\ndf_gw12 &lt;- rbind(df_gibsonwu,df_gibsonwu2)\n\n\n7.3.0.2.2 Informative model\n\n# contrasts\nhead(df_gw12)\n\n     subj   item     type   rt\n94  1_gw1 13_gw1  obj-ext 1561\n221 1_gw1  6_gw1 subj-ext  959\n341 1_gw1  5_gw1  obj-ext  582\n461 1_gw1  9_gw1  obj-ext  294\n621 1_gw1 14_gw1 subj-ext  438\n753 1_gw1  4_gw1 subj-ext  286\n\ndf_gw12$type &lt;- factor(df_gw12$type, levels = c(\"obj-ext\",\"subj-ext\"))\n\ncontrasts(df_gw12$type) &lt;- c(0.5,-0.5)\ncontrasts(df_gw12$type)\n\n         [,1]\nobj-ext   0.5\nsubj-ext -0.5\n\n\n\nsame priors as based on previous models\n\n\npriors_gw12_log &lt;- c(\n  set_prior(\"normal(6, 0.07)\", class = \"Intercept\"),\n  set_prior(\"normal(-0.7,0.06)\", class = \"b\", coef = \"type1\"),\n  set_prior(\"normal(0,1)\",class = \"sd\"),\n  set_prior(\"normal(0,1)\",class = \"sigma\"),\n  set_prior(\"lkj(2)\", class = \"cor\")\n)\n\n\nfit_gw12_log &lt;- brm(rt ~ 1 + type + \n                   (1 + type | subj) +\n                   (1 + type | item), \n                 data = df_gw12,\n                 family = lognormal(),\n                 prior = priors_gw12_log,\n                 file = here::here(\"models\", \"exercises\", \"ch5\", \"fit_gw12_log\")\n                 )\n\n\nsummary(fit_gw12_log)\n\n Family: lognormal \n  Links: mu = identity; sigma = identity \nFormula: rt ~ 1 + type + (1 + type | subj) + (1 + type | item) \n   Data: df_gw12 (Number of observations: 1142) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~item (Number of levels: 30) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)            0.18      0.03     0.13     0.24 1.00     1488\nsd(type1)                0.45      0.10     0.26     0.67 1.00     1081\ncor(Intercept,type1)    -0.12      0.29    -0.64     0.45 1.02      433\n                     Tail_ESS\nsd(Intercept)            2112\nsd(type1)                1515\ncor(Intercept,type1)     1052\n\n~subj (Number of levels: 77) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)            0.24      0.03     0.20     0.30 1.00     1497\nsd(type1)                0.12      0.05     0.02     0.22 1.00      806\ncor(Intercept,type1)    -0.33      0.28    -0.82     0.27 1.00     4190\n                     Tail_ESS\nsd(Intercept)            2569\nsd(type1)                1344\ncor(Intercept,type1)     2368\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     6.04      0.05     5.95     6.13 1.01      701     1576\ntype1        -0.49      0.07    -0.63    -0.35 1.00     1574     2408\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.47      0.01     0.45     0.49 1.00     4636     3007\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nplot(fit_gw12_log)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.0.2.3 Estimates\n\n# log distr\ngw12_intercept_log &lt;- as_draws_df(fit_gw12_log)$b_Intercept\ngw12_slope_log &lt;- as_draws_df(fit_gw12_log)$b_type1\n\ngw12_RT_diff_log &lt;- exp(gw12_intercept_log + gw12_slope_log/2) - exp(gw12_intercept_log - gw12_slope_log/2)\nquantile(gw12_RT_diff_log,prob=c(0.025,0.975))\n\n     2.5%     97.5% \n-272.3808 -146.4277 \n\n\n\nnegative slope, CrI doesn’t include 0\n\n\n\n7.3.0.3 Regularised prior?\n\npriors_gw12_log_reg &lt;- c(\n  set_prior(\"normal(6, 1.5)\", class = \"Intercept\"),\n  set_prior(\"normal(0,1)\", class = \"b\", coef = \"type1\"),\n  set_prior(\"normal(0,1)\",class = \"sd\"),\n  set_prior(\"normal(0,1)\",class = \"sigma\"),\n  set_prior(\"lkj(2)\", class = \"cor\")\n)\n\n\nfit_gw12_log_reg &lt;- brm(rt ~ 1 + type + \n                   (1 + type | subj) +\n                   (1 + type | item), \n                 data = df_gw12,\n                 family = lognormal(),\n                 prior = priors_gw12_log_reg,\n                 file = here::here(\"models\", \"exercises\", \"ch5\", \"fit_gw12_log_reg\")\n                 )\n\n\nsummary(fit_gw12_log_reg)\n\n Family: lognormal \n  Links: mu = identity; sigma = identity \nFormula: rt ~ 1 + type + (1 + type | subj) + (1 + type | item) \n   Data: df_gw12 (Number of observations: 1142) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~item (Number of levels: 30) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)            0.17      0.03     0.12     0.24 1.00     1269\nsd(type1)                0.11      0.05     0.01     0.21 1.01     1063\ncor(Intercept,type1)    -0.29      0.31    -0.82     0.39 1.00     2244\n                     Tail_ESS\nsd(Intercept)            1767\nsd(type1)                1150\ncor(Intercept,type1)     2001\n\n~subj (Number of levels: 77) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)            0.25      0.03     0.20     0.30 1.00     1226\nsd(type1)                0.10      0.05     0.01     0.20 1.00      988\ncor(Intercept,type1)    -0.34      0.29    -0.83     0.31 1.00     2636\n                     Tail_ESS\nsd(Intercept)            1954\nsd(type1)                1074\ncor(Intercept,type1)     1913\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     6.03      0.04     5.95     6.12 1.00      858     1436\ntype1        -0.08      0.04    -0.16    -0.00 1.00     2156     2379\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.47      0.01     0.45     0.49 1.00     2851     2765\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nprior_summary(fit_gw12_log_reg)\n\n                prior     class      coef group resp dpar nlpar lb ub\n               (flat)         b                                      \n          normal(0,1)         b     type1                            \n       normal(6, 1.5) Intercept                                      \n lkj_corr_cholesky(2)         L                                      \n lkj_corr_cholesky(2)         L            item                      \n lkj_corr_cholesky(2)         L            subj                      \n          normal(0,1)        sd                                  0   \n          normal(0,1)        sd            item                  0   \n          normal(0,1)        sd Intercept  item                  0   \n          normal(0,1)        sd     type1  item                  0   \n          normal(0,1)        sd            subj                  0   \n          normal(0,1)        sd Intercept  subj                  0   \n          normal(0,1)        sd     type1  subj                  0   \n          normal(0,1)     sigma                                  0   \n       source\n      default\n         user\n         user\n         user\n (vectorized)\n (vectorized)\n         user\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n         user\n\n\n\nplot(fit_gw12_log_reg)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.0.3.1 Estimates\n\n# log distr\ngw12_intercept_log_reg &lt;- as_draws_df(fit_gw12_log_reg)$b_Intercept\ngw12_slope_log_reg &lt;- as_draws_df(fit_gw12_log_reg)$b_type1\n\ngw12_RT_diff_log_reg &lt;- exp(gw12_intercept_log_reg + gw12_slope_log_reg/2) - \n  exp(gw12_intercept_log_reg - gw12_slope_log_reg/2)\nquantile(gw12_RT_diff_log_reg,prob=c(0.025,0.975))\n\n      2.5%      97.5% \n-65.965900  -1.192242 \n\n\n\nnow the 95% CrI does not include 0, but the range of values is much tighter and includes smaller values",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ch. Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch5_exercises.html#exercise-5.4---agreement-attraction-in-comprehension",
    "href": "book_exercises/ch5_exercises.html#exercise-5.4---agreement-attraction-in-comprehension",
    "title": "6  Ch. Exercises",
    "section": "7.4 Exercise 5.4 - Agreement attraction in comprehension",
    "text": "7.4 Exercise 5.4 - Agreement attraction in comprehension\nLoad the following data:\n\ndata(\"df_dillonE1\")\ndillonE1 &lt;- df_dillonE1\nhead(dillonE1)\n\n        subj       item   rt int     expt\n49 dillonE11 dillonE119 2918 low dillonE1\n56 dillonE11 dillonE119 1338 low dillonE1\n63 dillonE11 dillonE119  424 low dillonE1\n70 dillonE11 dillonE119  186 low dillonE1\n77 dillonE11 dillonE119  195 low dillonE1\n84 dillonE11 dillonE119 1218 low dillonE1\n\n\nThe data are taken from an experiment that investigate (inter alia) the effect of number similarity between a noun and the auxiliary verb in sentences like the following. There are two levels to a factor called Int(erference): low and high.\n(3a) low: The key to the cabinet are on the table (3b) high: The key to the cabinets are on the table\nHere, in (3b), the auxiliary verb are is predicted to be read faster than in (3a), because the plural marking on the noun cabinets leads the reader to think that the sentence is grammatical. (Both sentences are ungrammatical.) This phenomenon, where the high condition is read faster than the low condition, is called agreement attraction.\nThe data provided are for the critical region (the auxiliary verb are). The experiment method is eye-tracking; we have total reading times in milliseconds.\nThe research question is whether the difference in reading times between high and low conditions is negative.\n\nFirst, using a log-normal likelihood, fit a hierarchical model with correlated varying intercept and slopes for subjects and items. You will need to decide on the priors for the model.\nBy simply looking at the posterior distribution of the slope parameter, \\(\\beta\\), what would you conclude about the theoretical claim relating to agreement attraction?",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ch. Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch5_exercises.html#exercise-5.5",
    "href": "book_exercises/ch5_exercises.html#exercise-5.5",
    "title": "6  Ch. Exercises",
    "section": "7.5 Exercise 5.5",
    "text": "7.5 Exercise 5.5",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ch. Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch5_exercises.html#exercise-5.6",
    "href": "book_exercises/ch5_exercises.html#exercise-5.6",
    "title": "6  Ch. Exercises",
    "section": "7.6 Exercise 5.6",
    "text": "7.6 Exercise 5.6",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ch. Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch5_exercises.html#exercise-5.7",
    "href": "book_exercises/ch5_exercises.html#exercise-5.7",
    "title": "6  Ch. Exercises",
    "section": "7.7 Exercise 5.7",
    "text": "7.7 Exercise 5.7",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ch. Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch5_exercises.html#exercise-5.8",
    "href": "book_exercises/ch5_exercises.html#exercise-5.8",
    "title": "6  Ch. Exercises",
    "section": "7.8 Exercise 5.8",
    "text": "7.8 Exercise 5.8",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ch. Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch8_exercises.html",
    "href": "book_exercises/ch8_exercises.html",
    "title": "7  Ch. 8 Exercises",
    "section": "",
    "text": "7.1 Exercise 8.1 Contrast coding for a four-condition design\nlibrary(bcogsci)\ndata(\"df_persianE1\")\ndat1 &lt;- df_persianE1\nhead(dat1)\n\n    subj item   rt distance   predability\n60     4    6  568    short   predictable\n94     4   17  517     long unpredictable\n146    4   22  675    short   predictable\n185    4    5  575     long unpredictable\n215    4    3  581     long   predictable\n285    4    7 1171     long   predictable",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ch. 8 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch8_exercises.html#exercise-8.1-contrast-coding-for-a-four-condition-design",
    "href": "book_exercises/ch8_exercises.html#exercise-8.1-contrast-coding-for-a-four-condition-design",
    "title": "7  Ch. 8 Exercises",
    "section": "",
    "text": "Load the following data. These data are from Experiment 1 in a set of reading studies on Persian (Safavi, Husain, and Vasishth 2016). This is a self-paced reading study on particle-verb constructions, with a 2 x 2 design: distance (short, long) and predictability (predictable, unpredictable). The data are from a critical region in the sentence. All the data from the Safavi, Husain, and Vasishth (2016) paper are available from https://github.com/vasishth/SafaviEtAl2016.\n\n\n\nThe four conditions are:\n\nDistance=short and Predictability=unpredictable\nDistance=short and Predictability=predictable\nDistance=long and Predictability=unpredictable\nDistance=long and Predictability=predictable\n\nThe researcher wants to do the following sets of comparisons between condition means:\nCompare the condition labeled Distance=short and Predictability=unpredictable with each of the following conditions:\n\nDistance=short and Predictability=predictable\nDistance=long and Predictability=unpredictable\nDistance=long and Predictability=predictable\n\n\n\n7.1.1 Questions\n\n\nWhich contrast coding is needed for such a comparison?\n\n\nTreatment contrasts, because we’re comparing everything to on baseline condition.\n\ndat1$distance &lt;- as.factor(dat1$distance)\ndat1$predability &lt;- as.factor(dat1$predability)\n\n\nlevels(dat1$distance)\n\n[1] \"long\"  \"short\"\n\nlevels(dat1$predability)\n\n[1] \"predictable\"   \"unpredictable\"\n\n\nEach have 2 levels (2x2 design).\nDesired comparisons:\n\nshort-unpredictable vs. short-predictable\nshort-unpredictable vs. long-predictable\nshort-unpredictable vs. long-unpredictable\nwe do not care about comparing short and unpredictable\nso we want treatment contrasts, with short-predictable as our baseline\n\n\n\nFirst, define the relevant contrast coding. Hint: You can do it by creating a condition column labeled a,b,c,d and then use a built-in contrast coding function.\n\n\nCreate variable ‘cond’\n\ndat1 &lt;- dat1 |&gt; \n  mutate(cond = paste(distance, predability, sep = \"-\"),\n         cond = fct_relevel(cond, \"short-unpredictable\", \"short-predictable\"))\n\nSet treatment contrasts\n\ndat1$cond &lt;- as.factor(dat1$cond)\ncontrasts(dat1$cond) &lt;- contr.treatment(4)\n\nPrint contrast matrix\n\ncontrasts(dat1$cond)\n\n                    2 3 4\nlong-predictable    0 0 0\nlong-unpredictable  1 0 0\nshort-predictable   0 1 0\nshort-unpredictable 0 0 1\n\n\nSo cond1 will be a comparisons between short-unpred and long-pred, etc.\nLet’s also look at the means per condition.\n\ndat1 |&gt; \n  Rmisc::summarySEwithin(\n    measurevar = \"rt\", withinvars = c(\"distance\", \"predability\")\n  ) |&gt; \n  knitr::kable()\n\n\n\n\ndistance\npredability\nN\nrt\nsd\nse\nci\n\n\n\n\nlong\npredictable\n378\n577.6217\n441.0407\n22.68469\n44.60436\n\n\nlong\nunpredictable\n378\n645.5847\n468.6011\n24.10224\n47.39166\n\n\nshort\npredictable\n378\n535.7302\n321.3159\n16.52671\n32.49608\n\n\nshort\nunpredictable\n378\n575.8413\n462.0511\n23.76534\n46.72924\n\n\n\n\n\n\n\nThen, use the hypr library function to confirm that your contrast coding actually does the comparison you need.\n\n\nWe’ll need to define our 3 comparisons:\n\nlibrary(hypr)\n\n\nlevels(dat1$cond)\n\n[1] \"long-predictable\"    \"long-unpredictable\"  \"short-predictable\"  \n[4] \"short-unpredictable\"\n\n\n\ncond_treat &lt;-\n  hypr(\n   b0 = `short-unpredictable` ~ 0, # include intercept\n   b1 = `long-predictable` ~ `short-unpredictable`,\n   b2 = `long-unpredictable` ~ `short-unpredictable`,\n   b3 = `short-predictable` ~ `short-unpredictable`,\n   levels = c(\"short-unpredictable\", \"short-predictable\", \"long-predictable\", \"long-unpredictable\")\n )\n\ncond_treat\n\nhypr object containing 4 null hypotheses:\nH0.b0: 0 = short-unpredictable                       (Intercept)\nH0.b1: 0 = long-predictable - short-unpredictable\nH0.b2: 0 = long-unpredictable - short-unpredictable\nH0.b3: 0 = short-predictable - short-unpredictable\n\nCall:\nhypr(b0 = ~`short-unpredictable`, b1 = ~`long-predictable` - \n    `short-unpredictable`, b2 = ~`long-unpredictable` - `short-unpredictable`, \n    b3 = ~`short-predictable` - `short-unpredictable`, levels = c(\"short-unpredictable\", \n    \"short-predictable\", \"long-predictable\", \"long-unpredictable\"\n    ))\n\nHypothesis matrix (transposed):\n                    b0 b1 b2 b3\nshort-unpredictable  1 -1 -1 -1\nshort-predictable    0  0  0  1\nlong-predictable     0  1  0  0\nlong-unpredictable   0  0  1  0\n\nContrast matrix:\n                    b0 b1 b2 b3\nshort-unpredictable 1  0  0  0 \nshort-predictable   1  0  0  1 \nlong-predictable    1  1  0  0 \nlong-unpredictable  1  0  1  0 \n\n\nCheck out hypothesis matrix\n\ncontr.hypothesis(cond_treat)\n\n                    b1 b2 b3\nshort-unpredictable  0  0  0\nshort-predictable    0  0  1\nlong-predictable     1  0  0\nlong-unpredictable   0  1  0\nattr(,\"class\")\n[1] \"hypr_cmat\" \"matrix\"    \"array\"    \n\n\nSet contrasts.\n\ncontrasts(dat1$cond) &lt;- contr.hypothesis(cond_treat)\n\nPrint contrasts\n\ncontrasts(dat1$cond)\n\n                    b1 b2 b3\nshort-unpredictable 0  0  0 \nshort-predictable   0  0  1 \nlong-predictable    1  0  0 \nlong-unpredictable  0  1  0 \n\n\n\n\nFit a simple linear model with the above contrast coding and display the slopes, which constitute the relevant comparisons.\n\n\n\nfit_dat1 &lt;- brm(rt ~ 1 + cond,\n  data = dat1,\n  family = gaussian(),\n  # prior = c(\n  #   prior(normal(550, 25), class = Intercept),\n  #   prior(normal(25, 2), class = sigma),\n  #   prior(normal(25, 1), class = b)\n  # ),\n  file = here::here(\"models/exercises/ch8/fit_ch_8_ex1\")\n)\n\n\nfixef(fit_dat1)\n\n            Estimate Est.Error      Q2.5     Q97.5\nIntercept 575.475897  19.52131 537.22261 614.16236\ncondb1      1.926428  27.28125 -51.72818  56.24605\ncondb2     69.867350  27.19697  15.34477 124.10026\ncondb3    -39.888746  26.46207 -91.86960  14.17325\n\n\nCalculate the estimates per condition:\n\n# intercept\nshort_unpred &lt;- fixef(fit_dat1)[1,\"Estimate\"]\nlong_pred &lt;- short_unpred + fixef(fit_dat1)[2,\"Estimate\"]\nlong_unpred &lt;- short_unpred + fixef(fit_dat1)[3,\"Estimate\"]\nshort_pred &lt;- short_unpred + fixef(fit_dat1)[4,\"Estimate\"]\n\n\nshort_unpred\n\n[1] 575.4759\n\nlong_pred\n\n[1] 577.4023\n\nlong_unpred\n\n[1] 645.3432\n\nshort_pred\n\n[1] 535.5872\n\n\n\ncontrasts(dat1$cond)\n\n                    b1 b2 b3\nshort-unpredictable 0  0  0 \nshort-predictable   0  0  1 \nlong-predictable    1  0  0 \nlong-unpredictable  0  1  0 \n\n\n\n\nNow, compute each of the four conditions’ means and check that the slopes from the linear model correspond to the relevant differences between means that you obtained from the data.\n\n\n\ndat1 |&gt; \n  Rmisc::summarySEwithin(\n    measurevar = \"rt\", withinvars = c(\"distance\", \"predability\")\n  ) |&gt; \n  knitr::kable()\n\n\n\n\ndistance\npredability\nN\nrt\nsd\nse\nci\n\n\n\n\nlong\npredictable\n378\n577.6217\n441.0407\n22.68469\n44.60436\n\n\nlong\nunpredictable\n378\n645.5847\n468.6011\n24.10224\n47.39166\n\n\nshort\npredictable\n378\n535.7302\n321.3159\n16.52671\n32.49608\n\n\nshort\nunpredictable\n378\n575.8413\n462.0511\n23.76534\n46.72924\n\n\n\n\n\nOr with the tidyverse:\n\ndat1 |&gt; \n  dplyr::summarise(mean = mean(rt),\n            .by = cond)\n\n                 cond     mean\n1   short-predictable 535.7302\n2  long-unpredictable 645.5847\n3    long-predictable 577.6217\n4 short-unpredictable 575.8413\n\n\nYup they correspond.",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ch. 8 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch8_exercises.html#exercise-8.2-helmert-coding-for-a-four-condition-design.",
    "href": "book_exercises/ch8_exercises.html#exercise-8.2-helmert-coding-for-a-four-condition-design.",
    "title": "7  Ch. 8 Exercises",
    "section": "7.2 Exercise 8.2 Helmert coding for a four-condition design.",
    "text": "7.2 Exercise 8.2 Helmert coding for a four-condition design.\n\nLoad the following data:\n\n\nlibrary(bcogsci)\ndata(\"df_polarity\")\nhead(df_polarity)\n\n  subject item condition times   value\n1       1    6         f   SFD 327.845\n2       1   24         f   SFD 205.948\n3       1   35         e   SFD 315.225\n4       1   17         e   SFD 264.773\n5       1   34         d   SFD 252.193\n6       1    7         a   SFD 155.511\n\n\n\nThe data come from an eyetracking study in German reported in Vasishth et al. (2008). The experiment is a reading study involving six conditions. The sentences are in English, but the original design was involved German sentences. In German, the word durchaus (certainly) is a positive polarity item: in the constructions used in this experiment, durchaus cannot have a c-commanding element that is a negative polarity item licensor. Here are the conditions:\n\nNegative polarity items\n\n\nGrammatical: No man who had a beard was ever thrifty.\nUngrammatical (Intrusive NPI licensor): A man who had no beard was ever thrifty.\nUngrammatical: A man who had a beard was ever thrifty.\n\n\nPositive polarity items\n\n\nUngrammatical: No man who had a beard was certainly thrifty.\nGrammatical (Intrusive NPI licensor): A man who had no beard was certainly thrifty.\nGrammatical: A man who had a beard was certainly thrifty.\n\nWe will focus only on re-reading time in this data set. Subset the data so that we only have re-reading times in the data frame:\n\n\ndat2 &lt;- subset(df_polarity, times == \"RRT\")\nhead(dat2)\n\n     subject item condition times    value\n6365       1   20         b   RRT  239.571\n6366       1    3         c   RRT 1866.169\n6367       1   13         a   RRT  529.576\n6368       1   19         a   RRT  269.002\n6369       1   27         c   RRT  844.770\n6370       1   26         b   RRT  634.654\n\n\nThe comparisons we are interested in are: &gt; - RQ1: What is the difference in reading time between negative polarity items and positive polarity items? - RQ2: Within negative polarity items, what is the difference between grammatical and ungrammatical conditions? - RQ3: Within negative polarity items, what is the difference between the two ungrammatical conditions? - RQ4: Within positive polarity items, what is the difference between grammatical and ungrammatical conditions? - RQ5: Within positive polarity items, what is the difference between the two grammatical conditions? &gt; Use the hypr package to specify the comparisons specified above, and then extract the contrast matrix.\nMy outline of our effects/comparisons of interest:\n\na main effect of polarity (positive vs negative)\nnested effect of grammaticality within either level of polarity\neffect of intrusivity within either polarity level\n\n\nlevels(dat2$condition)\n\n[1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\"\n\n\nTo help me: create predictor factors.\n\ndat2 &lt;-\n  dat2 |&gt; \n  mutate(polarity = ifelse(condition %in% c(\"a\", \"b\", \"c\"), \"negative\", \"positive\"),\n         gramm = ifelse(condition %in% c(\"a\", \"e\", \"f\"), \"gramm\", \"ungramm\"),\n         intru = ifelse(condition %in% c(\"b\", \"e\"), \"intrusive\", \"unintrusive\"))\n\n\ndat2 |&gt; \n  distinct(condition, .keep_all = T) |&gt; \n  arrange(condition)\n\n  subject item condition times    value polarity   gramm       intru\n1       1   13         a   RRT  529.576 negative   gramm unintrusive\n2       1   20         b   RRT  239.571 negative ungramm   intrusive\n3       1    3         c   RRT 1866.169 negative ungramm unintrusive\n4       1    4         d   RRT  332.036 positive ungramm unintrusive\n5       1   11         e   RRT  806.971 positive   gramm   intrusive\n6       2   29         f   RRT  319.430 positive   gramm unintrusive\n\n\n\ncond_dat2 &lt;-\n  hypr(\n   rq1 =  (a + b + c) /3~ (d + e + f) /3,\n   rq2 = a ~ (b + c) / 2,\n   rq3 = b ~ c,\n   rq4 = d ~ (e+f)/2,\n   rq5 = e ~ f,\n   levels = c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")\n )\n\ncond_dat2\n\nhypr object containing 5 null hypotheses:\nH0.rq1: 0 = (a + b + c - d - e - f)/3\nH0.rq2: 0 = a - 1/2*b - 1/2*c\nH0.rq3: 0 = b - c\nH0.rq4: 0 = d - 1/2*e - 1/2*f\nH0.rq5: 0 = e - f\n\nCall:\nhypr(rq1 = ~1/3 * a + 1/3 * b + 1/3 * c - 1/3 * d - 1/3 * e - \n    1/3 * f, rq2 = ~a - 1/2 * b - 1/2 * c, rq3 = ~b - c, rq4 = ~d - \n    1/2 * e - 1/2 * f, rq5 = ~e - f, levels = c(\"a\", \"b\", \"c\", \n\"d\", \"e\", \"f\"))\n\nHypothesis matrix (transposed):\n  rq1  rq2  rq3  rq4  rq5 \na  1/3    1    0    0    0\nb  1/3 -1/2    1    0    0\nc  1/3 -1/2   -1    0    0\nd -1/3    0    0    1    0\ne -1/3    0    0 -1/2    1\nf -1/3    0    0 -1/2   -1\n\nContrast matrix:\n  rq1  rq2  rq3  rq4  rq5 \na  1/2  2/3    0    0    0\nb  1/2 -1/3  1/2    0    0\nc  1/2 -1/3 -1/2    0    0\nd -1/2    0    0  2/3    0\ne -1/2    0    0 -1/3  1/2\nf -1/2    0    0 -1/3 -1/2\n\n\n\nFinally, specify the contrasts to the condition column in the data frame.\n\n\ncontrasts(dat2$condition) &lt;- contr.hypothesis(cond_dat2)\n\n\ncontrasts(dat2$condition)\n\n  rq1  rq2  rq3  rq4  rq5 \na  1/2  2/3    0    0    0\nb  1/2 -1/3  1/2    0    0\nc  1/2 -1/3 -1/2    0    0\nd -1/2    0    0  2/3    0\ne -1/2    0    0 -1/3  1/2\nf -1/2    0    0 -1/3 -1/2\n\n\n\nFit a linear model using this contrast specification, and then check that the estimates from the model match the mean differences between the conditions being compared.\n\n\nfit_dat2 &lt;- brm(value ~ 1 + condition,\n  data = dat2,\n  family = gaussian(),\n  # prior = c(\n  #   prior(normal(550, 25), class = Intercept),\n  #   prior(normal(25, 2), class = sigma),\n  #   prior(normal(25, 1), class = b)\n  # ),\n  file = here::here(\"models/exercises/ch8/fit_ch_8_ex2\")\n)\n\n\nfixef(fit_dat2)\n\n               Estimate Est.Error       Q2.5     Q97.5\nIntercept     510.79417  17.39399  477.20865 544.30347\nconditionrq1  153.45661  35.39835   85.69990 223.12523\nconditionrq2 -152.05606  52.45486 -251.79242 -52.02678\nconditionrq3  -25.59221  56.49876 -136.06084  84.89980\nconditionrq4  141.53725  55.53767   34.55437 249.76384\nconditionrq5   34.69203  62.82869  -91.78247 158.63615\n\n\nCalculate the estimates per condition:\n\ncontrasts(dat2$condition)\n\n  rq1  rq2  rq3  rq4  rq5 \na  1/2  2/3    0    0    0\nb  1/2 -1/3  1/2    0    0\nc  1/2 -1/3 -1/2    0    0\nd -1/2    0    0  2/3    0\ne -1/2    0    0 -1/3  1/2\nf -1/2    0    0 -1/3 -1/2\n\n\n\n# intercept\nintercept &lt;- fixef(fit_dat2)[\"Intercept\",\"Estimate\"]\n\n\n7.2.1 RQ1: dif between positive and negative\nRaw diff’s.\n\ndat2 |&gt; \n  summarise(mean = mean(value),\n            .by = polarity) |&gt; \n  pivot_wider(names_from = polarity, values_from = mean) |&gt; \n  mutate(difference = negative - positive)\n\n# A tibble: 1 × 3\n  negative positive difference\n     &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n1     592.     440.       152.\n\n\n\npositive &lt;- intercept + fixef(fit_dat2)[\"conditionrq1\",\"Estimate\"]*-0.5\nnegative &lt;- intercept + fixef(fit_dat2)[\"conditionrq1\",\"Estimate\"]*0.5\nrq1 &lt;- negative - positive\n\nEstimated diff.\n\nrq1\n\n[1] 153.4566\n\n\nSlope value.\n\nfixef(fit_dat2)[\"conditionrq1\",\"Estimate\"]\n\n[1] 153.4566\n\n\n\n\n7.2.2 RQ2: Grammaticality diff’s within negative (cond a vs b+c)\nRaw diff’s.\n\ndat2 |&gt; \n  filter(polarity == \"negative\") |&gt; \n  summarise(mean = mean(value),\n            .by = gramm) |&gt; \n  pivot_wider(names_from = gramm, values_from = mean) |&gt; \n  mutate(difference = gramm - ungramm)\n\n# A tibble: 1 × 3\n  ungramm gramm difference\n    &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1    639.  487.      -152.\n\n\n\nest_gramm &lt;- intercept + fixef(fit_dat2)[\"conditionrq2\",\"Estimate\"]*0.5\nest_ungramm &lt;- intercept + fixef(fit_dat2)[\"conditionrq2\",\"Estimate\"]*-0.5\nrq2 &lt;- est_gramm - est_ungramm\n\nEstimated diff.\n\nrq2\n\n[1] -152.0561\n\n\nSlope value.\n\nfixef(fit_dat2)[\"conditionrq2\",\"Estimate\"]\n\n[1] -152.0561\n\n\n\n\n7.2.3 RQ3: Ungramm vs. ungramm within negative (cond b vs. c)\nRaw diff’s.\n\ndat2 |&gt; \n  summarise(mean = mean(value),\n            .by = condition) |&gt; \n  filter(condition %in% c(\"b\", \"c\")) |&gt; \n  pivot_wider(names_from = condition, values_from = mean) |&gt; \n  mutate(difference = b - c)\n\n# A tibble: 1 × 3\n      b     c difference\n  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1  626.  652.      -25.4\n\n\n\nest_b &lt;- intercept + fixef(fit_dat2)[\"conditionrq3\",\"Estimate\"]*0.5\nest_c &lt;- intercept + fixef(fit_dat2)[\"conditionrq3\",\"Estimate\"]*-0.5\nrq3 &lt;- est_b - est_c\n\nEstimated diff.\n\nrq3\n\n[1] -25.59221\n\n\nSlope value.\n\nfixef(fit_dat2)[\"conditionrq3\",\"Estimate\"]\n\n[1] -25.59221\n\n\n\n\n7.2.4 RQ4: Grammaticality diff’s within positive (cond d vs. e + f)\nRaw diff’s.\n\ndat2 |&gt; \n  filter(polarity == \"positive\") |&gt; \n  summarise(mean = mean(value),\n            .by = gramm) |&gt; \n  pivot_wider(names_from = gramm, values_from = mean) |&gt; \n  mutate(difference = gramm - ungramm)\n\n# A tibble: 1 × 3\n  ungramm gramm difference\n    &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1    529.  389.      -140.\n\n\n\nest_gramm &lt;- intercept + fixef(fit_dat2)[\"conditionrq4\",\"Estimate\"]*0.5\nest_ungramm &lt;- intercept + fixef(fit_dat2)[\"conditionrq4\",\"Estimate\"]*-0.5\nrq4 &lt;- est_gramm - est_ungramm\n\nEstimated diff.\n\nrq4\n\n[1] 141.5373\n\n\nSlope value.\n\nfixef(fit_dat2)[\"conditionrq4\",\"Estimate\"]\n\n[1] 141.5373\n\n\n\n\n7.2.5 RQ5: Gramm vs. gramm within positive (cond e vs. f)\nRaw diff’s.\n\ndat2 |&gt; \n  summarise(mean = mean(value),\n            .by = condition) |&gt; \n  filter(condition %in% c(\"e\", \"f\")) |&gt; \n  pivot_wider(names_from = condition, values_from = mean) |&gt; \n  mutate(difference = e - f)\n\n# A tibble: 1 × 3\n      e     f difference\n  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1  405.  371.       34.0\n\n\n\nest_e &lt;- intercept + fixef(fit_dat2)[\"conditionrq5\",\"Estimate\"]*0.5\nest_f &lt;- intercept + fixef(fit_dat2)[\"conditionrq5\",\"Estimate\"]*-0.5\nrq5 &lt;- est_e - est_f\n\nEstimated diff.\n\nrq5\n\n[1] 34.69203\n\n\nSlope value.\n\nfixef(fit_dat2)[\"conditionrq5\",\"Estimate\"]\n\n[1] 34.69203",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ch. 8 Exercises</span>"
    ]
  },
  {
    "objectID": "book_exercises/ch8_exercises.html#exercise-8.3-number-of-possible-comparisons-in-a-single-model.",
    "href": "book_exercises/ch8_exercises.html#exercise-8.3-number-of-possible-comparisons-in-a-single-model.",
    "title": "7  Ch. 8 Exercises",
    "section": "7.3 Exercise 8.3 Number of possible comparisons in a single model.",
    "text": "7.3 Exercise 8.3 Number of possible comparisons in a single model.\n\nHow many comparisons can one make in a single model when there is a single factor with four levels? Why can we not code four comparisons in a single model?\n\n1 v (2,3,4) (1,2) v. (3,4) (1,2,3) v. 4 1 v 2 1 v 3 1 v 4\n3 v. (3)\n\nHow many comparisons can one code in a model where there are two factors, one with three levels and one with two levels?\n\nSix conditions, two main effects.\n\nHow about a model for a 2 x 2 design?\n\nFour conditions, two main effects. - compare main effects (x1) - compare nested effects for pred1/pred2 (x2) + and pred2/pred1 (x2)",
    "crumbs": [
      "Book exercises",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ch. 8 Exercises</span>"
    ]
  }
]