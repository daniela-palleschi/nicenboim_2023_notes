---
title: "Ch. 15 Exercises"
execute:
  eval: true
  shift-heading-level-by: +1
---

## Set-up {.unnumbered}

```{r}
#| code-fold: true
pacman::p_load(
  tidyverse,
  brms,
  here,
  Rmisc,
  bcogsci,
  MASS,
  lmer4
)
summarise <- dplyr::summarise
```

## **Exercise 15.1** Is there evidence for differences in the effect of cloze probability among the subjects?

> Use Bayes factor to compare the log cloze probability model that we examined in section 15.2.2 with a similar model but that incorporates the strong assumption of no difference between subjects for the effect of cloze (τu2=0).

### My solution

Read in the data, transform cloze probabilities.

```{r}
data(df_eeg)
df_eeg <- df_eeg %>%
  mutate(c_cloze = cloze - mean(cloze),
         scloze = (cloze_ans + 1) / (N + 2),
         c_logscloze = log(scloze) - mean(log(scloze)),
         # centre
         c_logscloze = scale(c_logscloze) * sd(c_cloze))
```

Set original priors.

```{r}
priors1 <- c(prior(normal(2, 5), class = Intercept),
             prior(normal(0, 5), class = b),
             prior(normal(10, 5), class = sigma),
             prior(normal(0, 2), class = sd),
             prior(lkj(4), class = cor))
```

Run model from book section.

```{r}
fit_N400_h_log <- brm(n400 ~ c_logscloze +
                        (c_logscloze | subj) + (c_logscloze | item),
                      prior = priors1,
                      warmup = 2000,
                      iter = 20000,
                      control = list(adapt_delta = 0.9),
                      save_pars = save_pars(all = TRUE),
                      data = df_eeg,
  file = here::here("models/notes/ch15/fit_N400_h_log"))
```

Get marginal log likelihood for the model.

```{r}
margLogLik_log <- bridge_sampler(fit_N400_h_log, silent = TRUE)
```

Now for the new priors with "no difference between subjects for the effect of cloze ($\tau_{u_2}$ = 0)"^[from [Section 5.2.3 'Varying intercepts and varying slopes model'](https://vasishth.github.io/bayescogsci/book/ch-hierarchical.html#sec-uncorrelated): "the mean effect of cloze is estimated as  
$\beta$ [`class = b`], and the deviations of individual subjects’ mean effects of cloze from $\beta$ are the adjustment $u_2$. The standard deviations of these two adjustment terms, $\tau_{u_1}$ and $\tau_{u_2}$, respectively, represent between subject variability"]:

```{r}
fit_N400_h_log_tau0 <- brm(n400 ~ c_logscloze +
                        (1 | subj) + (c_logscloze | item),
                      prior = priors1,
                      warmup = 2000,
                      iter = 6000,
                      control = list(adapt_delta = 0.9),
                      save_pars = save_pars(all = TRUE),
                      data = df_eeg,
  file = here::here("models/exercises/ch15/fit_N400_h_log_tau0"))
```


```{r}
fixef(fit_N400_h_log_tau0)
```

Get marginal log likelihood for the model.

```{r}
margLogLik_log_tau0 <- bridge_sampler(fit_N400_h_log_tau0, silent = TRUE)
```

```{r}
(BF_log_tau <- bayes_factor(margLogLik_log,
                            margLogLik_log_tau0))
```

## **Exercise 15.2** Is there evidence for the claim that English subject relative clauses are easier to process than object relative clauses?

> Consider again the reading time data coming from Experiment 1 of Grodner and Gibson (2005) presented in exercise 5.2:
>
```{r}
data("df_gg05_rc")
df_gg05_rc
```

> As in exercise 5.2, you should use a sum coding for the predictors. Here, object relative clauses ("objgaps") are coded +1/2, and subject relative clauses as −1/2.
>
```{r}
df_gg05_rc <- df_gg05_rc %>%
  mutate(c_cond = if_else(condition == "objgap", 1/2, -1/2))
```

> Using the Bayes factors function shown in this chapter, quantify the evidence against the null model (no population-level reading time difference between SRC and ORC) relative to the following alternative models:
>
a. $\beta \sim \mathit{Normal}(0, 1)$
b. $\beta \sim \mathit{Normal}(0, 0.1)$
c. $\beta \sim \mathit{Normal}(0, 0.01)$
d. $\beta \sim \mathit{Normal_+}(0, 1)$
e. $\beta \sim \mathit{Normal_+}(0, 0.1)$
f. $\beta \sim \mathit{Normal_+}(0, .001)$
>
(A $Normal_+(.)$ prior can be set in `brms` by defining a lower boundary as 0, with the argument `lb = 0.`)
>
What are the Bayes factors in favor of the alternative models a-f, compared to the null model?
>
Now carry out a standard frequentist likelihood ratio test using the anova() function that is used with the lmer() function. The commands for doing this comparison would be:
>
```{r}
#| eval: false
m_full <- lmer(log(RT) ~ c_cond +
                 (c_cond || subj) + (c_cond || item),
               df_gg05_rc)
m_null <- lmer(log(RT) ~ 1 + (c_cond||subj) + (c_cond || item),
               df_gg05_rc)
anova(m_null, m_full)
```
>
How do the conclusions from the Bayes factor analyses compare with the conclusion we obtain from the frequentist model comparison?

